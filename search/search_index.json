{"config":{"lang":["en","pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>Mosaico is a Python library for programmatically creating and managing video compositions. It provides a high-level interface for working with media assets, positioning elements, applying effects, and generating video scripts, all built on top of MoviePy - one of the most popular video editing libraries in Python.</p> <p>The library is designed with flexibility and extensibility in mind, offering clean abstractions for:</p> <ul> <li>Managing different types of media assets (audio, images, text, subtitles)</li> <li>Precise positioning and layout control</li> <li>Effect application and animation</li> <li>AI-powered script generation</li> <li>Text-to-speech synthesis</li> <li>Integration with popular ML frameworks</li> </ul>"},{"location":"#key-features-and-capabilities","title":"Key Features and Capabilities","text":"<ul> <li> <p> Script Generation</p> <ul> <li>Clean interfaces for custom script generation</li> <li>Extensible framework for AI integration</li> <li>Shot and scene organization</li> <li>Script-to-video rendering</li> </ul> </li> <li> <p> Asset Management</p> <ul> <li>Support for multiple media types</li> <li>Flexible asset parameters and metadata handling</li> <li>Reference system for tracking assets in scenes</li> </ul> </li> <li> <p> Positioning System</p> <ul> <li>Multiple positioning modes (absolute, relative, region-based)</li> <li>Frame-aware positioning calculations</li> <li>Flexible alignment options</li> </ul> </li> <li> <p> Effects Engine</p> <ul> <li>Built-in pan and zoom effects</li> <li>Extensible effect system</li> <li>Parameter-based effect configuration</li> <li>Effect composition support</li> </ul> </li> <li> <p> Speech Synthesis</p> <ul> <li>Integration with major TTS providers</li> <li>Configurable voice parameters</li> <li>Batch synthesis support</li> <li>Asset parameter controls</li> </ul> </li> <li> <p> External Integrations</p> <ul> <li>Haystack and LangChain integrations out of the box</li> <li>Extensible adapter system</li> <li>Clean integration protocols</li> </ul> </li> </ul>"},{"location":"roadmap/","title":"Roadmap","text":"<p>Mosaico is constantly evolving. We are committed to continuously developing Mosaico, always seeking to improve the user experience and expand the library's capabilities. This roadmap is subject to change based on community feedback and emerging trends in video production technology.</p> <p>Below are the main focus areas for future library development:</p>"},{"location":"roadmap/#enhanced-content-generation","title":"Enhanced Content Generation","text":"<ul> <li>Implementation of script generation using advanced AI technologies</li> <li>Expansion of automated scene generation capabilities</li> <li>Development of tools for creating more dynamic and interactive content</li> </ul>"},{"location":"roadmap/#effects-and-transitions","title":"Effects and Transitions","text":"<ul> <li>Addition of a variety of transition effects between scenes</li> <li>Implementation of customizable effects for individual assets</li> <li>Creation of a standard effects library for quick use</li> </ul>"},{"location":"roadmap/#audio-and-music","title":"Audio and Music","text":"<ul> <li>Integration of functionality for adding soundtracks to projects</li> <li>Enhancement of subtitle support, including more dynamic and responsive options</li> <li>Expansion of speech synthesizer integrations</li> </ul>"},{"location":"roadmap/#customization-and-flexibility","title":"Customization and Flexibility","text":"<ul> <li>Development of a modular system for scene creation</li> <li>Implementation of advanced customization options for all aspects of the project</li> </ul>"},{"location":"roadmap/#documentation-and-examples","title":"Documentation and Examples","text":"<ul> <li>Creation of cookbooks with practical usage examples</li> <li>Expansion of documentation to include more languages</li> <li>Development of interactive tutorials and best practice guides</li> </ul>"},{"location":"roadmap/#integrations-and-compatibility","title":"Integrations and Compatibility","text":"<ul> <li>Expansion of integrations with other AI frameworks</li> <li>Improved compatibility with different media formats and platforms</li> </ul>"},{"location":"roadmap/#optimization-and-performance","title":"Optimization and Performance","text":"<ul> <li>Enhancement of overall library performance</li> <li>Implementation of optimization techniques for large-scale projects</li> </ul>"},{"location":"api-reference/asset-reference/","title":"Asset Reference","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference","title":"AssetReference","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an asset used in a scene.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.asset_id","title":"asset_id  <code>instance-attribute</code>","text":"<pre><code>asset_id: str\n</code></pre> <p>The ID of the asset.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.asset_type","title":"asset_type  <code>instance-attribute</code>","text":"<pre><code>asset_type: AssetType\n</code></pre> <p>The refered asset type.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.asset_params","title":"asset_params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>asset_params: AssetParams | None = None\n</code></pre> <p>The asset reference params.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.start_time","title":"start_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_time: NonNegativeFloat = 0\n</code></pre> <p>The start time of the asset in seconds.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.end_time","title":"end_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_time: NonNegativeFloat = 0\n</code></pre> <p>The end time of the asset in seconds.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.effects","title":"effects  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>effects: list[VideoEffect] = Field(default_factory=list)\n</code></pre> <p>The effects to apply to the asset.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: float\n</code></pre> <p>The duration of the asset in seconds.</p>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_asset","title":"from_asset  <code>classmethod</code>","text":"<pre><code>from_asset(\n    asset: Asset,\n    *,\n    asset_params: AssetParams | None = None,\n    start_time: float | None = None,\n    end_time: float | None = None,\n    effects: Sequence[VideoEffect] | None = None\n) -&gt; AssetReference\n</code></pre> <p>Create an asset reference from an asset.</p> <p>Parameters:</p> Name Type Description Default <code>Asset</code> <p>The asset to reference.</p> required <code>AssetParams | None</code> <p>The asset params.</p> <code>None</code> <code>float | None</code> <p>The start time of the asset in seconds.</p> <code>None</code> <code>float | None</code> <p>The end time of the asset in seconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>AssetReference</code> <p>The asset reference.</p> Source code in <code>src/mosaico/assets/reference.py</code> <pre><code>@classmethod\ndef from_asset(\n    cls,\n    asset: Asset,\n    *,\n    asset_params: AssetParams | None = None,\n    start_time: float | None = None,\n    end_time: float | None = None,\n    effects: Sequence[VideoEffect] | None = None,\n) -&gt; AssetReference:\n    \"\"\"\n    Create an asset reference from an asset.\n\n    :param asset: The asset to reference.\n    :param asset_params: The asset params.\n    :param start_time: The start time of the asset in seconds.\n    :param end_time: The end time of the asset in seconds.\n    :return: The asset reference.\n    \"\"\"\n    return cls(\n        asset_id=asset.id,\n        asset_type=asset.type,\n        asset_params=asset_params or asset.params,\n        start_time=start_time if start_time is not None else 0,\n        end_time=end_time if end_time is not None else 0,\n        effects=list(effects) if effects is not None else [],\n    )\n</code></pre>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_asset(asset)","title":"<code>asset</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_asset(asset_params)","title":"<code>asset_params</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_asset(start_time)","title":"<code>start_time</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_asset(end_time)","title":"<code>end_time</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: Mapping[str, Any]) -&gt; AssetReference\n</code></pre> <p>Create an asset reference from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>Mapping[str, Any]</code> <p>The dictionary data.</p> required <p>Returns:</p> Type Description <code>AssetReference</code> <p>The asset reference.</p> Source code in <code>src/mosaico/assets/reference.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Mapping[str, Any]) -&gt; AssetReference:\n    \"\"\"\n    Create an asset reference from a dictionary.\n\n    :param data: The dictionary data.\n    :return: The asset reference.\n    \"\"\"\n    if \"asset_type\" not in data:\n        msg = \"Missing 'asset_type' key in asset reference data.\"\n        raise ValueError(msg)\n\n    if \"asset_params\" in data and data[\"asset_params\"] is not None:\n        params_cls = get_asset_params_class(data[\"asset_type\"])\n        data[\"asset_params\"] = params_cls.model_validate(data[\"asset_params\"])\n\n    return cls.model_validate(data)\n</code></pre>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.from_dict(data)","title":"<code>data</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_params","title":"with_params","text":"<pre><code>with_params(params: AssetParams) -&gt; AssetReference\n</code></pre> <p>Add scene params to the asset reference.</p> <p>Parameters:</p> Name Type Description Default <code>AssetParams</code> <p>The scene params to add.</p> required <p>Returns:</p> Type Description <code>AssetReference</code> <p>The asset reference.</p> Source code in <code>src/mosaico/assets/reference.py</code> <pre><code>def with_params(self, params: AssetParams) -&gt; AssetReference:\n    \"\"\"\n    Add scene params to the asset reference.\n\n    :param params: The scene params to add.\n    :return: The asset reference.\n    \"\"\"\n    self.asset_params = params\n    return self\n</code></pre>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_params(params)","title":"<code>params</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_start_time","title":"with_start_time","text":"<pre><code>with_start_time(start_time: float) -&gt; AssetReference\n</code></pre> <p>Add a start time to the asset reference.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>The start time to add.</p> required <p>Returns:</p> Type Description <code>AssetReference</code> <p>The asset reference.</p> Source code in <code>src/mosaico/assets/reference.py</code> <pre><code>def with_start_time(self, start_time: float) -&gt; AssetReference:\n    \"\"\"\n    Add a start time to the asset reference.\n\n    :param start_time: The start time to add.\n    :return: The asset reference.\n    \"\"\"\n    self.start_time = start_time\n    return self\n</code></pre>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_start_time(start_time)","title":"<code>start_time</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_end_time","title":"with_end_time","text":"<pre><code>with_end_time(end_time: float) -&gt; AssetReference\n</code></pre> <p>Add an end time to the asset reference.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>The end time to add.</p> required <p>Returns:</p> Type Description <code>AssetReference</code> <p>The asset reference.</p> Source code in <code>src/mosaico/assets/reference.py</code> <pre><code>def with_end_time(self, end_time: float) -&gt; AssetReference:\n    \"\"\"\n    Add an end time to the asset reference.\n\n    :param end_time: The end time to add.\n    :return: The asset reference.\n    \"\"\"\n    self.end_time = end_time\n    return self\n</code></pre>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_end_time(end_time)","title":"<code>end_time</code>","text":""},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_effects","title":"with_effects","text":"<pre><code>with_effects(effects: Sequence[Effect]) -&gt; AssetReference\n</code></pre> <p>Add effects to the asset reference.</p> <p>Parameters:</p> Name Type Description Default <code>Sequence[Effect]</code> <p>The effects to add.</p> required <p>Returns:</p> Type Description <code>AssetReference</code> <p>The asset reference.</p> Source code in <code>src/mosaico/assets/reference.py</code> <pre><code>def with_effects(self, effects: Sequence[Effect]) -&gt; AssetReference:\n    \"\"\"\n    Add effects to the asset reference.\n\n    :param effects: The effects to add.\n    :return: The asset reference.\n    \"\"\"\n    effects = cast(list[VideoEffect], effects)\n    self.effects.extend(effects)\n    return self\n</code></pre>"},{"location":"api-reference/asset-reference/#mosaico.assets.reference.AssetReference.with_effects(effects)","title":"<code>effects</code>","text":""},{"location":"api-reference/media/","title":"Media","text":""},{"location":"api-reference/media/#mosaico.media.Media","title":"Media","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a media object.</p>"},{"location":"api-reference/media/#mosaico.media.Media.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre> <p>The unique identifier of the assets.</p>"},{"location":"api-reference/media/#mosaico.media.Media.data","title":"data  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data: str | bytes | None = None\n</code></pre> <p>The content of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.path","title":"path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>path: FilePath | None = None\n</code></pre> <p>The path to the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.mime_type","title":"mime_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mime_type: str | None = None\n</code></pre> <p>The MIME type of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.encoding","title":"encoding  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>encoding: str = 'utf-8'\n</code></pre> <p>The encoding of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <p>The metadata of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.storage_options","title":"storage_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>storage_options: dict[str, Any] = Field(\n    default_factory=copy\n)\n</code></pre> <p>Media's storage options.</p>"},{"location":"api-reference/media/#mosaico.media.Media.description","title":"description  <code>property</code>","text":"<pre><code>description: str\n</code></pre> <p>Returns a description of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.credits","title":"credits  <code>property</code>","text":"<pre><code>credits: list[str]\n</code></pre> <p>Returns the credits of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.credit","title":"credit  <code>property</code>","text":"<pre><code>credit: str\n</code></pre> <p>Returns the credit of the media.</p>"},{"location":"api-reference/media/#mosaico.media.Media.validate_media","title":"validate_media  <code>classmethod</code>","text":"<pre><code>validate_media(values: dict[str, Any]) -&gt; Any\n</code></pre> <p>Validates the content of the media.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef validate_media(cls, values: dict[str, Any]) -&gt; Any:\n    \"\"\"\n    Validates the content of the media.\n    \"\"\"\n    if \"data\" not in values and \"path\" not in values:\n        raise ValueError(\"Either data or path must be provided\")\n\n    return values\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.decode_base64_data","title":"decode_base64_data  <code>classmethod</code>","text":"<pre><code>decode_base64_data(\n    v: bytes | str | None,\n) -&gt; bytes | str | None\n</code></pre> <p>Decode field data from Base64 only if it looks like Base64.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@field_validator(\"data\")\n@classmethod\ndef decode_base64_data(cls, v: bytes | str | None) -&gt; bytes | str | None:\n    \"\"\"\n    Decode field data from Base64 only if it looks like Base64.\n    \"\"\"\n    decodable_length = 16\n\n    if isinstance(v, str):\n        try:\n            raw = v.encode(\"ascii\")\n        except UnicodeEncodeError:\n            return v\n\n        # Only try to decode if it's a reasonable length for base64 (at least 16 characters)\n        # and matches the base64 pattern\n        if len(raw) &gt;= decodable_length and _BASE64_BYTE_PATTERN.match(raw) is not None:\n            # Check if it looks like base64 (proper length and valid characters)\n            if len(raw) % 4 == 0:\n                try:\n                    return base64.b64decode(raw, validate=True)\n                except binascii.Error:\n                    pass\n            # Also try if it looks like base64 without padding\n            else:\n                try:\n                    padding_needed = 4 - (len(raw) % 4)\n                    padded_raw = raw + b\"=\" * padding_needed\n                    return base64.b64decode(padded_raw, validate=True)\n                except binascii.Error:\n                    pass\n    return v\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.encode_base64_data","title":"encode_base64_data","text":"<pre><code>encode_base64_data(v) -&gt; str\n</code></pre> <p>Codifica campo data em base64.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@field_serializer(\"data\", when_used=\"json\")\ndef encode_base64_data(self, v) -&gt; str:\n    \"\"\"\n    Codifica campo data em base64.\n    \"\"\"\n    if isinstance(v, bytes):\n        return base64.b64encode(v).decode(self.encoding)\n    return v\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.from_path","title":"from_path  <code>classmethod</code>","text":"<pre><code>from_path(\n    path: FilePath,\n    *,\n    encoding: str = \"utf-8\",\n    mime_type: str | None = None,\n    guess_mime_type: bool = True,\n    metadata: dict | None = None,\n    **kwargs: Any\n) -&gt; Self\n</code></pre> <p>Creates a media from a path.</p> <p>Parameters:</p> Name Type Description Default <code>FilePath</code> <p>The path to the media.</p> required <code>str</code> <p>The encoding of the media.</p> <code>'utf-8'</code> <code>str | None</code> <p>The MIME type of the media.</p> <code>None</code> <code>bool</code> <p>Whether to guess the MIME type.</p> <code>True</code> <code>dict | None</code> <p>The metadata of the media.</p> <code>None</code> <code>Any</code> <p>Additional keyword arguments to the constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The media.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@classmethod\ndef from_path(\n    cls,\n    path: FilePath,\n    *,\n    encoding: str = \"utf-8\",\n    mime_type: str | None = None,\n    guess_mime_type: bool = True,\n    metadata: dict | None = None,\n    **kwargs: Any,\n) -&gt; Self:\n    \"\"\"\n    Creates a media from a path.\n\n    :param path: The path to the media.\n    :param encoding: The encoding of the media.\n    :param mime_type: The MIME type of the media.\n    :param guess_mime_type: Whether to guess the MIME type.\n    :param metadata: The metadata of the media.\n    :param kwargs: Additional keyword arguments to the constructor.\n    :return: The media.\n    \"\"\"\n    if not mime_type and guess_mime_type:\n        mime_type = mimetypes.guess_type(str(path))[0]\n\n    return cls(\n        data=None,\n        path=path,\n        metadata=metadata if metadata is not None else {},\n        encoding=encoding,\n        mime_type=mime_type,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.from_path(path)","title":"<code>path</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_path(encoding)","title":"<code>encoding</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_path(mime_type)","title":"<code>mime_type</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_path(guess_mime_type)","title":"<code>guess_mime_type</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_path(metadata)","title":"<code>metadata</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_path(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_data","title":"from_data  <code>classmethod</code>","text":"<pre><code>from_data(\n    data: str | bytes,\n    *,\n    path: FilePath | None = None,\n    metadata: dict | None = None,\n    mime_type: str | None = None,\n    **kwargs: Any\n) -&gt; Self\n</code></pre> <p>Creates a media from data.</p> <p>Parameters:</p> Name Type Description Default <code>str | bytes</code> <p>The data of the media.</p> required <code>FilePath | None</code> <p>The path to the media.</p> <code>None</code> <code>dict | None</code> <p>The metadata of the media.</p> <code>None</code> <code>str | None</code> <p>The MIME type of the media.</p> <code>None</code> <code>Any</code> <p>Additional keyword arguments to the constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The media.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@classmethod\ndef from_data(\n    cls,\n    data: str | bytes,\n    *,\n    path: FilePath | None = None,\n    metadata: dict | None = None,\n    mime_type: str | None = None,\n    **kwargs: Any,\n) -&gt; Self:\n    \"\"\"\n    Creates a media from data.\n\n    :param data: The data of the media.\n    :param path: The path to the media.\n    :param metadata: The metadata of the media.\n    :param mime_type: The MIME type of the media.\n    :param kwargs: Additional keyword arguments to the constructor.\n    :return: The media.\n    \"\"\"\n    return cls(\n        data=data,\n        path=path,\n        metadata=metadata if metadata is not None else {},\n        mime_type=mime_type,\n        **{k: v for k, v in kwargs.items() if v is not None},\n    )\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.from_data(data)","title":"<code>data</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_data(path)","title":"<code>path</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_data(metadata)","title":"<code>metadata</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_data(mime_type)","title":"<code>mime_type</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_data(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/media/#mosaico.media.Media.from_external","title":"from_external  <code>classmethod</code>","text":"<pre><code>from_external(\n    adapter: Adapter[Media, Any], external: Any\n) -&gt; Media\n</code></pre> <p>Converts an external representation to a media.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@classmethod\ndef from_external(cls, adapter: Adapter[Media, Any], external: Any) -&gt; Media:\n    \"\"\"\n    Converts an external representation to a media.\n    \"\"\"\n    return adapter.from_external(external)\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.to_external","title":"to_external","text":"<pre><code>to_external(adapter: Adapter[Media, Any]) -&gt; Any\n</code></pre> <p>Converts the media to an external representation.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>def to_external(self, adapter: Adapter[Media, Any]) -&gt; Any:\n    \"\"\"\n    Converts the media to an external representation.\n    \"\"\"\n    return adapter.to_external(self)\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.to_string","title":"to_string","text":"<pre><code>to_string(**kwargs: Any) -&gt; str\n</code></pre> <p>Returns the media as a string.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>def to_string(self, **kwargs: Any) -&gt; str:\n    \"\"\"\n    Returns the media as a string.\n    \"\"\"\n    if isinstance(self.data, str):\n        return self.data\n    if isinstance(self.data, bytes):\n        return self.data.decode(self.encoding)\n    if self.data is None and self.path is not None:\n        kwargs[\"mode\"] = \"r\"\n        with self.open(**kwargs) as f:\n            return cast(str, f.read())\n    raise ValueError(\"Data is not a string or bytes\")\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.to_bytes","title":"to_bytes","text":"<pre><code>to_bytes(**kwargs: Any) -&gt; bytes\n</code></pre> <p>Returns the media as bytes.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>def to_bytes(self, **kwargs: Any) -&gt; bytes:\n    \"\"\"\n    Returns the media as bytes.\n    \"\"\"\n    if isinstance(self.data, bytes):\n        return self.data\n    if isinstance(self.data, str):\n        return self.data.encode(self.encoding)\n    if self.data is None and self.path is not None:\n        kwargs[\"mode\"] = \"rb\"\n        with self.open(**kwargs) as f:\n            return cast(bytes, f.read())\n    raise ValueError(\"Data is not a string or bytes\")\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.to_bytes_io","title":"to_bytes_io","text":"<pre><code>to_bytes_io(\n    **kwargs: Any,\n) -&gt; Generator[IO[bytes], None, None]\n</code></pre> <p>Read data as a byte stream.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@contextlib.contextmanager\ndef to_bytes_io(self, **kwargs: Any) -&gt; Generator[IO[bytes], None, None]:\n    \"\"\"\n    Read data as a byte stream.\n    \"\"\"\n    if isinstance(self.data, bytes):\n        yield io.BytesIO(self.data)\n    elif isinstance(self.data, str):\n        yield io.BytesIO(self.data.encode(self.encoding))\n    elif self.data is None and self.path:\n        kwargs[\"mode\"] = \"rb\"\n        with self.open(**kwargs) as f:\n            yield cast(IO[bytes], f)\n    else:\n        raise NotImplementedError(f\"Unable to convert blob {self}\")\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.open","title":"open","text":"<pre><code>open(\n    **kwargs,\n) -&gt; Generator[IO[bytes] | IO[str], None, None]\n</code></pre> <p>Opens the media for read/write operations.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>@contextlib.contextmanager\ndef open(self, **kwargs) -&gt; Generator[IO[bytes] | IO[str], None, None]:\n    \"\"\"\n    Opens the media for read/write operations.\n    \"\"\"\n    if self.path is None:\n        raise ValueError(\"File-opening could only be done when 'path' is not missing.\")\n    fs, path_str = fsspec.core.url_to_fs(self.path, **self.storage_options)\n    with fs.open(path_str, **kwargs) as f:\n        yield f\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.add_metadata","title":"add_metadata","text":"<pre><code>add_metadata(metadata: dict[str, Any]) -&gt; Self\n</code></pre> <p>Add metadata to the media object.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>def add_metadata(self, metadata: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Add metadata to the media object.\n    \"\"\"\n    self.metadata.update(metadata)\n    return self\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.with_metadata","title":"with_metadata","text":"<pre><code>with_metadata(metadata: dict[str, Any]) -&gt; Self\n</code></pre> <p>Set media object metadata.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>def with_metadata(self, metadata: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Set media object metadata.\n    \"\"\"\n    self.metadata = metadata\n    return self\n</code></pre>"},{"location":"api-reference/media/#mosaico.media.Media.with_storage_options","title":"with_storage_options","text":"<pre><code>with_storage_options(\n    storage_options: dict[str, Any],\n) -&gt; Self\n</code></pre> <p>Add/replace storage options of the media object.</p> Source code in <code>src/mosaico/media.py</code> <pre><code>def with_storage_options(self, storage_options: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Add/replace storage options of the media object.\n    \"\"\"\n    self.storage_options = storage_options\n    return self\n</code></pre>"},{"location":"api-reference/scene/","title":"Scene","text":""},{"location":"api-reference/scene/#mosaico.scene.Scene","title":"Scene","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a unit of grouped asset references in a timeline.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.title","title":"title  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>title: str | None = None\n</code></pre> <p>An optional title of the scene.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: str | None = None\n</code></pre> <p>An optional description of the scene.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.asset_references","title":"asset_references  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>asset_references: list[AssetReference] = Field(\n    default_factory=list\n)\n</code></pre> <p>A list of assets associated with the scene.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.start_time","title":"start_time  <code>property</code>","text":"<pre><code>start_time: float\n</code></pre> <p>The start time of the scene in seconds.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.end_time","title":"end_time  <code>property</code>","text":"<pre><code>end_time: float\n</code></pre> <p>The end time of the scene in seconds.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: float\n</code></pre> <p>The duration of the scene in seconds.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.has_audio","title":"has_audio  <code>property</code>","text":"<pre><code>has_audio: bool\n</code></pre> <p>Check if the scene has an audio asset.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.has_subtitles","title":"has_subtitles  <code>property</code>","text":"<pre><code>has_subtitles: bool\n</code></pre> <p>Check if the scene has a subtitle asset.</p>"},{"location":"api-reference/scene/#mosaico.scene.Scene.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: Mapping[str, Any]) -&gt; Scene\n</code></pre> <p>Create a scene from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>Mapping[str, Any]</code> <p>The dictionary data.</p> required <p>Returns:</p> Type Description <code>Scene</code> <p>The scene.</p> Source code in <code>src/mosaico/scene.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Mapping[str, Any]) -&gt; Scene:\n    \"\"\"\n    Create a scene from a dictionary.\n\n    :param data: The dictionary data.\n    :return: The scene.\n    \"\"\"\n    asset_refs = []\n\n    for asset_ref in data.get(\"asset_references\", []):\n        if isinstance(asset_ref, Mapping):\n            asset_ref = AssetReference.from_dict(asset_ref)\n        asset_refs.append(asset_ref)\n\n    return cls(\n        title=data.get(\"title\"),\n        description=data.get(\"description\"),\n        asset_references=asset_refs,\n    )\n</code></pre>"},{"location":"api-reference/scene/#mosaico.scene.Scene.from_dict(data)","title":"<code>data</code>","text":""},{"location":"api-reference/scene/#mosaico.scene.Scene.add_asset_references","title":"add_asset_references","text":"<pre><code>add_asset_references(\n    references: AssetReference | Sequence[AssetReference],\n) -&gt; Scene\n</code></pre> <p>Add asset references to the scene.</p> <p>Parameters:</p> Name Type Description Default <code>AssetReference | Sequence[AssetReference]</code> <p>The asset references to add.</p> required <p>Returns:</p> Type Description <code>Scene</code> <p>The scene.</p> Source code in <code>src/mosaico/scene.py</code> <pre><code>def add_asset_references(self, references: AssetReference | Sequence[AssetReference]) -&gt; Scene:\n    \"\"\"\n    Add asset references to the scene.\n\n    :param references: The asset references to add.\n    :return: The scene.\n    \"\"\"\n    references = references if isinstance(references, Sequence) else [references]\n    self.asset_references.extend(references)\n    return self\n</code></pre>"},{"location":"api-reference/scene/#mosaico.scene.Scene.add_asset_references(references)","title":"<code>references</code>","text":""},{"location":"api-reference/scene/#mosaico.scene.Scene.remove_asset_id_references","title":"remove_asset_id_references","text":"<pre><code>remove_asset_id_references(asset_id: str) -&gt; Scene\n</code></pre> <p>Remove asset references by asset ID.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The asset ID to remove.</p> required <p>Returns:</p> Type Description <code>Scene</code> <p>The scene.</p> Source code in <code>src/mosaico/scene.py</code> <pre><code>def remove_asset_id_references(self, asset_id: str) -&gt; Scene:\n    \"\"\"\n    Remove asset references by asset ID.\n\n    :param asset_id: The asset ID to remove.\n    :return: The scene.\n    \"\"\"\n    self.asset_references = [ref for ref in self.asset_references if ref.asset_id != asset_id]\n    return self\n</code></pre>"},{"location":"api-reference/scene/#mosaico.scene.Scene.remove_asset_id_references(asset_id)","title":"<code>asset_id</code>","text":""},{"location":"api-reference/scene/#mosaico.scene.Scene.with_subtitle_params","title":"with_subtitle_params","text":"<pre><code>with_subtitle_params(\n    params: TextAssetParams | Mapping[str, Any],\n) -&gt; Scene\n</code></pre> <p>Add subtitle asset params to the scene.</p> <p>Parameters:</p> Name Type Description Default <code>TextAssetParams | Mapping[str, Any]</code> <p>The subtitle asset params.</p> required <p>Returns:</p> Type Description <code>Scene</code> <p>The scene.</p> Source code in <code>src/mosaico/scene.py</code> <pre><code>def with_subtitle_params(self, params: TextAssetParams | Mapping[str, Any]) -&gt; Scene:\n    \"\"\"\n    Add subtitle asset params to the scene.\n\n    :param params: The subtitle asset params.\n    :return: The scene.\n    \"\"\"\n    for ref in self.asset_references:\n        if ref.asset_type == \"subtitle\":\n            ref.asset_params = TextAssetParams.model_validate(params)\n    return self\n</code></pre>"},{"location":"api-reference/scene/#mosaico.scene.Scene.with_subtitle_params(params)","title":"<code>params</code>","text":""},{"location":"api-reference/assets/","title":"Assets","text":""},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset","title":"BaseAsset","text":"<p>               Bases: <code>Media</code>, <code>Generic[_ParamsType, _InfoType]</code></p> <p>Represents an assets with various properties.</p>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str\n</code></pre> <p>The type of the assets.</p>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params: _ParamsType\n</code></pre> <p>The parameters for the assets.</p>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.info","title":"info  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>info: _InfoType | None = None\n</code></pre> <p>Information associated with the asset type.</p>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.from_media","title":"from_media  <code>classmethod</code>","text":"<pre><code>from_media(media: Media) -&gt; Self\n</code></pre> <p>Creates an assets from a media object.</p> <p>Parameters:</p> Name Type Description Default <code>Media</code> <p>The media object.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The assets.</p> Source code in <code>src/mosaico/assets/base.py</code> <pre><code>@classmethod\ndef from_media(cls, media: Media) -&gt; Self:\n    \"\"\"\n    Creates an assets from a media object.\n\n    :param media: The media object.\n    :return: The assets.\n    \"\"\"\n    return cls(**media.model_dump())\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.from_media(media)","title":"<code>media</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: Mapping[str, Any]) -&gt; Self\n</code></pre> <p>Creates an assets from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>Mapping[str, Any]</code> <p>The dictionary data.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The assets.</p> Source code in <code>src/mosaico/assets/base.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Mapping[str, Any]) -&gt; Self:\n    \"\"\"\n    Creates an assets from a dictionary.\n\n    :param data: The dictionary data.\n    :return: The assets.\n    \"\"\"\n    return cls.model_validate(data)\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.from_dict(data)","title":"<code>data</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.validate_params","title":"validate_params  <code>classmethod</code>","text":"<pre><code>validate_params(params: Any) -&gt; _ParamsType\n</code></pre> <p>Validates the parameters for the assets.</p> <p>Parameters:</p> Name Type Description Default <code>Any</code> <p>The parameters to validate.</p> required <p>Returns:</p> Type Description <code>_ParamsType</code> <p>The validated parameters.</p> Source code in <code>src/mosaico/assets/base.py</code> <pre><code>@classmethod\ndef validate_params(cls, params: Any) -&gt; _ParamsType:\n    \"\"\"\n    Validates the parameters for the assets.\n\n    :param params: The parameters to validate.\n    :return: The validated parameters.\n    \"\"\"\n    params_cls = cls.model_fields[\"params\"].annotation\n    params_cls = cast(type[_ParamsType], params_cls)\n    return params_cls.model_validate(params)\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.validate_params(params)","title":"<code>params</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.with_params","title":"with_params","text":"<pre><code>with_params(params: _ParamsType | dict[str, Any]) -&gt; Self\n</code></pre> <p>Returns a new assets with the specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>_ParamsType | dict[str, Any]</code> <p>The parameters to update.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new assets with the specified parameters.</p> Source code in <code>src/mosaico/assets/base.py</code> <pre><code>def with_params(self, params: _ParamsType | dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Returns a new assets with the specified parameters.\n\n    :param params: The parameters to update.\n    :return: A new assets with the specified parameters.\n    \"\"\"\n    if isinstance(params, BaseModel):\n        params = params.model_dump(exclude_unset=True)\n\n    existing_params = self.params.model_dump(exclude_unset=True)\n    existing_params.update(params)\n\n    self.params = self.validate_params(existing_params)\n\n    return self\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.base.BaseAsset.with_params(params)","title":"<code>params</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.types.AssetType","title":"AssetType  <code>module-attribute</code>","text":"<pre><code>AssetType = Literal[\n    \"video\", \"image\", \"audio\", \"text\", \"subtitle\"\n]\n</code></pre> <p>An enumeration of the different types of assets that can be held in an assets.</p>"},{"location":"api-reference/assets/#mosaico.assets.types.Asset","title":"Asset  <code>module-attribute</code>","text":"<pre><code>Asset = AudioAsset | ImageAsset | TextAsset | SubtitleAsset\n</code></pre> <p>Represents an assets with various properties.</p>"},{"location":"api-reference/assets/#mosaico.assets.types.AssetParams","title":"AssetParams  <code>module-attribute</code>","text":"<pre><code>AssetParams = (\n    AudioAssetParams | ImageAssetParams | TextAssetParams\n)\n</code></pre> <p>Represents the parameters of an assets.</p>"},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset","title":"create_asset","text":"<pre><code>create_asset(\n    asset_type: Literal[\"image\"],\n    id: str | None = ...,\n    data: str | bytes | None = ...,\n    path: FilePath | None = ...,\n    metadata: dict[str, Any] | None = ...,\n    params: ImageAssetParams | None = ...,\n    **kwargs: Any\n) -&gt; ImageAsset\n</code></pre><pre><code>create_asset(\n    asset_type: Literal[\"audio\"],\n    id: str | None = ...,\n    data: str | bytes | None = ...,\n    path: FilePath | None = ...,\n    metadata: dict[str, Any] | None = ...,\n    params: AudioAssetParams | None = ...,\n    **kwargs: Any\n) -&gt; AudioAsset\n</code></pre><pre><code>create_asset(\n    asset_type: Literal[\"text\"],\n    id: str | None = ...,\n    data: str | bytes | None = ...,\n    path: FilePath | None = ...,\n    metadata: dict[str, Any] | None = ...,\n    params: TextAssetParams | None = ...,\n    **kwargs: Any\n) -&gt; TextAsset\n</code></pre><pre><code>create_asset(\n    asset_type: Literal[\"subtitle\"],\n    id: str | None = ...,\n    data: str | bytes | None = ...,\n    path: FilePath | None = ...,\n    metadata: dict[str, Any] | None = ...,\n    params: TextAssetParams | None = ...,\n    **kwargs: Any\n) -&gt; SubtitleAsset\n</code></pre><pre><code>create_asset(\n    asset_type: AssetType,\n    id: str | None = ...,\n    data: str | bytes | None = ...,\n    path: FilePath | None = ...,\n    metadata: dict[str, Any] | None = ...,\n    params: AssetParams | None = ...,\n    **kwargs: Any\n) -&gt; Asset\n</code></pre> <pre><code>create_asset(\n    asset_type: AssetType,\n    id: str | None = None,\n    data: str | bytes | None = None,\n    path: FilePath | None = None,\n    metadata: dict[str, Any] | None = None,\n    params: AssetParams | dict[str, Any] | None = None,\n    **kwargs: Any\n) -&gt; Asset\n</code></pre> <p>Create an asset from the given asset type.</p> <p>Parameters:</p> Name Type Description Default <code>AssetType</code> <p>The asset type.</p> required <code>str | None</code> <p>The asset ID.</p> <code>None</code> <code>str | bytes | None</code> <p>The asset data.</p> <code>None</code> <code>FilePath | None</code> <p>The asset path.</p> <code>None</code> <code>dict[str, Any] | None</code> <p>The asset metadata. ;param params: The asset parameters.</p> <code>None</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Asset</code> <p>The asset.</p> Source code in <code>src/mosaico/assets/factory.py</code> <pre><code>def create_asset(\n    asset_type: AssetType,\n    id: str | None = None,\n    data: str | bytes | None = None,\n    path: FilePath | None = None,\n    metadata: dict[str, Any] | None = None,\n    params: AssetParams | dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; Asset:\n    \"\"\"\n    Create an asset from the given asset type.\n\n    :param asset_type: The asset type.\n    :param id: The asset ID.\n    :param data: The asset data.\n    :param path: The asset path.\n    :param metadata: The asset metadata.\n    ;param params: The asset parameters.\n    :param kwargs: Additional keyword arguments.\n    :return: The asset.\n    \"\"\"\n    asset_mod_name = f\"mosaico.assets.{asset_type}\"\n\n    if not importlib.util.find_spec(asset_mod_name):\n        raise InvalidAssetTypeError(asset_type)\n\n    asset_mod = importlib.import_module(f\"mosaico.assets.{asset_type}\")\n    asset_class = getattr(asset_mod, asset_type.capitalize() + \"Asset\")\n\n    def _get_asset_class_default_params(asset_class: type[Asset]) -&gt; AssetParams:\n        params_field = asset_class.model_fields[\"params\"]\n        params_factory = params_field.default_factory\n        if params_factory is None:\n            raise ValueError(f\"Asset class '{asset_class.__name__}' does not have a default params factory.\")\n        return params_factory()\n\n    def _merge_params_with_dict(params: AssetParams, params_dict: dict[str, Any]) -&gt; AssetParams:\n        new_params = params.__class__.model_validate(params_dict)\n        for field_name in new_params.model_fields_set:\n            setattr(params, field_name, getattr(new_params, field_name))\n        return params\n\n    if params is not None:\n        if isinstance(params, dict):\n            default_params = _get_asset_class_default_params(asset_class)\n            params = _merge_params_with_dict(default_params, params)\n\n        kwargs[\"params\"] = params\n\n    if id is not None:\n        kwargs[\"id\"] = id\n\n    if metadata is not None:\n        kwargs[\"metadata\"] = metadata\n\n    if data is not None:\n        return asset_class.from_data(data, path=path, **kwargs)\n\n    if path is None:\n        msg = \"Either 'data' or 'path' must be provided.\"\n        raise ValueError(msg)\n\n    return asset_class.from_path(path, **kwargs)\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset(asset_type)","title":"<code>asset_type</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset(id)","title":"<code>id</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset(data)","title":"<code>data</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset(path)","title":"<code>path</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset(metadata)","title":"<code>metadata</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.factory.create_asset(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.factory.get_asset_params_class","title":"get_asset_params_class","text":"<pre><code>get_asset_params_class(\n    asset_type: Literal[\"image\"],\n) -&gt; type[ImageAssetParams]\n</code></pre><pre><code>get_asset_params_class(\n    asset_type: Literal[\"audio\"],\n) -&gt; type[AudioAssetParams]\n</code></pre><pre><code>get_asset_params_class(\n    asset_type: Literal[\"text\"],\n) -&gt; type[TextAssetParams]\n</code></pre><pre><code>get_asset_params_class(\n    asset_type: Literal[\"subtitle\"],\n) -&gt; type[TextAssetParams]\n</code></pre><pre><code>get_asset_params_class(\n    asset_type: AssetType,\n) -&gt; type[AssetParams]\n</code></pre> <pre><code>get_asset_params_class(\n    asset_type: AssetType,\n) -&gt; type[AssetParams]\n</code></pre> <p>Get the asset parameters class for the given asset type.</p> <p>Parameters:</p> Name Type Description Default <code>AssetType</code> <p>The asset type.</p> required <p>Returns:</p> Type Description <code>type[AssetParams]</code> <p>The asset parameters class.</p> Source code in <code>src/mosaico/assets/factory.py</code> <pre><code>def get_asset_params_class(asset_type: AssetType) -&gt; type[AssetParams]:\n    \"\"\"\n    Get the asset parameters class for the given asset type.\n\n    :param asset_type: The asset type.\n    :return: The asset parameters class.\n    \"\"\"\n    if asset_type == \"subtitle\":\n        asset_type = \"text\"\n\n    asset_mod_name = f\"mosaico.assets.{asset_type}\"\n\n    if not importlib.util.find_spec(asset_mod_name):\n        raise InvalidAssetTypeError(asset_type)\n\n    asset_mod = importlib.import_module(asset_mod_name)\n    asset_params_class = getattr(asset_mod, f\"{asset_type.capitalize()}AssetParams\")\n\n    return asset_params_class\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.factory.get_asset_params_class(asset_type)","title":"<code>asset_type</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.utils.convert_media_to_asset","title":"convert_media_to_asset","text":"<pre><code>convert_media_to_asset(media: Media) -&gt; Asset\n</code></pre> <p>Convert a media object to an asset.</p> <p>Parameters:</p> Name Type Description Default <code>Media</code> <p>The media object to convert.</p> required <p>Returns:</p> Type Description <code>Asset</code> <p>The asset object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the media object does not have a MIME type or the MIME type is unsupported.</p> Source code in <code>src/mosaico/assets/utils.py</code> <pre><code>def convert_media_to_asset(media: Media) -&gt; Asset:\n    \"\"\"\n    Convert a media object to an asset.\n\n    :param media: The media object to convert.\n    :return: The asset object.\n    :raises ValueError: If the media object does not have a MIME type or the MIME type is unsupported.\n    \"\"\"\n    if media.mime_type is None:\n        raise ValueError(\"Media object does not have a MIME type.\")\n    asset_type = guess_asset_type_from_mime_type(media.mime_type)\n    return create_asset(asset_type, **media.model_dump())\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.utils.convert_media_to_asset(media)","title":"<code>media</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.utils.guess_asset_type_from_mime_type","title":"guess_asset_type_from_mime_type","text":"<pre><code>guess_asset_type_from_mime_type(\n    mime_type: str,\n) -&gt; AssetType\n</code></pre> <p>Guess the asset type from a MIME type.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The MIME type to guess the asset type from.</p> required <p>Returns:</p> Type Description <code>AssetType</code> <p>The asset type.</p> Source code in <code>src/mosaico/assets/utils.py</code> <pre><code>def guess_asset_type_from_mime_type(mime_type: str) -&gt; AssetType:\n    \"\"\"\n    Guess the asset type from a MIME type.\n\n    :param mime_type: The MIME type to guess the asset type from.\n    :return: The asset type.\n    \"\"\"\n    if mime_type.startswith(\"audio/\"):\n        return \"audio\"\n    if mime_type.startswith(\"image/\"):\n        return \"image\"\n    if mime_type.startswith(\"text/\"):\n        return \"text\"\n    raise ValueError(f\"Unsupported MIME type: {mime_type}\")\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.utils.guess_asset_type_from_mime_type(mime_type)","title":"<code>mime_type</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.utils.check_user_provided_required_keys","title":"check_user_provided_required_keys","text":"<pre><code>check_user_provided_required_keys(\n    data: dict, required_keys: Sequence[str]\n) -&gt; bool\n</code></pre> <p>Check if the user provided all required keys.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>The data to check.</p> required <code>Sequence[str]</code> <p>The required keys.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the user provided all required keys.</p> Source code in <code>src/mosaico/assets/utils.py</code> <pre><code>def check_user_provided_required_keys(data: dict, required_keys: Sequence[str]) -&gt; bool:\n    \"\"\"\n    Check if the user provided all required keys.\n\n    :param data: The data to check.\n    :param required_keys: The required keys.\n    :return: Whether the user provided all required keys.\n    \"\"\"\n    return set(required_keys).issubset(data.keys())\n</code></pre>"},{"location":"api-reference/assets/#mosaico.assets.utils.check_user_provided_required_keys(data)","title":"<code>data</code>","text":""},{"location":"api-reference/assets/#mosaico.assets.utils.check_user_provided_required_keys(required_keys)","title":"<code>required_keys</code>","text":""},{"location":"api-reference/assets/audio/","title":"Audio","text":""},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioInfo","title":"AudioInfo","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the audio specific metadata.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioInfo.duration","title":"duration  <code>instance-attribute</code>","text":"<pre><code>duration: PositiveFloat\n</code></pre> <p>The duration of the audio asset.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioInfo.sample_rate","title":"sample_rate  <code>instance-attribute</code>","text":"<pre><code>sample_rate: PositiveFloat\n</code></pre> <p>The sample rate of the audio asset.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioInfo.sample_width","title":"sample_width  <code>instance-attribute</code>","text":"<pre><code>sample_width: NonNegativeInt\n</code></pre> <p>The sample width of the audio asset.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioInfo.channels","title":"channels  <code>instance-attribute</code>","text":"<pre><code>channels: NonNegativeInt\n</code></pre> <p>The number of channels in the audio asset.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAssetParams","title":"AudioAssetParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the parameters for an Audio assets.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAssetParams.volume","title":"volume  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>volume: float = Field(default=1.0)\n</code></pre> <p>The volume of the audio assets.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAssetParams.crop","title":"crop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>crop: tuple[int, int] | None = None\n</code></pre> <p>Crop range for the audio assets</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset","title":"AudioAsset","text":"<p>               Bases: <code>BaseAsset[AudioAssetParams, AudioInfo]</code></p> <p>Represents an Audio asset with various properties.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['audio'] = 'audio'\n</code></pre> <p>The type of the asset. Defaults to \"audio\".</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: AudioAssetParams = Field(\n    default_factory=AudioAssetParams\n)\n</code></pre> <p>The parameters for the asset.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: float\n</code></pre> <p>The duration of the audio asset.</p> <p>Wrapper of <code>AudioAsset.info.duration</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.sample_rate","title":"sample_rate  <code>property</code>","text":"<pre><code>sample_rate: float\n</code></pre> <p>The sample rate of the audio asset.</p> <p>Wrapper of <code>AudioAsset.info.sample_rate</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.sample_width","title":"sample_width  <code>property</code>","text":"<pre><code>sample_width: int\n</code></pre> <p>The sample width of the audio asset.</p> <p>Wrapper of <code>AudioAsset.info.sample_width</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.channels","title":"channels  <code>property</code>","text":"<pre><code>channels: int\n</code></pre> <p>The number of channels in the audio asset.</p> <p>Wrapper of <code>AudioAsset.info.channels</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.to_audio_segment","title":"to_audio_segment","text":"<pre><code>to_audio_segment(**kwargs) -&gt; AudioSegment\n</code></pre> <p>Casts the audio asset to a pydub.AudioSegment object.</p> Source code in <code>src/mosaico/assets/audio.py</code> <pre><code>def to_audio_segment(self, **kwargs) -&gt; AudioSegment:\n    \"\"\"\n    Casts the audio asset to a pydub.AudioSegment object.\n    \"\"\"\n    with self.to_bytes_io(**kwargs) as audio_buf:\n        return AudioSegment.from_file(\n            file=audio_buf,\n            sample_width=self.sample_width,\n            frame_rate=self.sample_rate,\n            channels=self.channels,\n        )\n</code></pre>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.slice","title":"slice","text":"<pre><code>slice(\n    start_time: float, end_time: float, **kwargs: Any\n) -&gt; AudioAsset\n</code></pre> <p>Slices the audio asset.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>The start time in seconds.</p> required <code>float</code> <p>The end time in seconds.</p> required <code>Any</code> <p>Additional parameters passed to the audio loader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>AudioAsset</code> <p>The sliced audio asset.</p> Source code in <code>src/mosaico/assets/audio.py</code> <pre><code>def slice(self, start_time: float, end_time: float, **kwargs: Any) -&gt; AudioAsset:\n    \"\"\"\n    Slices the audio asset.\n\n    :param start_time: The start time in seconds.\n    :param end_time: The end time in seconds.\n    :param kwargs: Additional parameters passed to the audio loader.\n    :return: The sliced audio asset.\n    \"\"\"\n    audio = self.to_audio_segment(**kwargs)\n\n    sliced_buf = io.BytesIO()\n    sliced_audio = cast(AudioSegment, audio[round(start_time * 1000) : round(end_time * 1000)])\n    sliced_audio.export(sliced_buf, format=\"mp3\")\n    sliced_buf.seek(0)\n\n    return AudioAsset.from_data(\n        sliced_buf.read(),\n        info=AudioInfo(\n            duration=len(sliced_audio) / 1000,\n            sample_rate=self.sample_rate,\n            sample_width=self.sample_width,\n            channels=self.channels,\n        ),\n    )\n</code></pre>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.slice(start_time)","title":"<code>start_time</code>","text":""},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.slice(end_time)","title":"<code>end_time</code>","text":""},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.slice(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.strip_silence","title":"strip_silence","text":"<pre><code>strip_silence(\n    silence_threshold: float = -50,\n    chunk_size: int = 10,\n    **kwargs: Any\n) -&gt; AudioAsset\n</code></pre> <p>Removes leading and trailing silence from the audio asset.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Silence threshold in dBFS (default: -50.0).</p> <code>-50</code> <code>int</code> <p>Size of the audio iterator chunk, in ms (default: 10).</p> <code>10</code> <code>Any</code> <p>Additional parameters passed to the audio loader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>AudioAsset</code> <p>A new AudioAsset with leading and trailing silence removed.</p> Source code in <code>src/mosaico/assets/audio.py</code> <pre><code>def strip_silence(self, silence_threshold: float = -50, chunk_size: int = 10, **kwargs: Any) -&gt; AudioAsset:\n    \"\"\"\n    Removes leading and trailing silence from the audio asset.\n\n    :param silence_threshold: Silence threshold in dBFS (default: -50.0).\n    :param chunk_size: Size of the audio iterator chunk, in ms (default: 10).\n    :param kwargs: Additional parameters passed to the audio loader.\n    :return: A new AudioAsset with leading and trailing silence removed.\n    \"\"\"\n    audio = self.to_audio_segment(**kwargs)\n    start_trim = detect_leading_silence(audio, silence_threshold, chunk_size)\n    end_trim = detect_leading_silence(audio.reverse(), silence_threshold, chunk_size)\n    return self.slice(start_trim / 1000, (len(audio) - end_trim) / 1000)\n</code></pre>"},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.strip_silence(silence_threshold)","title":"<code>silence_threshold</code>","text":""},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.strip_silence(chunk_size)","title":"<code>chunk_size</code>","text":""},{"location":"api-reference/assets/audio/#mosaico.assets.audio.AudioAsset.strip_silence(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/assets/image/","title":"Image","text":""},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageInfo","title":"ImageInfo","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an image metadata information.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageInfo.width","title":"width  <code>instance-attribute</code>","text":"<pre><code>width: NonNegativeInt\n</code></pre> <p>The width of the image, in pixels.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageInfo.height","title":"height  <code>instance-attribute</code>","text":"<pre><code>height: NonNegativeInt\n</code></pre> <p>The height of the image, in pixels.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageInfo.mode","title":"mode  <code>instance-attribute</code>","text":"<pre><code>mode: str\n</code></pre> <p>Image mode.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAssetParams","title":"ImageAssetParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the parameters for an image assets.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAssetParams.position","title":"position  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>position: Position = Field(default_factory=AbsolutePosition)\n</code></pre> <p>The positioning of the text assets in the video.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAssetParams.z_index","title":"z_index  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>z_index: int = -1\n</code></pre> <p>The z-index of the assets.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAssetParams.crop","title":"crop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>crop: tuple[int, int, int, int] | None = None\n</code></pre> <p>The crop range for the image assets.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAssetParams.as_background","title":"as_background  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>as_background: bool = True\n</code></pre> <p>Whether the image should be used as a background.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset","title":"ImageAsset","text":"<p>               Bases: <code>BaseAsset[ImageAssetParams, ImageInfo]</code></p> <p>Represents an image assets with various properties.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['image'] = 'image'\n</code></pre> <p>The type of the assets. Defaults to \"image\".</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: ImageAssetParams = Field(\n    default_factory=ImageAssetParams\n)\n</code></pre> <p>The parameters for the assets.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset.width","title":"width  <code>property</code>","text":"<pre><code>width: int\n</code></pre> <p>The width of the image, in pixels.</p> <p>Wrapper of <code>ImageAsset.info.width</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset.height","title":"height  <code>property</code>","text":"<pre><code>height: int\n</code></pre> <p>The height of the image, in pixels.</p> <p>Wrapper of <code>ImageAsset.info.height</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset.mode","title":"mode  <code>property</code>","text":"<pre><code>mode: str\n</code></pre> <p>Image mode.</p> <p>Wrapper of <code>ImageAsset.info.mode</code> for convenience and type-hint compatibility.</p>"},{"location":"api-reference/assets/image/#mosaico.assets.image.ImageAsset.size","title":"size  <code>property</code>","text":"<pre><code>size: FrameSize\n</code></pre> <p>Image dimensions as a tuple.</p>"},{"location":"api-reference/assets/subtitle/","title":"Subtitle","text":""},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset","title":"SubtitleAsset","text":"<p>               Bases: <code>BaseTextAsset</code></p> <p>Represents a subtitles assets.</p>"},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['subtitle'] = 'subtitle'\n</code></pre> <p>The type of the assets. Defaults to \"subtitle\".</p>"},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: TextAssetParams = Field(\n    default_factory=lambda: TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\"),\n        font_color=Color(\"white\"),\n        font_size=45,\n        stroke_width=1,\n        align=\"center\",\n        shadow_blur=10,\n        shadow_angle=135,\n        shadow_opacity=0.5,\n        shadow_distance=5,\n    )\n)\n</code></pre> <p>The parameters for the assets.</p>"},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset.check_position_is_region","title":"check_position_is_region  <code>classmethod</code>","text":"<pre><code>check_position_is_region(\n    params: TextAssetParams,\n) -&gt; TextAssetParams\n</code></pre> <p>Validate that the subtitle positioning is of type RegionPosition.</p> Source code in <code>src/mosaico/assets/subtitle.py</code> <pre><code>@field_validator(\"params\", mode=\"after\")\n@classmethod\ndef check_position_is_region(cls, params: TextAssetParams) -&gt; TextAssetParams:\n    \"\"\"\n    Validate that the subtitle positioning is of type RegionPosition.\n    \"\"\"\n    if not is_region_position(params.position):\n        raise ValueError(\"Subtitle positioning must be of type RegionPosition\")\n    if not params.position.x == \"center\":\n        raise ValueError(\"Subtitle x position must be 'center'\")\n    return params\n</code></pre>"},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset.from_shot","title":"from_shot  <code>classmethod</code>","text":"<pre><code>from_shot(shot: Shot, **kwargs: Any) -&gt; SubtitleAsset\n</code></pre> <p>Create a SubtitleAsset from a Shot.</p> <p>Parameters:</p> Name Type Description Default <code>Shot</code> <p>The shot to create the asset from.</p> required <code>Any</code> <p>Additional parameters for the asset.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SubtitleAsset</code> <p>The created asset.</p> Source code in <code>src/mosaico/assets/subtitle.py</code> <pre><code>@classmethod\ndef from_shot(cls, shot: Shot, **kwargs: Any) -&gt; SubtitleAsset:\n    \"\"\"\n    Create a SubtitleAsset from a Shot.\n\n    :param shot: The shot to create the asset from.\n    :param kwargs: Additional parameters for the asset.\n    :return: The created asset.\n    \"\"\"\n    return cls.from_data(shot.subtitle, **kwargs)\n</code></pre>"},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset.from_shot(shot)","title":"<code>shot</code>","text":""},{"location":"api-reference/assets/subtitle/#mosaico.assets.subtitle.SubtitleAsset.from_shot(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/assets/text/","title":"Text","text":""},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams","title":"TextAssetParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the parameters for a text assets.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.position","title":"position  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>position: Position = Field(default_factory=AbsolutePosition)\n</code></pre> <p>The positioning of the text assets in the video.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.font_family","title":"font_family  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>font_family: str | None = None\n</code></pre> <p>The font family.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.font_size","title":"font_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>font_size: NonNegativeInt = 70\n</code></pre> <p>The font size.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.font_color","title":"font_color  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>font_color: Color = Field(\n    default_factory=lambda: Color(\"#000000\")\n)\n</code></pre> <p>The font color hexadecimal code.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.font_kerning","title":"font_kerning  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>font_kerning: float = 0\n</code></pre> <p>The font kerning.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.line_height","title":"line_height  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>line_height: int = 10\n</code></pre> <p>The line height.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.stroke_color","title":"stroke_color  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>stroke_color: Color = Field(\n    default_factory=lambda: Color(\"#000000\")\n)\n</code></pre> <p>The font stroke color hexadecimal code.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.stroke_width","title":"stroke_width  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>stroke_width: NonNegativeFloat = 0\n</code></pre> <p>The font stroke width.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.shadow_color","title":"shadow_color  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shadow_color: Color = Field(\n    default_factory=lambda: Color(\"#000000\")\n)\n</code></pre> <p>The shadow color hexadecimal code.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.shadow_blur","title":"shadow_blur  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shadow_blur: int = 0\n</code></pre> <p>The shadow blur.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.shadow_opacity","title":"shadow_opacity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shadow_opacity: Annotated[float, Field(ge=0, le=1)] = 1\n</code></pre> <p>The shadow opacity.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.shadow_angle","title":"shadow_angle  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shadow_angle: int = 0\n</code></pre> <p>The shadow angle.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.shadow_distance","title":"shadow_distance  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shadow_distance: NonNegativeInt = 0\n</code></pre> <p>The shadow distance.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.background_color","title":"background_color  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>background_color: Color = Field(\n    default_factory=lambda: Color(\"transparent\")\n)\n</code></pre> <p>The background color hexadecimal code.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.align","title":"align  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>align: Literal['left', 'center', 'right'] = 'left'\n</code></pre> <p>The text alignment.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.z_index","title":"z_index  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>z_index: int = 0\n</code></pre> <p>The z-index of the assets.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAssetParams.serialize_color","title":"serialize_color","text":"<pre><code>serialize_color(value: Color) -&gt; str\n</code></pre> <p>Serialize the color to its hexadecimal code.</p> Source code in <code>src/mosaico/assets/text.py</code> <pre><code>@field_serializer(\"font_color\", \"stroke_color\", \"shadow_color\", \"background_color\", when_used=\"always\")\ndef serialize_color(self, value: Color) -&gt; str:\n    \"\"\"Serialize the color to its hexadecimal code.\"\"\"\n    return value.as_hex()\n</code></pre>"},{"location":"api-reference/assets/text/#mosaico.assets.text.BaseTextAsset","title":"BaseTextAsset","text":"<p>               Bases: <code>BaseAsset[TextAssetParams, None]</code></p> <p>Represents a text assets with various properties.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.BaseTextAsset.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: TextAssetParams = Field(\n    default_factory=TextAssetParams\n)\n</code></pre> <p>The parameters for the text assets.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.BaseTextAsset.has_background","title":"has_background  <code>property</code>","text":"<pre><code>has_background: bool\n</code></pre> <p>Check if the text asset has a background.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.BaseTextAsset.has_shadow","title":"has_shadow  <code>property</code>","text":"<pre><code>has_shadow: bool\n</code></pre> <p>Check if the text asset has a shadow.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAsset","title":"TextAsset","text":"<p>               Bases: <code>BaseTextAsset</code></p> <p>Represents a text assets with various properties.</p>"},{"location":"api-reference/assets/text/#mosaico.assets.text.TextAsset.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['text'] = 'text'\n</code></pre> <p>\u00a8The type of the assets. Defaults to \"text\".</p>"},{"location":"api-reference/audio-transcribers/","title":"Audio Transcribers","text":""},{"location":"api-reference/audio-transcribers/#mosaico.audio_transcribers.protocol.AudioTranscriber","title":"AudioTranscriber","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol defining the interface for audio transcription services.</p> <p>This protocol specifies the contract that all audio transcribers in the Mosaico project should adhere to. It defines a single method, :meth:<code>transcribe</code>, which takes an audio asset and returns a transcription.</p> <p>Implementations of this protocol can use various transcription technologies, such as speech-to-text APIs, local models, or custom algorithms. The protocol ensures a consistent interface regardless of the underlying implementation.</p> <p>Note</p> <p>This is a runtime checkable protocol, which means <code>isinstance()</code> and <code>issubclass()</code> checks can be performed against it.</p> <p>Example:</p> <pre><code>    class MyTranscriber:\n        def transcribe(self, audio_asset: AudioAsset) -&gt; Transcription:\n            # Implement transcription logic here\n            ...\n\n    transcriber: AudioTranscriber = MyTranscriber()\n    transcription = transcriber.transcribe(my_audio_asset)\n</code></pre>"},{"location":"api-reference/audio-transcribers/#mosaico.audio_transcribers.protocol.AudioTranscriber.transcribe","title":"transcribe","text":"<pre><code>transcribe(audio_asset: AudioAsset) -&gt; Transcription\n</code></pre> <p>Transcribe speech from an audio asset to text.</p> <p>This method should implement the core logic for converting speech in the provided audio asset into text. The specific implementation can vary based on the transcription technology being used.</p> <p>Parameters:</p> Name Type Description Default <code>AudioAsset</code> <p>The audio asset containing the speech to be transcribed.</p> required <p>Returns:</p> Type Description <code>Transcription</code> <p>A Transcription object containing the text transcription of the speech.  .. note:: The implementation should handle various audio formats and durations as defined by the :class:<code>AudioAsset</code> class. It should also be able to handle potential errors gracefully.</p> Source code in <code>src/mosaico/audio_transcribers/protocol.py</code> <pre><code>def transcribe(self, audio_asset: AudioAsset) -&gt; Transcription:\n    \"\"\"\n    Transcribe speech from an audio asset to text.\n\n    This method should implement the core logic for converting speech in the\n    provided audio asset into text. The specific implementation can vary\n    based on the transcription technology being used.\n\n    :param audio_asset: The audio asset containing the speech to be transcribed.\n    :return: A Transcription object containing the text transcription of the speech.\n\n    .. note::\n       The implementation should handle various audio formats and durations\n       as defined by the :class:`AudioAsset` class. It should also be able to handle\n       potential errors gracefully.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/audio-transcribers/#mosaico.audio_transcribers.protocol.AudioTranscriber.transcribe(audio_asset)","title":"<code>audio_asset</code>","text":""},{"location":"api-reference/audio-transcribers/assemblyai/","title":"AssemblyAI","text":""},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber","title":"AssemblyAIAudioTranscriber","text":"<p>               Bases: <code>BaseModel</code></p> <p>Transcriber using AssemblyAI's API.</p>"},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre> <p>API key for AssemblyAI.</p>"},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: Literal['best', 'nano'] = 'best'\n</code></pre> <p>Model to use for transcription.</p>"},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber.language","title":"language  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>language: LanguageAlpha2 | None = None\n</code></pre> <p>Language of the transcription.</p>"},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber.custom_spelling","title":"custom_spelling  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>custom_spelling: dict[str, str | Sequence[str]] | None = (\n    None\n)\n</code></pre> <p>Custom spelling dictionary for the transcription.</p>"},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber.transcribe","title":"transcribe","text":"<pre><code>transcribe(audio_asset: AudioAsset) -&gt; Transcription\n</code></pre> <p>Transcribe audio using AssemblyAI's API.</p> <p>Parameters:</p> Name Type Description Default <code>AudioAsset</code> required <p>Returns:</p> Type Description <code>Transcription</code> <p>The transcription.</p> Source code in <code>src/mosaico/audio_transcribers/assemblyai.py</code> <pre><code>def transcribe(self, audio_asset: AudioAsset) -&gt; Transcription:\n    \"\"\"\n    Transcribe audio using AssemblyAI's API.\n\n    :param audio_asset:\n    :return: The transcription.\n    \"\"\"\n    try:\n        import assemblyai as aai\n    except ImportError:\n        raise ImportError(\"AssemblyAI package is required for AssemblyAIAudioTranscriber.\")\n\n    config = aai.TranscriptionConfig(\n        speech_model=aai.SpeechModel(self.model),\n        language_code=str(self.language) if self.language else None,\n        language_detection=self.language is None,\n        custom_spelling=self.custom_spelling,\n        punctuate=True,\n        format_text=True,\n    )\n\n    transcriber = aai.Transcriber(client=self._client, config=config)\n\n    with audio_asset.to_bytes_io() as audio_file:\n        response = transcriber.transcribe(audio_file)  # type: ignore\n\n    transcription = response.wait_for_completion()\n\n    if transcription.words is None:\n        raise ValueError(\"No word timestamps found in transcription.\")\n\n    return Transcription(\n        words=[\n            TranscriptionWord(start_time=word.start / 1000, end_time=word.end / 1000, text=word.text)\n            for word in transcription.words\n        ]\n    )\n</code></pre>"},{"location":"api-reference/audio-transcribers/assemblyai/#mosaico.audio_transcribers.assemblyai.AssemblyAIAudioTranscriber.transcribe(audio_asset)","title":"<code>audio_asset</code>","text":""},{"location":"api-reference/audio-transcribers/openai/","title":"OpenAI","text":""},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber","title":"OpenAIWhisperTranscriber","text":"<p>               Bases: <code>BaseModel</code></p> <p>Transcriber using OpenAI's Whisper API.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre> <p>API key for OpenAI's Whisper API.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.base_url","title":"base_url  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>base_url: str | None = None\n</code></pre> <p>Base URL for OpenAI's Whisper API.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: PositiveInt = 120\n</code></pre> <p>Timeout for transcription in seconds.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: Literal['whisper-1'] = 'whisper-1'\n</code></pre> <p>Model to use for transcription.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.temperature","title":"temperature  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>temperature: ModelTemperature = 0\n</code></pre> <p>The sampling temperature for the model.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.language","title":"language  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>language: LanguageAlpha2 | None = None\n</code></pre> <p>Language of the transcription.</p>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.transcribe","title":"transcribe","text":"<pre><code>transcribe(audio_asset: AudioAsset) -&gt; Transcription\n</code></pre> <p>Transcribe audio using OpenAI's Whisper API.</p> <p>Parameters:</p> Name Type Description Default <code>AudioAsset</code> <p>The audio asset to transcribe.</p> required <p>Returns:</p> Type Description <code>Transcription</code> <p>The transcription words.</p> Source code in <code>src/mosaico/audio_transcribers/openai.py</code> <pre><code>def transcribe(self, audio_asset: AudioAsset) -&gt; Transcription:\n    \"\"\"\n    Transcribe audio using OpenAI's Whisper API.\n\n    :param audio_asset: The audio asset to transcribe.\n    :return: The transcription words.\n    \"\"\"\n    with audio_asset.to_bytes_io() as audio_file:\n        audio_file.name = f\"{audio_asset.id}.mp3\"  # type: ignore\n        response = self._client.audio.transcriptions.create(\n            file=audio_file,\n            model=self.model,\n            temperature=self.temperature,\n            language=str(self.language) if self.language is not None else \"\",\n            response_format=\"verbose_json\",\n            timestamp_granularities=[\"word\"],\n        )\n\n    if not response.words:\n        raise ValueError(\"No words found in transcription response.\")\n\n    words = [TranscriptionWord(start_time=word.start, end_time=word.end, text=word.word) for word in response.words]\n\n    return Transcription(words=words)\n</code></pre>"},{"location":"api-reference/audio-transcribers/openai/#mosaico.audio_transcribers.openai.OpenAIWhisperTranscriber.transcribe(audio_asset)","title":"<code>audio_asset</code>","text":""},{"location":"api-reference/clip-makers/","title":"Clip Makers","text":""},{"location":"api-reference/clip-makers/#mosaico.clip_makers.protocol.ClipMaker","title":"ClipMaker","text":"<p>               Bases: <code>Protocol[T_contra]</code></p> <p>A protocol for clip makers.</p>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.protocol.ClipMaker.make_clip","title":"make_clip","text":"<pre><code>make_clip(asset: T_contra) -&gt; Clip\n</code></pre> <p>Make a clip from the given asset.</p> Source code in <code>src/mosaico/clip_makers/protocol.py</code> <pre><code>def make_clip(self, asset: T_contra) -&gt; Clip:\n    \"\"\"\n    Make a clip from the given asset.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.base.BaseClipMaker","title":"BaseClipMaker","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code>, <code>ABC</code></p> <p>Base class for clip makers.</p>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.base.BaseClipMaker.duration","title":"duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>duration: PositiveFloat | None = None\n</code></pre> <p>The duration of the clip in seconds.</p>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.base.BaseClipMaker.video_resolution","title":"video_resolution  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>video_resolution: FrameSize | None = None\n</code></pre> <p>The resolution of the video.</p>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.base.BaseClipMaker.effects","title":"effects  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>effects: list[Effect] = Field(default_factory=list)\n</code></pre> <p>List of effects to apply to the clip.</p>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.base.BaseClipMaker.make_clip","title":"make_clip","text":"<pre><code>make_clip(asset: T) -&gt; Clip\n</code></pre> <p>Make a clip from the given clip, duration and video resolution.</p> <p>:asset: The asset to make the clip from. :duration: The duration of the clip in seconds. :video_resolution: The resolution of the video.</p> <p>Returns:</p> Type Description <code>Clip</code> <p>The clip.</p> Source code in <code>src/mosaico/clip_makers/base.py</code> <pre><code>def make_clip(self, asset: T) -&gt; Clip:\n    \"\"\"\n    Make a clip from the given clip, duration and video resolution.\n\n    :asset: The asset to make the clip from.\n    :duration: The duration of the clip in seconds.\n    :video_resolution: The resolution of the video.\n    :return: The clip.\n    \"\"\"\n    clip = self._make_clip(asset)\n\n    for effect in self.effects:\n        clip = effect.apply(clip)\n\n    return clip\n</code></pre>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.factory.get_clip_maker_class","title":"get_clip_maker_class","text":"<pre><code>get_clip_maker_class(\n    asset_type: Literal[\"text\"],\n) -&gt; type[ClipMaker[TextAsset]]\n</code></pre><pre><code>get_clip_maker_class(\n    asset_type: Literal[\"subtitle\"],\n) -&gt; type[ClipMaker[SubtitleAsset]]\n</code></pre><pre><code>get_clip_maker_class(\n    asset_type: Literal[\"audio\"],\n) -&gt; type[ClipMaker[AudioAsset]]\n</code></pre><pre><code>get_clip_maker_class(\n    asset_type: Literal[\"image\"],\n) -&gt; type[ClipMaker[ImageAsset]]\n</code></pre><pre><code>get_clip_maker_class(\n    asset_type: AssetType,\n) -&gt; type[ClipMaker]\n</code></pre> <pre><code>get_clip_maker_class(\n    asset_type: AssetType,\n) -&gt; type[ClipMaker]\n</code></pre> <p>Get a clip maker class.</p> <p>Parameters:</p> Name Type Description Default <code>AssetType</code> <p>The assets type.</p> required <p>Returns:</p> Type Description <code>type[ClipMaker]</code> <p>The clip maker class.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no clip maker is found for the given assets type and name.</p> Source code in <code>src/mosaico/clip_makers/factory.py</code> <pre><code>def get_clip_maker_class(asset_type: AssetType) -&gt; type[ClipMaker]:\n    \"\"\"\n    Get a clip maker class.\n\n    :param asset_type: The assets type.\n    :return: The clip maker class.\n    :raises ValueError: If no clip maker is found for the given assets type and name.\n    \"\"\"\n    cm_mod_name = f\"mosaico.clip_makers.{asset_type}\"\n\n    if not importlib.util.find_spec(cm_mod_name):\n        raise InvalidAssetTypeError(asset_type)\n\n    cm_mod = importlib.import_module(f\"mosaico.clip_makers.{asset_type}\")\n    cm_class = getattr(cm_mod, asset_type.capitalize() + \"ClipMaker\")\n\n    return cm_class\n</code></pre>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.factory.get_clip_maker_class(asset_type)","title":"<code>asset_type</code>","text":""},{"location":"api-reference/clip-makers/#mosaico.clip_makers.factory.make_clip","title":"make_clip","text":"<pre><code>make_clip(\n    asset: Asset,\n    duration: float | None = None,\n    video_resolution: FrameSize | None = None,\n    effects: Sequence[Effect] | None = None,\n    **kwargs: Any\n) -&gt; Clip\n</code></pre> <p>Make a clip from the given asset.</p> <p>Parameters:</p> Name Type Description Default <code>Asset</code> <p>The asset.</p> required <code>float | None</code> <p>The duration of the clip.</p> <code>None</code> <code>FrameSize | None</code> <p>The resolution of the video.</p> <code>None</code> <p>Returns:</p> Type Description <code>Clip</code> <p>The clip.</p> Source code in <code>src/mosaico/clip_makers/factory.py</code> <pre><code>def make_clip(\n    asset: Asset,\n    duration: float | None = None,\n    video_resolution: FrameSize | None = None,\n    effects: Sequence[Effect] | None = None,\n    **kwargs: Any,\n) -&gt; Clip:\n    \"\"\"\n    Make a clip from the given asset.\n\n    :param asset: The asset.\n    :param duration: The duration of the clip.\n    :param video_resolution: The resolution of the video.\n    :return: The clip.\n    \"\"\"\n    clip_maker_cls = get_clip_maker_class(asset.type)\n    clip_maker_cls = cast(type[BaseClipMaker], clip_maker_cls)\n    clip_maker = clip_maker_cls(\n        duration=duration,\n        video_resolution=video_resolution,\n        effects=list(effects) if effects is not None else [],\n        **kwargs,\n    )\n    return clip_maker.make_clip(asset)\n</code></pre>"},{"location":"api-reference/clip-makers/#mosaico.clip_makers.factory.make_clip(asset)","title":"<code>asset</code>","text":""},{"location":"api-reference/clip-makers/#mosaico.clip_makers.factory.make_clip(duration)","title":"<code>duration</code>","text":""},{"location":"api-reference/clip-makers/#mosaico.clip_makers.factory.make_clip(video_resolution)","title":"<code>video_resolution</code>","text":""},{"location":"api-reference/clip-makers/audio/","title":"Audio","text":""},{"location":"api-reference/clip-makers/audio/#mosaico.clip_makers.audio.AudioClipMaker","title":"AudioClipMaker","text":"<p>               Bases: <code>BaseClipMaker[AudioAsset]</code></p> <p>A clip maker for audio assets.</p> <p>The audio clip maker performs these transformations:</p> <ol> <li>Loads raw audio data into PyDub format</li> <li>Crops if needed to match clip duration</li> <li>Exports audio to temporary MP3 file</li> </ol> <p>Examples:</p> <pre><code># Create a basic audio clip\nmaker = AudioClipMaker(duration=5.0)\nclip = maker.make_clip(audio_asset)\n\n# Create clip with custom duration\nclip = maker.make_clip(audio_asset, duration=10.0)\n</code></pre>"},{"location":"api-reference/clip-makers/image/","title":"Image","text":""},{"location":"api-reference/clip-makers/image/#mosaico.clip_makers.image.ImageClipMaker","title":"ImageClipMaker","text":"<p>               Bases: <code>BaseClipMaker[ImageAsset]</code></p> <p>A clip maker for image assets.</p> <p>The image clip maker performs these transformations:</p> <ol> <li>Loads raw image data into OpenCV format</li> <li>Resizes/crops if needed to match video resolution</li> <li>Creates temporary image file</li> <li>Constructs MoviePy ImageClip with:<ul> <li>Image data from temp file</li> <li>Position from asset params</li> <li>Duration from clip maker config</li> </ul> </li> </ol> <p>Examples:</p> <pre><code># Create a basic image clip\nmaker = ImageClipMaker(duration=5.0, video_resolution=(1920, 1080))\nclip = maker.make_clip(image_asset)\n\n# Create clip with background resize\nimage_asset.params.as_background = True\nclip = maker.make_clip(image_asset)  # Will resize to match resolution\n\n# Create clip with custom position\nimage_asset.params.position = AbsolutePosition(x=100, y=50)\nclip = maker.make_clip(image_asset)  # Will position at x=100, y=50\n</code></pre>"},{"location":"api-reference/clip-makers/subtitle/","title":"Subtitle","text":""},{"location":"api-reference/clip-makers/subtitle/#mosaico.clip_makers.subtitle.SubtitleClipMaker","title":"SubtitleClipMaker","text":"<p>               Bases: <code>TextClipMaker</code></p> <p>A clip maker for subtitle assets.</p> <p>The subtitle clip maker performs these transformations:</p> <ol> <li>Execute the text clip maker process</li> <li>Position the subtitle at the top, bottom, or center of the video</li> <li>Return the subtitle clip</li> </ol> <p>Note</p> <p>For further details, refer to the TextClipMaker documentation.</p> <p>Examples:</p> <pre><code># Create a basic subtitle clip\nmaker = SubtitleClipMaker(duration=5.0, video_resolution=(1920, 1080))\nclip = maker.make_clip(subtitle_asset)\n</code></pre>"},{"location":"api-reference/clip-makers/text/","title":"Text","text":""},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.TextClipMaker","title":"TextClipMaker","text":"<p>               Bases: <code>BaseClipMaker[BaseTextAsset]</code></p> <p>A clip maker for text assets.</p> <p>The process of text clip creation involves:</p> <ol> <li> <p>Font and Text Preparation:</p> <ul> <li>Loads system fonts using the specified font family</li> <li>Wraps text to fit within video width</li> <li>Calculates text dimensions</li> </ul> </li> <li> <p>Shadow Creation (if enabled):</p> <ul> <li>Generates shadow layer with specified angle and distance</li> <li>Applies blur effect and opacity</li> <li>Handles shadow color and positioning</li> </ul> </li> <li> <p>Text Rendering:</p> <ul> <li>Creates text layer with specified font and color</li> <li>Applies stroke/outline effects</li> <li>Handles text alignment and line height</li> <li>Supports RGBA colors with transparency</li> </ul> </li> <li> <p>Image Composition:</p> <ul> <li>Combines shadow and text layers if shadow enabled</li> <li>Crops image to text boundaries</li> <li>Creates temporary PNG file for MoviePy</li> </ul> </li> <li> <p>Clip Creation:</p> <ul> <li>Converts rendered image to MoviePy clip</li> <li>Sets position based on text parameters</li> <li>Applies specified duration</li> </ul> </li> </ol> <p>Examples:</p> <pre><code># Create a basic text clip\nmaker = TextClipMaker(duration=5.0, video_resolution=(1920, 1080))\nclip = maker.make_clip(text_asset)\n\n# Create clip with shadow\ntext_asset.params.has_shadow = True\nclip = maker.make_clip(text_asset)  # Will add shadow effect\n\n# Create clip with custom position\ntext_asset.params.position = AbsolutePosition(x=100, y=50)\nclip = maker.make_clip(text_asset)  # Will position at x=100, y=50\n\n# Create clip with custom font size\ntext_asset.params.font_size = 48\nclip = maker.make_clip(text_asset)  # Will render text with font size 48\n</code></pre>"},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.SystemFont","title":"SystemFont  <code>dataclass</code>","text":"<pre><code>SystemFont(path: str)\n</code></pre> <p>System font representation.</p>"},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.SystemFont.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: str\n</code></pre> <p>The path to the font file in the system.</p>"},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.SystemFont.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get the font name.</p>"},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.SystemFont.slug","title":"slug  <code>property</code>","text":"<pre><code>slug: str\n</code></pre> <p>Get the slugified font name.</p>"},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.SystemFont.matches","title":"matches","text":"<pre><code>matches(name: str) -&gt; bool\n</code></pre> <p>Check if the font name matches the given name.</p> Source code in <code>src/mosaico/clip_makers/text.py</code> <pre><code>def matches(self, name: str) -&gt; bool:\n    \"\"\"\n    Check if the font name matches the given name.\n    \"\"\"\n    return self.name == name or self.slug == _slugify_font_name(name)\n</code></pre>"},{"location":"api-reference/clip-makers/text/#mosaico.clip_makers.text.SystemFont.load","title":"load","text":"<pre><code>load(size: float) -&gt; FreeTypeFont\n</code></pre> <p>Load the font.</p> Source code in <code>src/mosaico/clip_makers/text.py</code> <pre><code>def load(self, size: float) -&gt; ImageFont.FreeTypeFont:\n    \"\"\"\n    Load the font.\n    \"\"\"\n    return ImageFont.truetype(self.path, size)\n</code></pre>"},{"location":"api-reference/effects/","title":"Effects","text":""},{"location":"api-reference/effects/#mosaico.effects.protocol.Effect","title":"Effect","text":"<p>               Bases: <code>Protocol[ClipType]</code></p> <p>A protocol for clip effects.</p> <p>Note</p> <p>This is a runtime checkable protocol, which means <code>isinstance()</code> and <code>issubclass()</code> checks can be performed against it.</p>"},{"location":"api-reference/effects/#mosaico.effects.protocol.Effect.apply","title":"apply","text":"<pre><code>apply(clip: ClipType) -&gt; ClipType\n</code></pre> <p>Apply the effect to the clip.</p> Source code in <code>src/mosaico/effects/protocol.py</code> <pre><code>def apply(self, clip: ClipType) -&gt; ClipType:\n    \"\"\"Apply the effect to the clip.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/effects/#mosaico.effects.types.VideoEffect","title":"VideoEffect  <code>module-attribute</code>","text":"<pre><code>VideoEffect = (\n    ZoomInEffect\n    | ZoomOutEffect\n    | PanLeftEffect\n    | PanRightEffect\n    | PanUpEffect\n    | PanDownEffect\n    | FadeInEffect\n    | FadeOutEffect\n    | CrossFadeInEffect\n    | CrossFadeOutEffect\n)\n</code></pre> <p>A type representing any video effect.</p>"},{"location":"api-reference/effects/#mosaico.effects.types.VideoEffectType","title":"VideoEffectType  <code>module-attribute</code>","text":"<pre><code>VideoEffectType = Literal[\n    \"zoom_in\",\n    \"zoom_out\",\n    \"pan_left\",\n    \"pan_right\",\n    \"pan_up\",\n    \"pan_down\",\n    \"fade_in\",\n    \"fade_out\",\n    \"crossfade_out\",\n    \"crossfade_in\",\n]\n</code></pre> <p>A type representing the type of a video effect.</p>"},{"location":"api-reference/effects/pan/","title":"Pan","text":""},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanFn","title":"PanFn  <code>module-attribute</code>","text":"<pre><code>PanFn = Callable[\n    [float], tuple[float, str] | tuple[str, float]\n]\n</code></pre> <p>The pan function type.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.BasePanEffect","title":"BasePanEffect","text":"<p>               Bases: <code>BaseModel</code></p> <p>A pan effect.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.BasePanEffect.zoom_factor","title":"zoom_factor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>zoom_factor: PositiveFloat = 1.1\n</code></pre> <p>The zoom factor.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.BasePanEffect.apply","title":"apply","text":"<pre><code>apply(clip: VideoClip) -&gt; VideoClip\n</code></pre> <p>Apply the pan effect to the clip.</p> <p>Parameters:</p> Name Type Description Default <code>VideoClip</code> <p>The clip.</p> required <p>Returns:</p> Type Description <code>VideoClip</code> <p>The clip with the effect applied.</p> Source code in <code>src/mosaico/effects/pan.py</code> <pre><code>def apply(self, clip: VideoClip) -&gt; VideoClip:\n    \"\"\"\n    Apply the pan effect to the clip.\n\n    :param clip: The clip.\n    :return: The clip with the effect applied.\n    \"\"\"\n    pan_fn = self._pan_fn(clip)\n    return clip.with_effects([vfx.Resize(self.zoom_factor)]).with_position(pan_fn)  # type: ignore\n</code></pre>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.BasePanEffect.apply(clip)","title":"<code>clip</code>","text":""},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanRightEffect","title":"PanRightEffect","text":"<p>               Bases: <code>BasePanEffect</code></p> <p>A left to right pan effect.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanRightEffect.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['pan_right'] = 'pan_right'\n</code></pre> <p>Effect type. Must be \"pan_right\".</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanLeftEffect","title":"PanLeftEffect","text":"<p>               Bases: <code>BasePanEffect</code></p> <p>A right to left pan effect.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanLeftEffect.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['pan_left'] = 'pan_left'\n</code></pre> <p>Effect type. Must be \"pan_left\".</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanDownEffect","title":"PanDownEffect","text":"<p>               Bases: <code>BasePanEffect</code></p> <p>A top to bottom pan effect.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanDownEffect.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['pan_down'] = 'pan_down'\n</code></pre> <p>Effect type. Must be \"pan_down\".</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanUpEffect","title":"PanUpEffect","text":"<p>               Bases: <code>BasePanEffect</code></p> <p>A bottom to top pan effect.</p>"},{"location":"api-reference/effects/pan/#mosaico.effects.pan.PanUpEffect.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['pan_up'] = 'pan_up'\n</code></pre> <p>Effect type. Must be \"pan_up\".</p>"},{"location":"api-reference/effects/zoom/","title":"Zoom","text":""},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.BaseZoomEffect","title":"BaseZoomEffect","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for zoom effects.</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.BaseZoomEffect.start_zoom","title":"start_zoom  <code>instance-attribute</code>","text":"<pre><code>start_zoom: Annotated[float, Field(ge=0.1, le=2)]\n</code></pre> <p>Starting zoom scale (1.0 is original size).</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.BaseZoomEffect.end_zoom","title":"end_zoom  <code>instance-attribute</code>","text":"<pre><code>end_zoom: Annotated[float, Field(ge=0.1, le=2.0)]\n</code></pre> <p>Ending zoom scale.</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.BaseZoomEffect.apply","title":"apply","text":"<pre><code>apply(clip: VideoClip) -&gt; VideoClip\n</code></pre> <p>Apply zoom effect to clip.</p> <p>Parameters:</p> Name Type Description Default <code>VideoClip</code> <p>The clip to apply the effect to.</p> required <p>Returns:</p> Type Description <code>VideoClip</code> <p>The clip with the effect applied.</p> Source code in <code>src/mosaico/effects/zoom.py</code> <pre><code>def apply(self, clip: VideoClip) -&gt; VideoClip:\n    \"\"\"\n    Apply zoom effect to clip.\n\n    :param clip: The clip to apply the effect to.\n    :return: The clip with the effect applied.\n    \"\"\"\n\n    def zoom(t):\n        \"\"\"Calculate zoom factor at time t.\"\"\"\n        progress = t / clip.duration\n        return self.start_zoom + (self.end_zoom - self.start_zoom) * progress\n\n    return clip.with_effects([vfx.Resize(zoom)])  # type: ignore\n</code></pre>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.BaseZoomEffect.apply(clip)","title":"<code>clip</code>","text":""},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomInEffect","title":"ZoomInEffect","text":"<p>               Bases: <code>BaseZoomEffect</code></p> <p>Zoom-in effect for video clips.</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomInEffect.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['zoom_in'] = 'zoom_in'\n</code></pre> <p>Effect type. Must be \"zoom_in\".</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomInEffect.start_zoom","title":"start_zoom  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.0\n</code></pre> <p>Starting zoom scale (1.0 is original size).</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomInEffect.end_zoom","title":"end_zoom  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.1\n</code></pre> <p>Ending zoom scale.</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomOutEffect","title":"ZoomOutEffect","text":"<p>               Bases: <code>BaseZoomEffect</code></p> <p>Zoom-out effect for video clips.</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomOutEffect.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['zoom_out'] = 'zoom_out'\n</code></pre> <p>Effect type. Must be \"zoom_out\".</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomOutEffect.start_zoom","title":"start_zoom  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.5\n</code></pre> <p>Starting zoom scale (1.5 times the original size).</p>"},{"location":"api-reference/effects/zoom/#mosaico.effects.zoom.ZoomOutEffect.end_zoom","title":"end_zoom  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.4\n</code></pre> <p>Ending zoom scale.</p>"},{"location":"api-reference/positioning/","title":"Positioning","text":""},{"location":"api-reference/positioning/#mosaico.positioning.types.PositionType","title":"PositionType  <code>module-attribute</code>","text":"<pre><code>PositionType = Literal['absolute', 'relative', 'region']\n</code></pre> <p>An enumeration of the different types of positions that can be held in an assets.</p>"},{"location":"api-reference/positioning/#mosaico.positioning.types.Position","title":"Position  <code>module-attribute</code>","text":"<pre><code>Position = Union[\n    AbsolutePosition, RelativePosition, RegionPosition\n]\n</code></pre> <p>Represents a positioning of an assets in the frame.</p>"},{"location":"api-reference/positioning/#mosaico.positioning.utils.convert_position_to_absolute","title":"convert_position_to_absolute","text":"<pre><code>convert_position_to_absolute(\n    position: Position, frame_size: FrameSize\n) -&gt; AbsolutePosition\n</code></pre> <p>Convert a relative position to an absolute position.</p> <p>Parameters:</p> Name Type Description Default <code>Position</code> <p>The position to be converted.</p> required <code>FrameSize</code> <p>The size of the frame.</p> required <p>Returns:</p> Type Description <code>AbsolutePosition</code> <p>The converted absolute positioning object.</p> Source code in <code>src/mosaico/positioning/utils.py</code> <pre><code>def convert_position_to_absolute(position: Position, frame_size: FrameSize) -&gt; AbsolutePosition:\n    \"\"\"\n    Convert a relative position to an absolute position.\n\n    :param position: The position to be converted.\n    :param frame_size: The size of the frame.\n    :return: The converted absolute positioning object.\n    \"\"\"\n    if isinstance(position, AbsolutePosition):\n        return position\n\n    if isinstance(position, RelativePosition):\n        return AbsolutePosition.from_relative(position, frame_size)\n\n    return AbsolutePosition.from_region(position, frame_size)\n</code></pre>"},{"location":"api-reference/positioning/#mosaico.positioning.utils.convert_position_to_absolute(position)","title":"<code>position</code>","text":""},{"location":"api-reference/positioning/#mosaico.positioning.utils.convert_position_to_absolute(frame_size)","title":"<code>frame_size</code>","text":""},{"location":"api-reference/positioning/#mosaico.positioning.utils.is_region_position","title":"is_region_position","text":"<pre><code>is_region_position(position: Position) -&gt; bool\n</code></pre> <p>Check if the position is a region position.</p> <p>Parameters:</p> Name Type Description Default <code>Position</code> <p>The position to be checked.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the position is a region position.</p> Source code in <code>src/mosaico/positioning/utils.py</code> <pre><code>def is_region_position(position: Position) -&gt; bool:\n    \"\"\"\n    Check if the position is a region position.\n\n    :param position: The position to be checked.\n    :return: Whether the position is a region position.\n    \"\"\"\n    return isinstance(position, RegionPosition)\n</code></pre>"},{"location":"api-reference/positioning/#mosaico.positioning.utils.is_region_position(position)","title":"<code>position</code>","text":""},{"location":"api-reference/positioning/#mosaico.positioning.utils.is_relative_position","title":"is_relative_position","text":"<pre><code>is_relative_position(position: Position) -&gt; bool\n</code></pre> <p>Check if the position is a relative position.</p> <p>Parameters:</p> Name Type Description Default <code>Position</code> <p>The position to be checked.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the position is a relative position.</p> Source code in <code>src/mosaico/positioning/utils.py</code> <pre><code>def is_relative_position(position: Position) -&gt; bool:\n    \"\"\"\n    Check if the position is a relative position.\n\n    :param position: The position to be checked.\n    :return: Whether the position is a relative position.\n    \"\"\"\n    return isinstance(position, RelativePosition)\n</code></pre>"},{"location":"api-reference/positioning/#mosaico.positioning.utils.is_relative_position(position)","title":"<code>position</code>","text":""},{"location":"api-reference/positioning/#mosaico.positioning.utils.is_absolute_position","title":"is_absolute_position","text":"<pre><code>is_absolute_position(position: Position) -&gt; bool\n</code></pre> <p>Check if the position is an absolute position.</p> <p>Parameters:</p> Name Type Description Default <code>Position</code> <p>The position to be checked.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the position is an absolute position.</p> Source code in <code>src/mosaico/positioning/utils.py</code> <pre><code>def is_absolute_position(position: Position) -&gt; bool:\n    \"\"\"\n    Check if the position is an absolute position.\n\n    :param position: The position to be checked.\n    :return: Whether the position is an absolute position.\n    \"\"\"\n    return isinstance(position, AbsolutePosition)\n</code></pre>"},{"location":"api-reference/positioning/#mosaico.positioning.utils.is_absolute_position(position)","title":"<code>position</code>","text":""},{"location":"api-reference/positioning/absolute/","title":"Absolute","text":""},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition","title":"AbsolutePosition","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an absolute positioning.</p>"},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['absolute'] = 'absolute'\n</code></pre> <p>The type of positioning. Defaults to \"absolute\".</p>"},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.x","title":"x  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>x: NonNegativeInt = 0\n</code></pre> <p>The x-coordinate of the assets.</p>"},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.y","title":"y  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>y: NonNegativeInt = 0\n</code></pre> <p>The y-coordinate of the assets.</p>"},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_relative","title":"from_relative  <code>classmethod</code>","text":"<pre><code>from_relative(\n    position: RelativePosition, frame_size: FrameSize\n) -&gt; AbsolutePosition\n</code></pre> <p>Creates an absolute positioning from a relative positioning.</p> <p>Parameters:</p> Name Type Description Default <code>RelativePosition</code> <p>The relative positioning.</p> required <code>FrameSize</code> <p>The size of the frame.</p> required <p>Returns:</p> Type Description <code>AbsolutePosition</code> <p>The absolute positioning.</p> Source code in <code>src/mosaico/positioning/absolute.py</code> <pre><code>@classmethod\ndef from_relative(cls, position: RelativePosition, frame_size: FrameSize) -&gt; AbsolutePosition:\n    \"\"\"\n    Creates an absolute positioning from a relative positioning.\n\n    :param position: The relative positioning.\n    :param frame_size: The size of the frame.\n    :return: The absolute positioning.\n    \"\"\"\n    frame_max_width, frame_max_height = frame_size\n    return cls(x=int(position.x * frame_max_width), y=int(position.y * frame_max_height))\n</code></pre>"},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_relative(position)","title":"<code>position</code>","text":""},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_relative(frame_size)","title":"<code>frame_size</code>","text":""},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_region","title":"from_region  <code>classmethod</code>","text":"<pre><code>from_region(\n    position: RegionPosition, frame_size: FrameSize\n) -&gt; AbsolutePosition\n</code></pre> <p>Creates an absolute positioning from a region positioning.</p> <p>Parameters:</p> Name Type Description Default <code>RegionPosition</code> <p>The region positioning.</p> required <p>The maximum width of the frame.</p> required <p>The maximum height of the frame.</p> required <p>Returns:</p> Type Description <code>AbsolutePosition</code> <p>The absolute positioning.</p> Source code in <code>src/mosaico/positioning/absolute.py</code> <pre><code>@classmethod\ndef from_region(cls, position: RegionPosition, frame_size: FrameSize) -&gt; AbsolutePosition:\n    \"\"\"\n    Creates an absolute positioning from a region positioning.\n\n    :param position: The region positioning.\n    :param frame_max_width: The maximum width of the frame.\n    :param frame_max_height: The maximum height of the frame.\n    :return: The absolute positioning.\n    \"\"\"\n    frame_max_width, frame_max_height = frame_size\n    x_map = {\"left\": 0, \"center\": frame_max_width // 2, \"right\": frame_max_width}\n    y_map = {\"top\": 0, \"center\": frame_max_height // 2, \"bottom\": frame_max_height}\n    return cls(x=x_map[position.x], y=y_map[position.y])\n</code></pre>"},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_region(position)","title":"<code>position</code>","text":""},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_region(frame_max_width)","title":"<code>frame_max_width</code>","text":""},{"location":"api-reference/positioning/absolute/#mosaico.positioning.absolute.AbsolutePosition.from_region(frame_max_height)","title":"<code>frame_max_height</code>","text":""},{"location":"api-reference/positioning/region/","title":"Region","text":""},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionX","title":"RegionX  <code>module-attribute</code>","text":"<pre><code>RegionX = Literal['left', 'center', 'right']\n</code></pre> <p>The possible region x-coordinates of the assets.</p>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionY","title":"RegionY  <code>module-attribute</code>","text":"<pre><code>RegionY = Literal['top', 'center', 'bottom']\n</code></pre> <p>The possible region y-coordinates of the assets.</p>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionPosition","title":"RegionPosition","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a region positioning.</p>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionPosition.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['region'] = 'region'\n</code></pre> <p>The type of positioning. Defaults to \"region\".</p>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionPosition.x","title":"x  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>x: RegionX = 'center'\n</code></pre> <p>The region x-coordinate of the assets.</p>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionPosition.y","title":"y  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>y: RegionY = 'center'\n</code></pre> <p>The region y-coordinate of the assets.</p>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionPosition.from_string","title":"from_string  <code>classmethod</code>","text":"<pre><code>from_string(string: str) -&gt; RegionPosition\n</code></pre> <p>Create a region position from a string.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The string to parse.</p> required <p>Returns:</p> Type Description <code>RegionPosition</code> <p>The region position.</p> Source code in <code>src/mosaico/positioning/region.py</code> <pre><code>@classmethod\ndef from_string(cls, string: str) -&gt; RegionPosition:\n    \"\"\"\n    Create a region position from a string.\n\n    :param string: The string to parse.\n    :return: The region position.\n    \"\"\"\n    if string not in {\"left\", \"center\", \"right\", \"top\", \"center\", \"bottom\"}:\n        raise ValueError(\"Invalid region position\")\n    if string in {\"left\", \"center\", \"right\"}:\n        return cls(x=cast(RegionX, string), y=\"center\")\n    if string in {\"top\", \"bottom\"}:\n        return cls(x=\"center\", y=cast(RegionY, string))\n    raise ValueError(\"Invalid region position\")\n</code></pre>"},{"location":"api-reference/positioning/region/#mosaico.positioning.region.RegionPosition.from_string(string)","title":"<code>string</code>","text":""},{"location":"api-reference/positioning/relative/","title":"Relative","text":""},{"location":"api-reference/positioning/relative/#mosaico.positioning.relative.RelativePosition","title":"RelativePosition","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a relative position.</p>"},{"location":"api-reference/positioning/relative/#mosaico.positioning.relative.RelativePosition.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal['relative'] = 'relative'\n</code></pre> <p>The type of position. Defaults to \"relative\".</p>"},{"location":"api-reference/positioning/relative/#mosaico.positioning.relative.RelativePosition.x","title":"x  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>x: NonNegativeFloat = 0.5\n</code></pre> <p>The x-coordinate of the assets.</p>"},{"location":"api-reference/positioning/relative/#mosaico.positioning.relative.RelativePosition.y","title":"y  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>y: NonNegativeFloat = 0.5\n</code></pre> <p>The y-coordinate of the assets.</p>"},{"location":"api-reference/script-generators/","title":"Script Generators","text":""},{"location":"api-reference/script-generators/#mosaico.script_generators.protocol.ScriptGenerator","title":"ScriptGenerator","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol for generating a shooting script from a list of media files.</p> <p>This protocol defines the interface for generating a shooting script for a project from a list of media objects. The <code>generate</code> method should be implemented by concrete classes and should fullfill the contract of this protocol by returning a shooting script containing the shots generated from the media files.</p> <p>Concrete implementations of the <code>ScriptGenerator</code> protocol can be used by the <code>VideoProjectBuilder</code> class to automatically generate a shooting script for a project, avoiding the need of a manually defined timeline.</p> <p>Note</p> <p>This is a runtime checkable protocol, which means <code>isinstance()</code> and <code>issubclass()</code> checks can be performed against it.</p> <p>Example:</p> <pre><code>class MyScriptGenerator:\n    def generate(self, media: Sequence[Media], **kwargs: Any) -&gt; ShootingScript:\n        # Implement script generation logic here\n        ...\n\ngenerator: ScriptGenerator = MyScriptGenerator()\nscript = generator.generate(my_media_files)\n</code></pre>"},{"location":"api-reference/script-generators/#mosaico.script_generators.protocol.ScriptGenerator.generate","title":"generate","text":"<pre><code>generate(\n    media: Sequence[Media], **kwargs: Any\n) -&gt; ShootingScript\n</code></pre> <p>Generate a shooting script from a list of media files.</p> <p>Parameters:</p> Name Type Description Default <code>Sequence[Media]</code> <p>The list of media objects.</p> required <code>Any</code> <p>Additional context for the script generation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ShootingScript</code> <p>The shooting script generated from the media files.</p> Source code in <code>src/mosaico/script_generators/protocol.py</code> <pre><code>def generate(self, media: Sequence[Media], **kwargs: Any) -&gt; ShootingScript:\n    \"\"\"\n    Generate a shooting script from a list of media files.\n\n    :param media: The list of media objects.\n    :param kwargs: Additional context for the script generation.\n    :return: The shooting script generated from the media files.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/script-generators/#mosaico.script_generators.protocol.ScriptGenerator.generate(media)","title":"<code>media</code>","text":""},{"location":"api-reference/script-generators/#mosaico.script_generators.protocol.ScriptGenerator.generate(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/script-generators/script/","title":"Script","text":""},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShotMediaReference","title":"ShotMediaReference","text":"<p>               Bases: <code>BaseModel</code></p> <p>A reference to a media object.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShotMediaReference.media_id","title":"media_id  <code>instance-attribute</code>","text":"<pre><code>media_id: str\n</code></pre> <p>The ID of the media object.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShotMediaReference.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['image', 'video']\n</code></pre> <p>The type of the media object.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShotMediaReference.start_time","title":"start_time  <code>instance-attribute</code>","text":"<pre><code>start_time: NonNegativeFloat\n</code></pre> <p>The start time of the media object in seconds.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShotMediaReference.end_time","title":"end_time  <code>instance-attribute</code>","text":"<pre><code>end_time: PositiveFloat\n</code></pre> <p>The end time of the media object in seconds.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShotMediaReference.effects","title":"effects  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>effects: list[VideoEffectType] = Field(default_factory=list)\n</code></pre> <p>The effects applied to the media object.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot","title":"Shot","text":"<p>               Bases: <code>BaseModel</code></p> <p>A shot for a script.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.number","title":"number  <code>instance-attribute</code>","text":"<pre><code>number: PositiveInt\n</code></pre> <p>The number of the shot.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre> <p>The description of the shot.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.subtitle","title":"subtitle  <code>instance-attribute</code>","text":"<pre><code>subtitle: str\n</code></pre> <p>The subtitle for the shot.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.media_references","title":"media_references  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>media_references: list[ShotMediaReference] = Field(\n    default_factory=list\n)\n</code></pre> <p>The media references for the shot.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.start_time","title":"start_time  <code>property</code>","text":"<pre><code>start_time: float\n</code></pre> <p>The start time of the shot in seconds.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.end_time","title":"end_time  <code>property</code>","text":"<pre><code>end_time: float\n</code></pre> <p>The end time of the shot in seconds.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.Shot.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: float\n</code></pre> <p>The duration of the shot in seconds.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShootingScript","title":"ShootingScript","text":"<p>               Bases: <code>BaseModel</code></p> <p>A shooting script for a video project.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShootingScript.title","title":"title  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>title: str = 'Untitled'\n</code></pre> <p>The title of the script.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShootingScript.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: str | None = None\n</code></pre> <p>The description of the script.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShootingScript.shots","title":"shots  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shots: list[Shot] = Field(default_factory=list)\n</code></pre> <p>The shots in the script.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShootingScript.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: float\n</code></pre> <p>The total duration of the script in seconds.</p>"},{"location":"api-reference/script-generators/script/#mosaico.script_generators.script.ShootingScript.shot_count","title":"shot_count  <code>property</code>","text":"<pre><code>shot_count: int\n</code></pre> <p>The number of shots in the script.</p>"},{"location":"api-reference/speech-synthesizers/","title":"Index","text":""},{"location":"api-reference/speech-synthesizers/#mosaico.speech_synthesizers.protocol.SpeechSynthesizer","title":"SpeechSynthesizer","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the interface for text-to-speech synthesis services.</p> <p>The SpeechSynthesizer protocol standardizes how text is converted to speech across different TTS providers (e.g., Google Cloud TTS, Azure Speech). Implementations of this protocol handle the specifics of communicating with TTS services and managing the generated audio assets.</p> <p>Implementations should handle:</p> <ul> <li>Authentication with the TTS service</li> <li>Rate limiting and quotas</li> <li>Error handling and retries</li> <li>Audio format conversion if necessary</li> <li>Temporary file management</li> <li>Resource cleanup</li> </ul> <p>Example:</p> <pre><code>class MySpeechSynthesizer(SpeechSynthesizer):\n    provider = \"my-provider\"\n\n    def synthesize(self, texts, audio_params=None):\n        # Implementation details\n        pass\n\nsynthesizer = MySpeechSynthesizer()\naudio_assets = synthesizer.synthesize(\n    texts=[\"Hello world\", \"Welcome to the demo\"],\n    audio_params=AudioAssetParams(volume=0.8)\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>provider</code> <code>str</code> <p>Identifier for the TTS service provider (e.g., \"openai\", \"assemblyai\", \"azure\"). This should be a unique string that identifies the implementation.</p>"},{"location":"api-reference/speech-synthesizers/#mosaico.speech_synthesizers.protocol.SpeechSynthesizer.provider","title":"provider  <code>class-attribute</code>","text":"<pre><code>provider: str\n</code></pre> <p>The provider of the speech synthesizer.</p>"},{"location":"api-reference/speech-synthesizers/#mosaico.speech_synthesizers.protocol.SpeechSynthesizer.synthesize","title":"synthesize","text":"<pre><code>synthesize(\n    texts: Sequence[str],\n    *,\n    audio_params: AudioAssetParams | None = None,\n    **kwargs: Any\n) -&gt; list[AudioAsset]\n</code></pre> <p>Convert a list of texts into synthesized speech audio assets.</p> <p>This method handles the conversion of text to speech, managing both the synthesis process and the creation of audio assets for use in video projects.</p> <p>Note</p> <ul> <li>The method should handle cleanup of any temporary files</li> <li>Audio assets should be properly configured with metadata</li> <li>Implementation should handle text normalization if needed</li> <li>Large texts may need to be chunked according to service limits</li> <li>Audio format should match project requirements</li> </ul> <p>Parameters:</p> Name Type Description Default <code>Sequence[str]</code> <p>List of text strings to be converted to speech. Each string should be properly formatted text ready for synthesis.</p> required <code>AudioAssetParams | None</code> <p>Optional parameters for configuring the output audio assets. If None, default parameters will be used. These parameters affect properties like sample rate, channels, etc.</p> <code>None</code> <code>Any</code> <p>Additional provider-specific parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[AudioAsset]</code> <p>List of audio assets containing the synthesized speech. The returned list will have the same length as the input texts list, with corresponding indices.</p> Source code in <code>src/mosaico/speech_synthesizers/protocol.py</code> <pre><code>def synthesize(\n    self, texts: Sequence[str], *, audio_params: AudioAssetParams | None = None, **kwargs: Any\n) -&gt; list[AudioAsset]:\n    \"\"\"\n    Convert a list of texts into synthesized speech audio assets.\n\n    This method handles the conversion of text to speech, managing both the synthesis\n    process and the creation of audio assets for use in video projects.\n\n\n    !!! note\n        * The method should handle cleanup of any temporary files\n        * Audio assets should be properly configured with metadata\n        * Implementation should handle text normalization if needed\n        * Large texts may need to be chunked according to service limits\n        * Audio format should match project requirements\n\n    :param texts: List of text strings to be converted to speech. Each string should\n        be properly formatted text ready for synthesis.\n    :param audio_params: Optional parameters for configuring the output audio assets.\n        If None, default parameters will be used. These parameters affect properties\n        like sample rate, channels, etc.\n    :param kwargs: Additional provider-specific parameters.\n    :return: List of audio assets containing the synthesized speech. The returned list\n        will have the same length as the input texts list, with corresponding indices.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/speech-synthesizers/#mosaico.speech_synthesizers.protocol.SpeechSynthesizer.synthesize(texts)","title":"<code>texts</code>","text":""},{"location":"api-reference/speech-synthesizers/#mosaico.speech_synthesizers.protocol.SpeechSynthesizer.synthesize(audio_params)","title":"<code>audio_params</code>","text":""},{"location":"api-reference/speech-synthesizers/#mosaico.speech_synthesizers.protocol.SpeechSynthesizer.synthesize(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/speech-synthesizers/elevenlabs/","title":"ElevenLabs","text":""},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer","title":"ElevenLabsSpeechSynthesizer","text":"<p>               Bases: <code>BaseModel</code></p> <p>Speech synthesizer for ElevenLabs.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.provider","title":"provider  <code>class-attribute</code>","text":"<pre><code>provider: str = 'elevenlabs'\n</code></pre> <p>Provider name for ElevenLabs.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre> <p>API key for ElevenLabs.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.voice_id","title":"voice_id  <code>instance-attribute</code>","text":"<pre><code>voice_id: str\n</code></pre> <p>Voice ID for ElevenLabs.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.voice_stability","title":"voice_stability  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>voice_stability: Annotated[float, Field(ge=0, le=1)] = 0.5\n</code></pre> <p>Voice stability for the synthesized speech. It ranges from 0 to 1. Default is 0.5.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.voice_similarity_boost","title":"voice_similarity_boost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>voice_similarity_boost: Annotated[\n    float, Field(ge=0, le=1)\n] = 0.5\n</code></pre> <p>Voice similarity boost for the synthesized speech. It ranges from 0 to 1. Default is 0.5.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.voice_style","title":"voice_style  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>voice_style: Annotated[float, Field(ge=0, le=1)] = 0.5\n</code></pre> <p>Voice style for the synthesized speech. It ranges from 0 to 1. Default is 0.5.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.voice_speaker_boost","title":"voice_speaker_boost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>voice_speaker_boost: bool = True\n</code></pre> <p>Voice speaker boost for the synthesized speech. Default is True.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.voice_speed","title":"voice_speed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>voice_speed: Annotated[float, Field(ge=0.7, le=1.2)] = 1\n</code></pre> <p>The generated speech speed.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.language_code","title":"language_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>language_code: LanguageAlpha2 = Field(\n    default_factory=lambda: LanguageAlpha2(\"en\")\n)\n</code></pre> <p>Language code of the text to synthesize. If not provided, it defaults to \"en\".</p> <p>Check the ElevenLabs API documentation for the list of supported languages by model. https://help.elevenlabs.io/hc/en-us/articles/17883183930129-What-models-do-you-offer-and-what-is-the-difference-between-them</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: Literal[\n    \"eleven_turbo_v2_5\",\n    \"eleven_turbo_v2\",\n    \"eleven_multilingual_v2\",\n    \"eleven_monolingual_v1\",\n    \"eleven_multilingual_v1\",\n] = \"eleven_multilingual_v2\"\n</code></pre> <p>Model ID for ElevenLabs.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 120\n</code></pre> <p>Timeout for the HTTP request in seconds.</p>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.synthesize","title":"synthesize","text":"<pre><code>synthesize(\n    texts: Sequence[str],\n    *,\n    audio_params: AudioAssetParams | None = None,\n    **kwargs: Any\n) -&gt; list[AudioAsset]\n</code></pre> <p>Synthesizes the given texts into audio assets using the ElevenLabs API.</p> <p>Parameters:</p> Name Type Description Default <code>Sequence[str]</code> <p>List of texts to synthesize.</p> required <code>AudioAssetParams | None</code> <p>Audio parameters for the synthesized audio assets.</p> <code>None</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[AudioAsset]</code> <p>List of synthesized audio assets.</p> Source code in <code>src/mosaico/speech_synthesizers/elevenlabs.py</code> <pre><code>def synthesize(\n    self, texts: Sequence[str], *, audio_params: AudioAssetParams | None = None, **kwargs: Any\n) -&gt; list[AudioAsset]:\n    \"\"\"\n    Synthesizes the given texts into audio assets using the ElevenLabs API.\n\n    :param texts: List of texts to synthesize.\n    :param audio_params: Audio parameters for the synthesized audio assets.\n    :param kwargs: Additional keyword arguments.\n    :return: List of synthesized audio assets.\n    \"\"\"\n    assets = []\n    previous_request_ids = []\n\n    for i, text in enumerate(texts):\n        is_first = i == 0\n        is_last = i == len(texts) - 1\n        response = self._fetch_speech_synthesis(\n            text=text,\n            previous_request_ids=previous_request_ids[-3:],\n            previous_text=None if is_first else \" \".join(texts[:i]),\n            next_text=None if is_last else \" \".join(texts[i + 1 :]),\n        )\n        previous_request_ids.append(response.headers[\"request-id\"])\n        duration = AudioSegment.from_file(io.BytesIO(response.content), format=\"mp3\").duration_seconds\n        asset = AudioAsset.from_data(\n            response.content,\n            params=audio_params if audio_params is not None else {},\n            mime_type=\"audio/mpeg\",\n            info=AudioInfo(\n                duration=duration,\n                sample_rate=44100,\n                sample_width=128,\n                channels=1,\n            ),\n        )\n        assets.append(asset)\n\n    return assets\n</code></pre>"},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.synthesize(texts)","title":"<code>texts</code>","text":""},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.synthesize(audio_params)","title":"<code>audio_params</code>","text":""},{"location":"api-reference/speech-synthesizers/elevenlabs/#mosaico.speech_synthesizers.elevenlabs.ElevenLabsSpeechSynthesizer.synthesize(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/speech-synthesizers/openai/","title":"OpenAI","text":""},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAITTSVoice","title":"OpenAITTSVoice  <code>module-attribute</code>","text":"<pre><code>OpenAITTSVoice = Literal[\n    \"alloy\",\n    \"ash\",\n    \"ballad\",\n    \"echo\",\n    \"coral\",\n    \"fable\",\n    \"onyx\",\n    \"nova\",\n    \"sage\",\n    \"shimmer\",\n    \"verse\",\n]\n</code></pre> <p>OpenAI's text-to-speech available voices.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer","title":"OpenAISpeechSynthesizer","text":"<p>               Bases: <code>BaseModel</code></p> <p>Speech synthesizer using OpenAI's API.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.provider","title":"provider  <code>class-attribute</code>","text":"<pre><code>provider: str = 'openai'\n</code></pre> <p>Provider name for OpenAI.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre> <p>API key for OpenAI's API.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.base_url","title":"base_url  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>base_url: str | None = None\n</code></pre> <p>Base URL for OpenAI's API.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: Literal[\"gpt-4o-mini-tts\", \"tts-1\", \"tts-1-hd\"] = (\n    \"gpt-4o-mini-tts\"\n)\n</code></pre> <p>Model to use for speech synthesis.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.voice","title":"voice  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>voice: OpenAITTSVoice = 'alloy'\n</code></pre> <p>Voice to use for speech synthesis.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.speed","title":"speed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>speed: Annotated[float, Field(ge=0.25, le=4)] = 1.0\n</code></pre> <p>Speed of speech synthesis.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: PositiveInt = 120\n</code></pre> <p>Timeout for speech synthesis in seconds.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.instructions","title":"instructions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>instructions: str | None = None\n</code></pre> <p>Instructions passed to the model. Valid only when the model is from the GPT-4o family or higher.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.silence_threshold","title":"silence_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>silence_threshold: float | None = None\n</code></pre> <p>Silence threshold for the audio asset.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.silence_duration","title":"silence_duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>silence_duration: float | None = None\n</code></pre> <p>Silence duration for the audio asset.</p>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.synthesize","title":"synthesize","text":"<pre><code>synthesize(\n    texts: Sequence[str],\n    *,\n    audio_params: AudioAssetParams | None = None,\n    **kwargs: Any\n) -&gt; list[AudioAsset]\n</code></pre> <p>Synthesize speech from texts using OpenAI's API.</p> <p>Parameters:</p> Name Type Description Default <code>Sequence[str]</code> <p>Texts to synthesize.</p> required <code>AudioAssetParams | None</code> <p>Parameters for the audio asset.</p> <code>None</code> <code>Any</code> <p>Additional parameters for the OpenAI API.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[AudioAsset]</code> <p>List of audio assets.</p> Source code in <code>src/mosaico/speech_synthesizers/openai.py</code> <pre><code>def synthesize(\n    self, texts: Sequence[str], *, audio_params: AudioAssetParams | None = None, **kwargs: Any\n) -&gt; list[AudioAsset]:\n    \"\"\"\n    Synthesize speech from texts using OpenAI's API.\n\n    :param texts: Texts to synthesize.\n    :param audio_params: Parameters for the audio asset.\n    :param kwargs: Additional parameters for the OpenAI API.\n    :return: List of audio assets.\n    \"\"\"\n    assets = []\n\n    model = kwargs.pop(\"model\", self.model)\n    instructions = kwargs.pop(\"instructions\", self.instructions)\n    silence_threshold = kwargs.pop(\"silence_threshold\", self.silence_threshold)\n    silence_duration = kwargs.pop(\"silence_duration\", self.silence_duration)\n\n    if instructions and model.startswith(\"tts-\"):\n        raise ValueError(\"`instructions` cannot be set when model is not from the GPT-4o family or higher.\")\n\n    for text in texts:\n        response = self._client.audio.speech.create(\n            input=text,\n            model=model,\n            instructions=instructions,\n            voice=kwargs.pop(\"voice\", self.voice),\n            speed=kwargs.pop(\"speed\", self.speed),\n            response_format=\"mp3\",\n            **kwargs,\n        )\n        segment = AudioSegment.from_file(io.BytesIO(response.content), format=\"mp3\")\n        asset = AudioAsset.from_data(\n            response.content,\n            params=audio_params if audio_params is not None else {},\n            mime_type=\"audio/mpeg\",\n            info=AudioInfo(\n                duration=segment.duration_seconds,\n                sample_rate=segment.frame_rate,\n                sample_width=segment.sample_width,\n                channels=segment.channels,\n            ),\n        )\n\n        if silence_threshold is not None and silence_duration is not None:\n            asset = asset.strip_silence(silence_threshold, silence_duration)\n\n        assets.append(asset)\n\n    return assets\n</code></pre>"},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.synthesize(texts)","title":"<code>texts</code>","text":""},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.synthesize(audio_params)","title":"<code>audio_params</code>","text":""},{"location":"api-reference/speech-synthesizers/openai/#mosaico.speech_synthesizers.openai.OpenAISpeechSynthesizer.synthesize(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/video/","title":"Index","text":""},{"location":"api-reference/video/#mosaico.video.types.TimelineEvent","title":"TimelineEvent  <code>module-attribute</code>","text":"<pre><code>TimelineEvent = AssetReference | Scene\n</code></pre> <p>A type alias for a timeline event, which can be an asset reference or a scene.</p>"},{"location":"api-reference/video/#mosaico.video.types.AssetInputType","title":"AssetInputType  <code>module-attribute</code>","text":"<pre><code>AssetInputType: TypeAlias = (\n    Mapping[str, Any]\n    | Asset\n    | Sequence[dict[str, Any]]\n    | Sequence[Asset]\n)\n</code></pre> <p>A type alias for the input type of an asset.</p>"},{"location":"api-reference/video/#mosaico.video.types.TimelineEventInputType","title":"TimelineEventInputType  <code>module-attribute</code>","text":"<pre><code>TimelineEventInputType: TypeAlias = (\n    Mapping[str, Any]\n    | TimelineEvent\n    | Sequence[dict[str, Any]]\n    | Sequence[TimelineEvent]\n)\n</code></pre> <p>A type alias for the input type of a timeline event.</p>"},{"location":"api-reference/video/project/","title":"Project","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProjectConfig","title":"VideoProjectConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>A dictionary representing the configuration of a project.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProjectConfig.title","title":"title  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>title: str = 'Untitled Project'\n</code></pre> <p>The title of the project. Defaults to \"Untitled Project\".</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProjectConfig.version","title":"version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>version: int = 1\n</code></pre> <p>The version of the project. Defaults to 1.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProjectConfig.resolution","title":"resolution  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>resolution: FrameSize = (1920, 1080)\n</code></pre> <p>The resolution of the project in pixels. Defaults to 1920x1080.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProjectConfig.fps","title":"fps  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>fps: PositiveInt = 30\n</code></pre> <p>The frames per second of the project. Defaults to 30.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject","title":"VideoProject","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a project with various properties and methods to manipulate its data.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.config","title":"config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>config: VideoProjectConfig = Field(\n    default_factory=VideoProjectConfig\n)\n</code></pre> <p>The configuration of the project.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.assets","title":"assets  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>assets: dict[str, Asset] = Field(default_factory=dict)\n</code></pre> <p>A dictionary mapping assets keys to Asset objects.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.timeline","title":"timeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeline: Timeline = Field(default_factory=Timeline)\n</code></pre> <p>The timeline of assets and scenes of the video.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <p>The metadata of the video project.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: float\n</code></pre> <p>The total duration of the project in seconds.</p>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; VideoProject\n</code></pre> <p>Create a Project object from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>dict[str, Any]</code> <p>The dictionary containing the project data.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>A Project object instance.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; VideoProject:\n    \"\"\"\n    Create a Project object from a dictionary.\n\n    :param data: The dictionary containing the project data.\n    :return: A Project object instance.\n    \"\"\"\n    config = data.get(\"config\", VideoProjectConfig())\n    project = cls(config=config)\n\n    if \"assets\" in data:\n        project.add_assets(data[\"assets\"])\n\n    if \"timeline\" in data:\n        project.add_timeline_events(data[\"timeline\"])\n\n    return project\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_dict(data)","title":"<code>data</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_file","title":"from_file  <code>classmethod</code>","text":"<pre><code>from_file(\n    file: FilePath | ReadableBuffer[str],\n) -&gt; VideoProject\n</code></pre> <p>Create a Project object from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>FilePath | ReadableBuffer[str]</code> <p>The path to the YAML file.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>A Project object instance.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>@classmethod\ndef from_file(cls, file: FilePath | ReadableBuffer[str]) -&gt; VideoProject:\n    \"\"\"\n    Create a Project object from a YAML file.\n\n    :param file: The path to the YAML file.\n    :return: A Project object instance.\n    \"\"\"\n    if isinstance(file, (str, Path)):\n        project_str = Path(file).read_text(encoding=\"utf-8\")\n    else:\n        file.seek(0)\n        project_str = file.read()\n\n    project_dict = yaml.safe_load(project_str)\n    return cls.from_dict(project_dict)\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_file(file)","title":"<code>file</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_script_generator","title":"from_script_generator  <code>classmethod</code>","text":"<pre><code>from_script_generator(\n    script_generator: ScriptGenerator,\n    media: Sequence[Media],\n    *,\n    config: VideoProjectConfig | None = None,\n    **kwargs: Any\n) -&gt; VideoProject\n</code></pre> <p>Create a Project object from a script generator.</p> <p>Parameters:</p> Name Type Description Default <p>The script generator to use.</p> required <code>Sequence[Media]</code> <p>The media files to use.</p> required <code>VideoProjectConfig | None</code> <p>The configuration of the project.</p> <code>None</code> <code>Any</code> <p>Additional keyword arguments to pass to the script generator.</p> <code>{}</code> <p>Returns:</p> Type Description <code>VideoProject</code> <p>A Project object instance.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>@classmethod\ndef from_script_generator(\n    cls,\n    script_generator: ScriptGenerator,\n    media: Sequence[Media],\n    *,\n    config: VideoProjectConfig | None = None,\n    **kwargs: Any,\n) -&gt; VideoProject:\n    \"\"\"\n    Create a Project object from a script generator.\n\n    :param generator: The script generator to use.\n    :param media: The media files to use.\n    :param config: The configuration of the project.\n    :param kwargs: Additional keyword arguments to pass to the script generator.\n    :return: A Project object instance.\n    \"\"\"\n    config = config if config is not None else VideoProjectConfig()\n    project = cls(config=config)\n\n    # Generate assets and scenes from a scene generator.\n    script = script_generator.generate(media, **kwargs)\n\n    # Create assets and scenes from the script.\n    for shot in script.shots:\n        # Create subtitle asset\n        shot_subtitle = SubtitleAsset.from_data(shot.subtitle)\n\n        # Create scene with initial subtitle reference\n        scene = Scene(description=shot.description).add_asset_references(\n            AssetReference.from_asset(shot_subtitle).with_start_time(shot.start_time).with_end_time(shot.end_time)\n        )\n\n        # Add subtitle asset to project\n        project = project.add_assets(shot_subtitle)\n\n        # Process each media reference in the shot\n        for media_ref in shot.media_references:\n            # Find the referenced media\n            referenced_media = next(m for m in media if m.id == media_ref.media_id)\n\n            # Convert media to asset\n            media_asset = convert_media_to_asset(referenced_media)\n\n            # Create asset reference with timing and effects\n            asset_ref = (\n                AssetReference.from_asset(media_asset)\n                .with_start_time(media_ref.start_time)\n                .with_end_time(media_ref.end_time)\n            )\n\n            # Add effects if it's an image asset\n            if media_asset.type == \"image\" and media_ref.effects:\n                asset_ref = asset_ref.with_effects([create_effect(effect) for effect in media_ref.effects])\n\n            # Add media asset and its reference to the scene\n            project = project.add_assets(media_asset)\n            scene = scene.add_asset_references(asset_ref)\n\n        # Add completed scene to project timeline\n        project = project.add_timeline_events(scene)\n\n    return project\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_script_generator(generator)","title":"<code>generator</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_script_generator(media)","title":"<code>media</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_script_generator(config)","title":"<code>config</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.from_script_generator(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.to_file","title":"to_file","text":"<pre><code>to_file(file: FilePath | WritableBuffer[str]) -&gt; None\n</code></pre> <p>Write the Project object to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>FilePath | WritableBuffer[str]</code> <p>The path to the YAML file.</p> required Source code in <code>src/mosaico/video/project.py</code> <pre><code>def to_file(self, file: FilePath | WritableBuffer[str]) -&gt; None:\n    \"\"\"\n    Write the Project object to a YAML file.\n\n    :param file: The path to the YAML file.\n    \"\"\"\n    project = self.model_dump(exclude_none=True)\n    project[\"assets\"] = {asset_id: asset.model_dump() for asset_id, asset in self.assets.items()}\n    project[\"timeline\"] = [event.model_dump() for event in self.timeline]\n    project_yaml = yaml.safe_dump(project, allow_unicode=True, sort_keys=False)\n\n    if isinstance(file, (str, Path)):\n        Path(file).write_text(project_yaml, encoding=\"utf-8\")\n    else:\n        file.write(project_yaml)\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.to_file(file)","title":"<code>file</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_assets","title":"add_assets","text":"<pre><code>add_assets(assets: AssetInputType) -&gt; VideoProject\n</code></pre> <p>Add one or more assets to the project.</p> <p>Parameters:</p> Name Type Description Default <code>AssetInputType</code> <p>The asset or list of assets to add.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def add_assets(self, assets: AssetInputType) -&gt; VideoProject:\n    \"\"\"\n    Add one or more assets to the project.\n\n    :param assets: The asset or list of assets to add.\n    :return: The updated project.\n    \"\"\"\n    _assets = assets if isinstance(assets, Sequence) else [assets]\n\n    for asset in _assets:\n        if not isinstance(asset, Mapping):\n            self.assets[asset.id] = asset\n            continue\n\n        if not isinstance(asset, Mapping):\n            msg = f\"Invalid asset type: {type(asset)}\"\n            raise ValueError(msg)\n\n        if \"type\" not in asset:\n            self.assets.update({a.id: a for a in _process_asset_dicts(asset)})\n            continue\n\n        asset = _process_single_asset_dict(asset)\n        self.assets[asset.id] = asset\n\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_assets(assets)","title":"<code>assets</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_timeline_events","title":"add_timeline_events","text":"<pre><code>add_timeline_events(\n    events: EventOrEventSequence,\n) -&gt; VideoProject\n</code></pre> <p>Add one or more events to the timeline.</p> <p>Parameters:</p> Name Type Description Default <code>EventOrEventSequence</code> <p>The event or list of events to add.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an asset referenced in the events does not exist in the project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def add_timeline_events(self, events: EventOrEventSequence) -&gt; VideoProject:\n    \"\"\"\n    Add one or more events to the timeline.\n\n    :param events: The event or list of events to add.\n    :return: The updated project.\n    :raises ValueError: If an asset referenced in the events does not exist in the project.\n    \"\"\"\n\n    def validate_asset_id(asset_id: str) -&gt; None:\n        \"\"\"Helper to validate asset ID exists\"\"\"\n        if asset_id not in self.assets:\n            raise AssetNotFoundError(asset_id)\n\n    def validate_scene_assets(scene_event: Scene | Mapping[str, Any]) -&gt; None:\n        \"\"\"Helper to validate assets referenced in a scene\"\"\"\n        if isinstance(scene_event, Scene):\n            for ref in scene_event.asset_references:\n                validate_asset_id(ref.asset_id)\n        else:\n            for ref in scene_event[\"asset_references\"]:\n                asset_id = ref.asset_id if isinstance(ref, AssetReference) else ref[\"asset_id\"]\n                validate_asset_id(asset_id)\n\n    _events = events if isinstance(events, Sequence) else [events]\n\n    for event in _events:\n        if isinstance(event, Scene):\n            validate_scene_assets(event)\n        elif isinstance(event, AssetReference):\n            validate_asset_id(event.asset_id)\n        elif isinstance(event, Mapping):\n            if \"asset_references\" in event:\n                validate_scene_assets(event)\n            else:\n                validate_asset_id(event[\"asset_id\"])\n\n    self.timeline = self.timeline.add_events(events).sort()\n\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_timeline_events(events)","title":"<code>events</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_narration","title":"add_narration","text":"<pre><code>add_narration(\n    speech_synthesizer: SpeechSynthesizer,\n) -&gt; VideoProject\n</code></pre> <p>Add narration to subtitles inside Scene objects by generating speech audio from subtitle text.</p> <p>Updates asset timings within each Scene to match narration duration, dividing time equally between multiple images.</p> <p>Parameters:</p> Name Type Description Default <code>SpeechSynthesizer</code> <p>The speech synthesizer to use for generating narration audio</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project with narration added</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def add_narration(self, speech_synthesizer: SpeechSynthesizer) -&gt; VideoProject:\n    \"\"\"\n    Add narration to subtitles inside Scene objects by generating speech audio from subtitle text.\n\n    Updates asset timings within each Scene to match narration duration, dividing time equally\n    between multiple images.\n\n    :param speech_synthesizer: The speech synthesizer to use for generating narration audio\n    :return: The updated project with narration added\n    \"\"\"\n    logger.debug(f\"Adding narration to project with {speech_synthesizer.__class__.__name__} synthesizer\")\n    current_time = None\n\n    for i, scene in enumerate(self.timeline.sort()):\n        if not isinstance(scene, Scene):\n            continue\n\n        # Get subtitle content from scene\n        subtitle_refs = [ref for ref in scene.asset_references if ref.asset_type == \"subtitle\"]\n\n        if not subtitle_refs:\n            continue\n\n        logger.debug(f\"Adding narration to scene {i + 1} with {len(subtitle_refs)} subtitles\")\n\n        # Get subtitle assets and their text content\n        subtitle_assets = [cast(SubtitleAsset, self.get_asset(ref.asset_id)) for ref in subtitle_refs]\n\n        # Generate narration for subtitle content\n        texts = [subtitle.to_string() for subtitle in subtitle_assets]\n        narration_assets = speech_synthesizer.synthesize(texts)\n\n        # Add narration assets to project\n        self.add_assets(narration_assets)\n\n        # Calculate total narration duration for this scene\n        total_narration_duration = sum(narration.duration for narration in narration_assets)\n\n        # Get non-subtitle assets to adjust timing\n        non_subtitle_refs = [ref for ref in scene.asset_references if ref.asset_type != \"subtitle\"]\n        image_refs = [ref for ref in non_subtitle_refs if ref.asset_type == \"image\"]\n        other_refs = [ref for ref in non_subtitle_refs if ref.asset_type != \"image\"]\n\n        if current_time is None:\n            current_time = scene.asset_references[0].start_time\n\n        new_refs = []\n\n        # Adjust image timings - divide narration duration equally\n        if image_refs:\n            time_per_image = total_narration_duration / len(image_refs)\n            for idx, ref in enumerate(image_refs):\n                logger.debug(f\"Adjusting image {ref.asset_id} timing\")\n                new_start = current_time + (idx * time_per_image)\n                new_end = new_start + time_per_image\n                new_ref = ref.model_copy().with_start_time(new_start).with_end_time(new_end)\n                new_refs.append(new_ref)\n\n        # Add other non-image assets with full narration duration\n        for ref in other_refs:\n            logger.debug(f\"Adjusting non-image asset {ref.asset_id} timing\")\n            new_ref = (\n                ref.model_copy()\n                .with_start_time(current_time)\n                .with_end_time(current_time + total_narration_duration)\n            )\n            new_refs.append(new_ref)\n\n        # Add subtitle references spanning full narration duration\n        for ref in subtitle_refs:\n            logger.debug(f\"Adjusting subtitle asset {ref.asset_id} timing\")\n            new_ref = (\n                ref.model_copy()\n                .with_start_time(current_time)\n                .with_end_time(current_time + total_narration_duration)\n            )\n            new_refs.append(new_ref)\n\n        # Add narration references\n        for narration in narration_assets:\n            logger.debug(f\"Adjusting narration asset {narration.id} timing\")\n            narration_ref = (\n                AssetReference.from_asset(narration)\n                .with_start_time(current_time)\n                .with_end_time(current_time + narration.duration)\n            )\n            new_refs.append(narration_ref)\n\n        # Update current_time for next scene\n        current_time += total_narration_duration\n\n        # Create new scene with updated references\n        logger.debug(\"Creating new scene with narration and updated references\")\n        new_scene = scene.model_copy(update={\"asset_references\": new_refs})\n        self.timeline[i] = new_scene\n\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_narration(speech_synthesizer)","title":"<code>speech_synthesizer</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions","title":"add_captions","text":"<pre><code>add_captions(\n    transcription: Transcription,\n    *,\n    max_duration: int = 5,\n    aligner: TranscriptionAligner | None = None,\n    original_text: str | None = None,\n    params: TextAssetParams | None = None,\n    scene_index: int | None = None,\n    overwrite: bool = False\n) -&gt; VideoProject\n</code></pre> <p>Add subtitles to the project from a transcription.</p> <p>Parameters:</p> Name Type Description Default <code>Transcription</code> <p>The transcription to add subtitles from.</p> required <code>int</code> <p>The maximum duration of each subtitle.</p> <code>5</code> <code>TranscriptionAligner | None</code> <p>The aligner to use for aligning the transcription with the original text.</p> <code>None</code> <code>str | None</code> <p>The original text to align the transcription with.</p> <code>None</code> <code>TextAssetParams | None</code> <p>The parameters for the subtitle assets.</p> <code>None</code> <code>int | None</code> <p>The index of the scene to add the subtitles to.</p> <code>None</code> <code>bool</code> <p>Whether to overwrite existing subtitles in the scene.</p> <code>False</code> <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def add_captions(  # noqa: PLR0912, PLR0915\n    self,\n    transcription: Transcription,\n    *,\n    max_duration: int = 5,\n    aligner: TranscriptionAligner | None = None,\n    original_text: str | None = None,\n    params: TextAssetParams | None = None,\n    scene_index: int | None = None,\n    overwrite: bool = False,\n) -&gt; VideoProject:\n    \"\"\"\n    Add subtitles to the project from a transcription.\n\n    :param transcription: The transcription to add subtitles from.\n    :param max_duration: The maximum duration of each subtitle.\n    :param aligner: The aligner to use for aligning the transcription with the original text.\n    :param original_text: The original text to align the transcription with.\n    :param params: The parameters for the subtitle assets.\n    :param scene_index: The index of the scene to add the subtitles to.\n    :param overwrite: Whether to overwrite existing subtitles in the scene.\n    :return: The updated project.\n    \"\"\"\n    logger.debug(\"Adding subtitles to project\")\n\n    subtitles = []\n    references = []\n\n    if scene_index is not None:\n        logger.debug(f\"Adding subtitles to scene at index {scene_index}\")\n        scene = self.timeline[scene_index]\n\n        if scene.has_subtitles and not overwrite:\n            msg = f\"Scene at index {scene_index} already has subtitles. Use `overwrite=True` to replace.\"\n            raise ValueError(msg)\n\n        # Remove existing subtitles\n        logger.debug(f\"Removing existing subtitles from scene at index {scene_index}\")\n        for ref in scene.asset_references:\n            if ref.asset_type == \"subtitle\":\n                self.remove_asset(ref.asset_id)\n\n        if aligner is not None:\n            logger.debug(f\"Aligning subtitles for scene at index {scene_index}\")\n            subtitles = _extract_assets_from_scene(scene, self.assets, \"subtitle\")\n            if not original_text:\n                logger.debug(\n                    f\"No original text provided for scene at index {scene_index}. Using subtitles as original text.\"\n                )\n                original_text = \" \".join([s.to_string() for s in subtitles])\n            aligned_transcription = aligner.align(transcription, original_text)\n            phrases = _group_transcript_into_sentences(aligned_transcription, max_duration=max_duration)\n        else:\n            logger.debug(f\"No aligner provided for scene at index {scene_index}. Using original transcription.\")\n            phrases = _group_transcript_into_sentences(transcription, max_duration=max_duration)\n\n        # Calculate time scale factor if needed\n        current_time = scene.start_time\n\n        for phrase_index, phrase in enumerate(phrases):\n            logger.debug(f\"Processing phrase {phrase_index + 1} of {len(phrases)}\")\n            subtitle_text = \" \".join(word.text for word in phrase)\n            subtitle = SubtitleAsset.from_data(subtitle_text)\n\n            # Calculate scaled duration\n            phrase_duration = phrase[-1].end_time - phrase[0].start_time\n\n            start_time = current_time\n            end_time = start_time + phrase_duration\n\n            # Ensure we don't exceed scene bounds\n            end_time = min(end_time, scene.end_time)\n\n            if phrase_index == len(phrases) - 1:\n                end_time = scene.end_time\n\n            subtitle_ref = AssetReference.from_asset(\n                asset=subtitle,\n                asset_params=params,\n                start_time=start_time,\n                end_time=end_time,\n            )\n            subtitles.append(subtitle)\n            references.append(subtitle_ref)\n\n            current_time = end_time\n\n        logger.debug(f\"Processed {len(phrases)} phrases\")\n        self.add_assets(subtitles)\n        scene = scene.add_asset_references(references)\n        self.timeline[scene_index] = scene\n    else:\n        logger.warning(\"No scene index provided. Caption generation is likely to present inconsistent results.\")\n        if aligner is not None:\n            logger.debug(\"Aligning subtitles based on original text\")\n            subtitles = _extract_assets_from_timeline(self.timeline, self.assets, \"subtitle\")\n            if not original_text:\n                logger.debug(\"Original text not provided. Using all project subtitles as original text\")\n                original_text = \" \".join([s.to_string() for s in subtitles])\n            aligned_transcription = aligner.align(transcription, original_text)\n            phrases = _group_transcript_into_sentences(aligned_transcription, max_duration=max_duration)\n        else:\n            phrases = _group_transcript_into_sentences(transcription, max_duration=max_duration)\n\n        # Handle non-scene case\n        for phrase_index, phrase in enumerate(phrases):\n            logger.debug(f\"Processing phrase {phrase_index + 1} of {len(phrases)}\")\n            subtitle_text = \" \".join(word.text for word in phrase)\n            subtitle = SubtitleAsset.from_data(subtitle_text)\n\n            subtitle_ref = AssetReference.from_asset(\n                asset=subtitle,\n                asset_params=params,\n                start_time=phrase[0].start_time,\n                end_time=phrase[-1].end_time,\n            )\n            subtitles.append(subtitle)\n            references.append(subtitle_ref)\n\n        self.add_assets(subtitles)\n        self.add_timeline_events(references)\n\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(transcription)","title":"<code>transcription</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(max_duration)","title":"<code>max_duration</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(aligner)","title":"<code>aligner</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(original_text)","title":"<code>original_text</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(params)","title":"<code>params</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(scene_index)","title":"<code>scene_index</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions_from_transcriber","title":"add_captions_from_transcriber","text":"<pre><code>add_captions_from_transcriber(\n    audio_transcriber: AudioTranscriber,\n    *,\n    max_duration: int = 5,\n    aligner: TranscriptionAligner | None = None,\n    params: TextAssetParams | None = None,\n    overwrite: bool = False\n) -&gt; VideoProject\n</code></pre> <p>Add subtitles to the project from audio assets using an audio transcriber.</p> <p>Parameters:</p> Name Type Description Default <code>AudioTranscriber</code> <p>The audio transcriber to use for transcribing audio assets.</p> required <code>int</code> <p>The maximum duration of each subtitle.</p> <code>5</code> <code>TextAssetParams | None</code> <p>The parameters for the subtitle assets.</p> <code>None</code> <code>bool</code> <p>Whether to overwrite existing subtitles in the scene.</p> <code>False</code> <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def add_captions_from_transcriber(\n    self,\n    audio_transcriber: AudioTranscriber,\n    *,\n    max_duration: int = 5,\n    aligner: TranscriptionAligner | None = None,\n    params: TextAssetParams | None = None,\n    overwrite: bool = False,\n) -&gt; VideoProject:\n    \"\"\"\n    Add subtitles to the project from audio assets using an audio transcriber.\n\n    :param audio_transcriber: The audio transcriber to use for transcribing audio assets.\n    :param max_duration: The maximum duration of each subtitle.\n    :param params: The parameters for the subtitle assets.\n    :param overwrite: Whether to overwrite existing subtitles in the scene.\n    :return: The updated project.\n    \"\"\"\n    for i, event in enumerate(self.timeline):\n        if not isinstance(event, Scene) or not event.has_audio:\n            continue\n\n        subtitles = _extract_assets_from_scene(event, self.assets, \"subtitle\")\n\n        for asset_ref in event.asset_references:\n            if asset_ref.asset_type != \"audio\":\n                continue\n\n            audio_asset = self.get_asset(asset_ref.asset_id)\n            audio_asset = cast(AudioAsset, audio_asset)\n            audio_transcription = audio_transcriber.transcribe(audio_asset)\n\n            self.add_captions(\n                audio_transcription,\n                max_duration=max_duration,\n                aligner=aligner,\n                original_text=\" \".join([s.to_string() for s in subtitles]) if subtitles else None,\n                params=params,\n                scene_index=i,\n                overwrite=overwrite,\n            )\n\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions_from_transcriber(audio_transcriber)","title":"<code>audio_transcriber</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions_from_transcriber(max_duration)","title":"<code>max_duration</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions_from_transcriber(params)","title":"<code>params</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.add_captions_from_transcriber(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_config","title":"with_config","text":"<pre><code>with_config(\n    config: VideoProjectConfig | Mapping[str, Any],\n) -&gt; VideoProject\n</code></pre> <p>Override the video project configuration.</p> <p>Parameters:</p> Name Type Description Default <code>VideoProjectConfig | Mapping[str, Any]</code> <p>The configuration to set.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def with_config(self, config: VideoProjectConfig | Mapping[str, Any]) -&gt; VideoProject:\n    \"\"\"\n    Override the video project configuration.\n\n    :param config: The configuration to set.\n    :return: The updated project.\n    \"\"\"\n    if isinstance(config, Mapping):\n        config = VideoProjectConfig.model_validate(config)\n    self.config = config\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_config(config)","title":"<code>config</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_subtitle_params","title":"with_subtitle_params","text":"<pre><code>with_subtitle_params(\n    params: TextAssetParams | Mapping[str, Any],\n) -&gt; VideoProject\n</code></pre> <p>Override the subtitle parameters for the assets in the project.</p> <p>Parameters:</p> Name Type Description Default <code>TextAssetParams | Mapping[str, Any]</code> <p>The subtitle parameters to set.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def with_subtitle_params(self, params: TextAssetParams | Mapping[str, Any]) -&gt; VideoProject:\n    \"\"\"\n    Override the subtitle parameters for the assets in the project.\n\n    :param params: The subtitle parameters to set.\n    :return: The updated project.\n    \"\"\"\n    if not self.timeline:\n        msg = \"The project timeline is empty.\"\n        raise ValueError(msg)\n\n    params = TextAssetParams.model_validate(params)\n\n    for i, event in enumerate(self.timeline):\n        if isinstance(event, Scene):\n            self.timeline[i].with_subtitle_params(params)\n        elif isinstance(event, AssetReference):\n            self.timeline[i].asset_params = params\n\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_subtitle_params(params)","title":"<code>params</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_title","title":"with_title","text":"<pre><code>with_title(title: str) -&gt; VideoProject\n</code></pre> <p>Override the title of the project.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The title to set.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def with_title(self, title: str) -&gt; VideoProject:\n    \"\"\"\n    Override the title of the project.\n\n    :param title: The title to set.\n    :return: The updated project.\n    \"\"\"\n    self.config.title = title\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_title(title)","title":"<code>title</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_version","title":"with_version","text":"<pre><code>with_version(version: int) -&gt; VideoProject\n</code></pre> <p>Override the project version.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The version to set.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def with_version(self, version: int) -&gt; VideoProject:\n    \"\"\"\n    Override the project version.\n\n    :param version: The version to set.\n    :return: The updated project.\n    \"\"\"\n    self.config.version = version\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_version(version)","title":"<code>version</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_fps","title":"with_fps","text":"<pre><code>with_fps(fps: int) -&gt; VideoProject\n</code></pre> <p>Override the FPS of the project.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The FPS to set.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def with_fps(self, fps: int) -&gt; VideoProject:\n    \"\"\"\n    Override the FPS of the project.\n\n    :param fps: The FPS to set.\n    :return: The updated project.\n    \"\"\"\n    self.config.fps = fps\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_fps(fps)","title":"<code>fps</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_resolution","title":"with_resolution","text":"<pre><code>with_resolution(resolution: FrameSize) -&gt; VideoProject\n</code></pre> <p>Override the resolution of the project.</p> <p>Parameters:</p> Name Type Description Default <code>FrameSize</code> <p>The resolution to set.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def with_resolution(self, resolution: FrameSize) -&gt; VideoProject:\n    \"\"\"\n    Override the resolution of the project.\n\n    :param resolution: The resolution to set.\n    :return: The updated project.\n    \"\"\"\n    self.config.resolution = resolution\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.with_resolution(resolution)","title":"<code>resolution</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.get_asset","title":"get_asset","text":"<pre><code>get_asset(asset_id: str) -&gt; Asset\n</code></pre> <p>Get an asset by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The ID of the asset.</p> required <p>Returns:</p> Type Description <code>Asset</code> <p>The Asset object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the asset is not found in the project assets.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def get_asset(self, asset_id: str) -&gt; Asset:\n    \"\"\"\n    Get an asset by its ID.\n\n    :param asset_id: The ID of the asset.\n    :return: The Asset object.\n    :raises ValueError: If the asset is not found in the project assets.\n    \"\"\"\n    try:\n        return self.assets[asset_id]\n    except KeyError:\n        raise AssetNotFoundError(asset_id) from None\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.get_asset(asset_id)","title":"<code>asset_id</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.get_timeline_event","title":"get_timeline_event","text":"<pre><code>get_timeline_event(index: int) -&gt; TimelineEvent\n</code></pre> <p>Get a timeline event by its index.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The index of the timeline event.</p> required <p>Returns:</p> Type Description <code>TimelineEvent</code> <p>The TimelineEvent object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the index is out of range.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def get_timeline_event(self, index: int) -&gt; TimelineEvent:\n    \"\"\"\n    Get a timeline event by its index.\n\n    :param index: The index of the timeline event.\n    :return: The TimelineEvent object.\n    :raises ValueError: If the index is out of range.\n    \"\"\"\n    if abs(index) &gt;= len(self.timeline):\n        raise TimelineEventNotFoundError\n    return self.timeline[index]\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.get_timeline_event(index)","title":"<code>index</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.remove_timeline_event","title":"remove_timeline_event","text":"<pre><code>remove_timeline_event(index: int) -&gt; VideoProject\n</code></pre> <p>Remove a timeline event from the project.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The index of the timeline event to remove.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def remove_timeline_event(self, index: int) -&gt; VideoProject:\n    \"\"\"\n    Remove a timeline event from the project.\n\n    :param index: The index of the timeline event to remove.\n    :return: The updated project.\n    \"\"\"\n    if abs(index) &gt;= len(self.timeline):\n        raise TimelineEventNotFoundError\n    del self.timeline[index]\n    return self\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.remove_timeline_event(index)","title":"<code>index</code>","text":""},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.remove_asset","title":"remove_asset","text":"<pre><code>remove_asset(asset_id: str) -&gt; VideoProject\n</code></pre> <p>Remove an asset from the project.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The ID of the asset to remove.</p> required <p>Returns:</p> Type Description <code>VideoProject</code> <p>The updated project.</p> Source code in <code>src/mosaico/video/project.py</code> <pre><code>def remove_asset(self, asset_id: str) -&gt; VideoProject:\n    \"\"\"\n    Remove an asset from the project.\n\n    :param asset_id: The ID of the asset to remove.\n    :return: The updated project.\n    \"\"\"\n    try:\n        for i, event in enumerate(self.timeline):\n            if isinstance(event, Scene):\n                self.timeline[i] = event.remove_asset_id_references(asset_id)\n            elif isinstance(event, AssetReference) and event.asset_id == asset_id:\n                self.remove_timeline_event(i)\n        del self.assets[asset_id]\n        return self\n    except KeyError:\n        raise AssetNotFoundError(asset_id) from None\n</code></pre>"},{"location":"api-reference/video/project/#mosaico.video.project.VideoProject.remove_asset(asset_id)","title":"<code>asset_id</code>","text":""},{"location":"api-reference/video/rendering/","title":"Rendering","text":""},{"location":"api-reference/video/rendering/#mosaico.video.rendering.render_video","title":"render_video","text":"<pre><code>render_video(\n    project: VideoProject,\n    output_path: str | Path,\n    *,\n    overwrite: bool = False,\n    **kwargs: Any\n) -&gt; Path\n</code></pre> <p>Renders a video based on a project.</p> <p>Parameters:</p> Name Type Description Default <code>VideoProject</code> <p>The project to render.</p> required <code>str | Path</code> <p>The output path. If a directory is provided, the output file will be saved in the directory with the project title as the filename. Otherwise, be sure that the file extension matches the codec used. By default, the output file will be an MP4 file (H.264 codec). The available codecs are:  - libx264: .mp4 - mpeg4: .mp4 - rawvideo: .avi - png: .avi - libvorbis: .ogv - libvpx: .webm</p> required <code>bool</code> <p>Whether to overwrite the output file if it already exists.</p> <code>False</code> <code>Any</code> <p>Additional keyword arguments to pass to Moviepy clip video writer.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Path</code> <p>The path to the rendered video.</p> Source code in <code>src/mosaico/video/rendering.py</code> <pre><code>def render_video(\n    project: VideoProject,\n    output_path: str | Path,\n    *,\n    overwrite: bool = False,\n    **kwargs: Any,\n) -&gt; Path:\n    \"\"\"\n    Renders a video based on a project.\n\n    :param project: The project to render.\n    :param output_path: The output path. If a directory is provided, the output file will be saved in the directory\n        with the project title as the filename. Otherwise, be sure that the file extension matches the codec used.\n        By default, the output file will be an MP4 file (H.264 codec). The available codecs are:\n\n        - libx264: .mp4\n        - mpeg4: .mp4\n        - rawvideo: .avi\n        - png: .avi\n        - libvorbis: .ogv\n        - libvpx: .webm\n\n    :param overwrite: Whether to overwrite the output file if it already exists.\n    :param kwargs: Additional keyword arguments to pass to Moviepy clip video writer.\n    :return: The path to the rendered video.\n    \"\"\"\n    output_path = Path(output_path).resolve()\n    output_codec = kwargs.get(\"codec\") or _guess_codec_from_file_path(output_path) or \"libx264\"\n    output_file_ext = _CODEC_FILE_EXTENSION_MAP[output_codec]\n\n    if output_path.is_dir():\n        output_path /= f\"{project.config.title}.{output_file_ext}\"\n\n    if output_path.suffix != output_file_ext:\n        raise ValueError(f\"Output file must be an '{output_file_ext}' file.\")\n\n    if not output_path.parent.exists():\n        raise FileNotFoundError(f\"Output directory does not exist: {output_path.parent}\")\n\n    if output_path.exists() and not overwrite:\n        msg = f\"Output file already exists: {output_path}\"\n        raise FileExistsError(msg)\n\n    video_clips = []\n    audio_clips = []\n\n    for event in project.timeline:\n        event_asset_ref_pairs = _get_event_assets_and_refs(event, project)\n        event_video_clips, event_audio_clips = _render_event_clips(event_asset_ref_pairs, project.config.resolution)\n        video_clips.extend(event_video_clips or [])\n        audio_clips.extend(event_audio_clips or [])\n\n    video: VideoClip = (\n        CompositeVideoClip(video_clips, size=project.config.resolution)\n        .with_fps(project.config.fps)\n        .with_duration(project.duration)\n    )\n\n    if audio_clips:\n        audio = CompositeAudioClip(audio_clips).with_duration(project.duration)\n        video = video.with_audio(audio)\n\n    kwargs[\"codec\"] = output_codec\n    kwargs[\"audio_codec\"] = kwargs.get(\"audio_codec\", \"aac\")\n    kwargs[\"threads\"] = kwargs.get(\"threads\", multiprocessing.cpu_count())\n    kwargs[\"temp_audiofile_path\"] = kwargs.get(\"temp_audiofile_path\", output_path.parent.as_posix())\n\n    video.write_videofile(output_path.as_posix(), **kwargs)\n    video.close()\n\n    return output_path\n</code></pre>"},{"location":"api-reference/video/rendering/#mosaico.video.rendering.render_video(project)","title":"<code>project</code>","text":""},{"location":"api-reference/video/rendering/#mosaico.video.rendering.render_video(output_path)","title":"<code>output_path</code>","text":""},{"location":"api-reference/video/rendering/#mosaico.video.rendering.render_video(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"api-reference/video/rendering/#mosaico.video.rendering.render_video(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"concepts/asset-references-and-scenes/","title":"Asset References and Scenes","text":"<p>Prerequisites</p> <ul> <li>Assets</li> </ul>"},{"location":"concepts/asset-references-and-scenes/#overview","title":"Overview","text":"<p>Asset references are a core concept in Mosaico that allow you to control how assets appear in your video timeline. They provide a way to manage different types of media efficiently, control how media appears in your video, maintain type safety and validation, create complex video compositions, and extend functionality as needed. A group of asset references can be combined into a scene to create a logical section of your video.</p> <p>In summary, the asset system in Mosaico consists of two main components:</p> <ul> <li>Asset References: Define when and how assets appear in the timeline</li> <li>Scenes: Group related asset references together</li> </ul> <p>These components form the building blocks of your video timeline and control the presentation of your media assets.</p>"},{"location":"concepts/asset-references-and-scenes/#asset-references","title":"Asset References","text":"<p>Asset references are crucial for controlling how assets appear in your video timeline. They act as instructions for:</p> <ul> <li>When assets appear and disappear</li> <li>How long they're visible</li> <li>What effects are applied</li> <li>Any parameter overrides</li> </ul> <p>Think of them as the \"stage directions\" for your assets:</p> <pre><code>from mosaico.assets.reference import AssetReference\n\n# Control asset timing and effects\nasset_ref = (\n    AssetReference.from_asset(image)\n    .with_start_time(0)\n    .with_end_time(5)\n    .with_effects([fade_in_effect])\n)\n</code></pre>"},{"location":"concepts/asset-references-and-scenes/#structure","title":"Structure","text":"<p>The basic structure of an asset reference consists of the following components:</p> <pre><code>from mosaico.assets.reference import AssetReference\n\n#Basic structure of an asset reference\nreference = AssetReference(\n    asset_id=\"background_01\",           # Asset identifier\n    asset_params=ImageAssetParams(...), # Optional parameter overrides\n    start_time=0,                       # When asset appears\n    end_time=10,                        # When asset disappears\n    effects=[]                          # Optional effects\n)\n</code></pre>"},{"location":"concepts/asset-references-and-scenes/#creating-asset-references","title":"Creating Asset References","text":"<p>There are two main ways to create asset references:</p> <ol> <li> <p>From an Existing Asset <pre><code># Create reference from asset\nlogo_ref = AssetReference.from_asset(\n    asset=logo_asset,\n    start_time=0,\n    end_time=30\n)\n\n# Using builder pattern\ntitle_ref = AssetReference.from_asset(title_asset)\\\n    .with_start_time(5)\\\n    .with_end_time(10)\\\n    .with_params(TextAssetParams(font_size=48))\\\n    .with_effects([fade_in_effect])\n</code></pre></p> </li> <li> <p>Direct Construction <pre><code># Manual reference creation\nmusic_ref = AssetReference(\n    asset_id=\"background_music\",\n    start_time=0,\n    end_time=60,\n    asset_params=AudioAssetParams(volume=0.8)\n)\n</code></pre></p> </li> </ol>"},{"location":"concepts/asset-references-and-scenes/#scenes","title":"Scenes","text":"<p>Scenes are a way to group assets together in your video timeline. They allow you to organize your video into logical sections and apply effects to multiple assets at once. Scenes can be used to create transitions, apply global effects, or group related assets together:</p> <p>Warning</p> <p>Scene's implementation of transitions and global effects is not yet supported in Mosaico but will be added in future releases.</p> <pre><code>from mosaico.scenes.scene import Scene\n\n# Create a scene with multiple assets\nscene = Scene(\n    asset_references=[\n        AssetReference.from_asset(image1),\n        AssetReference.from_asset(image2),\n    ],\n)\n</code></pre>"},{"location":"concepts/asset-references-and-scenes/#common-patterns","title":"Common Patterns","text":""},{"location":"concepts/asset-references-and-scenes/#background-with-overlay","title":"Background with Overlay","text":"<pre><code>scene = Scene(\n    title=\"Title Scene\",\n    asset_references=[\n        # Background layer\n        AssetReference.from_asset(background)\n            .with_start_time(0)\n            .with_end_time(10),\n\n        # Text overlay\n        AssetReference.from_asset(title)\n            .with_start_time(2)\n            .with_end_time(8)\n    ]\n)\n</code></pre>"},{"location":"concepts/asset-references-and-scenes/#audio-visual-sync","title":"Audio-Visual Sync","text":"<pre><code>narration_ref = AssetReference.from_asset(narration)\n    .with_start_time(0)\n    .with_end_time(narration.duration)\n\nscene = Scene(\n    asset_references=[\n        # Visual content matches narration timing\n        AssetReference.from_asset(visual)\n            .with_start_time(narration_ref.start_time)\n            .with_end_time(narration_ref.end_time),\n        narration_ref\n    ]\n)\n</code></pre>"},{"location":"concepts/asset-references-and-scenes/#sequential-content","title":"Sequential Content","text":"<pre><code>def create_sequence_scene(assets: list[BaseAsset], duration_per_asset: float) -&gt; Scene:\n    \"\"\"Create a scene with sequential assets.\"\"\"\n    references = []\n    current_time = 0\n\n    for asset in assets:\n        references.append(\n            AssetReference.from_asset(asset)\n                .with_start_time(current_time)\n                .with_end_time(current_time + duration_per_asset)\n        )\n        current_time += duration_per_asset\n\n    return Scene(asset_references=references)\n</code></pre>"},{"location":"concepts/asset-references-and-scenes/#best-practices","title":"Best Practices","text":"<p>Asset Reference Organization</p> <ul> <li>Keep related assets together in scenes</li> <li>Use meaningful timing relationships</li> <li>Apply effects judiciously</li> </ul> <p>Scene Structure</p> <ul> <li>Group logically related content</li> <li>Maintain clear timing hierarchies</li> <li>Add descriptive titles and descriptions</li> </ul> <p>Timeline Management</p> <ul> <li>Verify asset existence before referencing</li> <li>Check timing consistency</li> <li>Handle transitions between scenes</li> </ul>"},{"location":"concepts/asset-references-and-scenes/#conclusion","title":"Conclusion","text":"<p>This comprehensive asset system allows you to manage different types of media efficiently, control how media appears in your video, maintain type safety and validation, create complex video compositions, and extend functionality as needed.</p>"},{"location":"concepts/audio-transcriptors/","title":"Audio Transcriptors","text":"<p>Prerequisites</p> <ul> <li>Media</li> <li>Assets</li> <li>Video Projects</li> </ul>"},{"location":"concepts/audio-transcriptors/#overview","title":"Overview","text":"<p>Mosaico provides audio transcriptor components to convert speech into text, which can be used for subtitle generation and content synchronization. The system uses a protocol-based approach allowing different transcriptor services to be integrated through a common interface.</p>"},{"location":"concepts/audio-transcriptors/#audio-transcriptor-protocol","title":"Audio Transcriptor Protocol","text":"<p>The transcriptor system is built around the <code>AudioTranscriber</code> protocol:</p> <pre><code>from mosaico.audio_transcribers.protocol import AudioTranscriber\nfrom mosaico.assets.audio import AudioAsset\nfrom mosaico.audio_transcribers.transcription import Transcription\n\nclass MyTranscriber(AudioTranscriber):\n    def transcribe(self, audio_asset: AudioAsset) -&gt; Transcription:\n        # Implement transcription logic\n        ...\n</code></pre>"},{"location":"concepts/audio-transcriptors/#transcription-structure","title":"Transcription Structure","text":"<p>Transcriptions are represented using the <code>Transcription</code> class:</p> <pre><code>from mosaico.audio_transcribers.transcription import Transcription, TranscriptionWord\n\nwords = [\n    TranscriptionWord(\n        start_time=0.0,\n        end_time=0.5,\n        text=\"Hello\"\n    ),\n    TranscriptionWord(\n        start_time=0.6,\n        end_time=1.0,\n        text=\"world\"\n    )\n]\n\ntranscription = Transcription(words=words)\n</code></pre>"},{"location":"concepts/audio-transcriptors/#using-transcriptors-in-projects","title":"Using Transcriptors in Projects","text":"<p>Transcriptors can be used to generate subtitles for video projects:</p> <pre><code># Create transcriptor\ntranscriber = MyTranscriber()\n\n# Transcribe audio asset\ntranscription = transcriber.transcribe(audio_asset)\n\n# Add subtitles from transcription\nproject = project.add_captions_from_transcriber(\n    transcription,\n    max_duration=5,  # Maximum subtitle duration\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    )\n)\n</code></pre>"},{"location":"concepts/audio-transcriptors/#transcription-formats","title":"Transcription Formats","text":""},{"location":"concepts/audio-transcriptors/#vtt-format","title":"VTT Format","text":"<pre><code># Convert to WebVTT\nvtt_content = transcription.as_vtt()\n\n# Create from VTT\ntranscription = Transcription.from_vtt(vtt_content)\n</code></pre>"},{"location":"concepts/audio-transcriptors/#srt-format","title":"SRT Format","text":"<pre><code># Create from SRT\ntranscription = Transcription.from_srt(srt_content)\n</code></pre>"},{"location":"concepts/audio-transcriptors/#best-practices","title":"Best Practices","text":""},{"location":"concepts/audio-transcriptors/#handling-long-content","title":"Handling Long Content","text":"<ul> <li>Break long transcriptions into manageable chunks</li> <li>Consider memory usage for large files</li> <li>Use appropriate subtitle durations</li> </ul>"},{"location":"concepts/audio-transcriptors/#timing-synchronization","title":"Timing Synchronization","text":"<ul> <li>Verify audio/subtitle sync</li> <li>Handle overlapping speech</li> <li>Account for pauses and breaks</li> </ul>"},{"location":"concepts/audio-transcriptors/#text-processing","title":"Text Processing","text":"<ul> <li>Clean up transcription text</li> <li>Handle punctuation properly</li> <li>Format numbers and special characters</li> </ul>"},{"location":"concepts/audio-transcriptors/#common-use-cases","title":"Common Use Cases","text":""},{"location":"concepts/audio-transcriptors/#video-subtitles","title":"Video Subtitles","text":"<pre><code># Create news video with transcribed subtitles\nproject = (\n    VideoProject.from_script_generator(news_generator, media_files)\n    .add_captions_from_transcriber(\n        transcriber,\n        max_duration=5,\n        params=TextAssetParams(\n            font_size=24,\n            font_color=\"yellow\"\n        )\n    )\n)\n</code></pre>"},{"location":"concepts/audio-transcriptors/#interview-captioning","title":"Interview Captioning","text":"<pre><code># Process interview audio\ntranscription = transcriber.transcribe(interview_audio)\n\n# Add captions to video\nproject = project.add_captions(\n    transcription,\n    params=TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\")\n    )\n)\n</code></pre>"},{"location":"concepts/audio-transcriptors/#multi-language-support","title":"Multi-language Support","text":"<pre><code># Create subtitles in different languages\nfor language in languages:\n    translated_transcription = translate_transcription(\n        transcription,\n        target_language=language\n    )\n    project.add_captions(\n        translated_transcription,\n        params=subtitle_params[language]\n    )\n</code></pre>"},{"location":"concepts/audio-transcriptors/#conclusion","title":"Conclusion","text":"<p>The transcriptor system in Mosaico provides a flexible foundation for adding subtitles and captions to your videos, with support for different formats and processing options.</p>"},{"location":"concepts/effects/","title":"Effects","text":"<p>Prerequisites</p> <ul> <li>Assets</li> <li>Asset References</li> </ul>"},{"location":"concepts/effects/#overview","title":"Overview","text":"<p>The Effects System in Mosaico provides a way to add dynamic animations and visual effects to your video elements. Effects can be applied to any asset reference and can be combined to create complex animations.</p>"},{"location":"concepts/effects/#interface","title":"Interface","text":"<p>At the core of the effects system is the Effect protocol:</p> <pre><code>from moviepy.Clip import Clip\nfrom typing import Protocol, TypeVar\n\nClipType = TypeVar(\"ClipType\", bound=Clip)\n\nclass Effect(Protocol[ClipType]):\n    \"\"\"Base protocol for all effects.\"\"\"\n\n    def apply(self, clip: ClipType) -&gt; ClipType:\n        \"\"\"Apply the effect to a clip.\"\"\"\n        ...\n</code></pre> <p>The user can create custom effects by implementing the <code>apply</code> method. The <code>apply</code> method takes a <code>Clip</code> object and returns a modified <code>Clip</code> object with the effect applied.</p>"},{"location":"concepts/effects/#built-in-effects","title":"Built-in Effects","text":"<p>Mosaico provides a set of built-in effects that can be used to create dynamic animations in your video compositions. These effects fall into two main categories: pan effects for camera-like movements and zoom effects for dynamic scaling.</p> <p>Here's a complete list of available effects:</p> Effect Type Parameters Description PanLeftEffect <code>pan_left</code> <code>zoom_factor: float = 1.1</code> Move from right to left across the frame PanRightEffect <code>pan_right</code> <code>zoom_factor: float = 1.1</code> Move from left to right across the frame PanUpEffect <code>pan_up</code> <code>zoom_factor: float = 1.1</code> Move from bottom to top across the frame PanDownEffect <code>pan_down</code> <code>zoom_factor: float = 1.1</code> Move from top to bottom across the frame ZoomInEffect <code>zoom_in</code> <code>start_zoom: float = 1.0</code><code>end_zoom: float = 1.1</code> Zoom into the frame ZoomOutEffect <code>zoom_out</code> <code>start_zoom: float = 1.5</code><code>end_zoom: float = 1.4</code> Zoom out of the frame <p>Here are some examples of how to use these effects:</p> <pre><code>from mosaico.effects.factory import create_effect\n\n# Pan effect example\npan_right = create_effect(\n    \"pan_right\",\n    zoom_factor=1.2\n)\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects([pan_right])\n\n# Zoom effect example\nzoom_in = create_effect(\n    \"zoom_in\",\n    start_zoom=1.0,\n    end_zoom=1.3\n)\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects([zoom_in])\n\n# Combining pan and zoom\ncombined_effect = [\n    create_effect(\"pan_right\", zoom_factor=1.1),\n    create_effect(\"zoom_in\", start_zoom=1.0, end_zoom=1.2)\n]\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects(combined_effect)\n</code></pre>"},{"location":"concepts/effects/#creating-custom-effects","title":"Creating Custom Effects","text":"<p>You can create custom effects by implementing the Effect protocol:</p> <pre><code>from moviepy.video.VideoClip import VideoClip\n\nclass CustomFadeEffect:\n    \"\"\"Custom fade effect implementation.\"\"\"\n\n    def __init__(self, fade_duration: float = 1.0):\n        self.fade_duration = fade_duration\n\n    def apply(self, clip: VideoClip) -&gt; VideoClip:\n        \"\"\"Apply custom fade effect.\"\"\"\n        def modify_frame(t):\n            # Custom frame modification logic\n            frame = clip.get_frame(t)\n            alpha = min(1.0, t / self.fade_duration)\n            return frame * alpha\n\n        return clip.fl(modify_frame)\n</code></pre>"},{"location":"concepts/effects/#combining-effects","title":"Combining Effects","text":"<p>Effects can be combined to create complex animations:</p> <pre><code># Create multiple effects\npan_right = create_effect(\"pan_right\")\nzoom_in = create_effect(\"zoom_in\")\n\n# Apply both effects to an asset\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects([pan_right, zoom_in])\n</code></pre>"},{"location":"concepts/effects/#real-world-examples","title":"Real-World Examples","text":""},{"location":"concepts/effects/#ken-burns-effect","title":"Ken Burns Effect","text":"<pre><code># Create a subtle Ken Burns effect\nken_burns = [\n    create_effect(\n        \"zoom_in\",\n        start_zoom=1.0,\n        end_zoom=1.2\n    ),\n    create_effect(\"pan_right\")\n]\n\n# Apply to background image\nbackground_ref = AssetReference.from_asset(background)\\\n    .with_effects(ken_burns)\n</code></pre>"},{"location":"concepts/effects/#title-animation","title":"Title Animation","text":"<pre><code># Create title entrance effect\ntitle_effects = [\n    create_effect(\"zoom_in\", start_zoom=0.8, end_zoom=1.0),\n    create_effect(\"pan_up\")\n]\n\n# Apply to title\ntitle_ref = AssetReference.from_asset(title)\\\n    .with_effects(title_effects)\n</code></pre>"},{"location":"concepts/effects/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Effect Timing <pre><code># Consider clip duration when setting effect parameters\nif clip_duration &lt; 2:\n    zoom_factor = 1.1  # Subtle for short clips\nelse:\n    zoom_factor = 1.3  # More dramatic for longer clips\n</code></pre></p> </li> <li> <p>Performance Considerations <pre><code># Limit number of simultaneous effects\nMAX_EFFECTS = 2\n\nif len(effects) &gt; MAX_EFFECTS:\n    warnings.warn(\"Too many effects may impact performance\")\n</code></pre></p> </li> <li> <p>Effect Combinations <pre><code># Create reusable effect combinations\ndef create_entrance_effects():\n    return [\n        create_effect(\"zoom_in\", start_zoom=0.8),\n        create_effect(\"pan_up\")\n    ]\n</code></pre></p> </li> </ol>"},{"location":"concepts/effects/#conclusion","title":"Conclusion","text":"<p>The Effects System in Mosaico provides a powerful way to add dynamic elements to your video compositions. By understanding and properly using effects, you can create professional-looking videos with engaging visual elements. Whether using built-in effects or creating custom ones, the system's flexibility allows for creative and impactful video productions.</p>"},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#overview","title":"Overview","text":"<p>Mosaico is built around several core concepts that work together to create video compositions:</p> <ul> <li>Media and Assets: Raw content and production-ready elements</li> <li>Positioning System: Placement and layout control</li> <li>Asset References and Scenes: Timeline organization</li> <li>Video Projects: High-level video compositions</li> <li>Script Generators: Automated content creation</li> <li>Effects: Dynamic animations and visual effects</li> </ul>"},{"location":"concepts/media-and-assets/","title":"Media and Assets","text":""},{"location":"concepts/media-and-assets/#overview","title":"Overview","text":"<p>In Mosaico, media and assets are the core building blocks of video production. They represent the raw materials and production-ready elements that make up a video composition. This guide explains the difference between media and assets, how they are used in video production, and the asset type system in Mosaico.</p>"},{"location":"concepts/media-and-assets/#understanding-the-production-pipeline","title":"Understanding the Production Pipeline","text":"<p>In video production with Mosaico, there are two distinct stages of content handling:</p> <ol> <li>Media Stage: Raw Content Collection</li> <li>Asset Stage: Production-Ready Elements</li> </ol> <p>This two-stage approach mirrors professional video production workflows, where raw materials are prepared and transformed into production-ready elements. The glue between these stages are script generators, which will be covered in a later section.</p>"},{"location":"concepts/media-and-assets/#media-objects-raw-materials","title":"Media Objects: Raw Materials","text":"<p>Media objects represent the \"raw materials\" stage of your content:</p> <ul> <li>Raw video clips</li> <li>Unprocessed audio files</li> <li>Original images</li> <li>Plain text content</li> </ul> <pre><code>from mosaico.media import Media\n\n# Collecting raw materials\nbackground = Media.from_path(\"media/background.png\")\nvoice_over = Media.from_path(\"media/narration.wav\")\ngraphics = Media.from_path(\"media/graphics.png\")\nscript = Media.from_path(\"media/script.txt\")\n</code></pre> <p>Think of Media objects as items in your \"media library\" before they're prepared for production.</p>"},{"location":"concepts/media-and-assets/#assets-production-ready-elements","title":"Assets: Production-Ready Elements","text":"<p>Assets are the fundamental building blocks of any video composition in Mosaico and represent the \"production-ready\" stage of a media. They represent different types of media elements that can be combined to create a video, such as images, audio clips, text overlays, and subtitles. Think of assets as the raw materials you need to build your video.</p> <p>Each asset in Mosaico has essentially the same structure of a media object but with additional properties and capabilities, such as type-specific parameters and metadata. Assets are designed to be production-ready and can be directly used in video compositions:</p> <ul> <li>A unique identifier</li> <li>Core content (the actual media data)</li> <li>Type-specific parameters</li> <li>Metadata for additional information</li> <li>Built-in validation and processing capabilities</li> </ul> <pre><code>from mosaico.assets import ImageAsset, AudioAsset\n\n# Instantiating assets\nbackground = ImageAsset.from_path(\"assets/background.png\")\nvoice_over = AudioAsset.from_path(\"assets/narration.wav\")\ngraphics = ImageAsset.from_path(\"assets/graphics.png\")\nsubtitles = [SubtitleAsset.from_data(data) for data in subtitle_data]\n</code></pre>"},{"location":"concepts/media-and-assets/#key-differences","title":"Key Differences","text":"<p>Here's a summary of the key differences between Media and Assets:</p> Aspect Media Objects Assets Purpose Raw content storage and basic handling Video production element handling State Unprocessed, original form Processed, production-ready Properties Basic metadata and content access Production parameters and behaviors Usage Content collection and storage Timeline and composition Integration External system bridging Video rendering system"},{"location":"concepts/media-and-assets/#the-asset-type-system","title":"The Asset Type System","text":"<p>Mosaico implements a flexible and type-safe asset system using a base class that other asset types extend. This hierarchical approach ensures consistency while allowing each asset type to have its specific features and parameters.</p>"},{"location":"concepts/media-and-assets/#base-asset-structure","title":"Base Asset Structure","text":"<p>The base asset class defines the core structure for all asset types in Mosaico. It includes common properties like the asset type and parameters, which are then extended by specific asset types.</p> <pre><code>from mosaico.assets.base import BaseAsset\nfrom pydantic import BaseModel\n\nclass BaseAsset(Media, Generic[T]):\n    type: str\n    params: T\n</code></pre>"},{"location":"concepts/media-and-assets/#types-of-assets","title":"Types of Assets","text":"<p>To create a video composition, you need different types of assets that represent various media elements. Here are some common asset types in Mosaico:</p> <p>Video Assets</p> <p>While planned, video assets are not currently implemented in Mosaico as their integration architecture is still being discussed. They will be added soon in future releases.</p>"},{"location":"concepts/media-and-assets/#audio","title":"Audio","text":"<p>Audio assets manage all sound elements in your video, including narration, music, sound effects, and voice-overs. They include basic properties like duration, sample rate, channels, volume, and cropping points. These help you control how audio plays in your video while keeping professional quality standards.</p> <p>Example usage:</p> <pre><code>from mosaico.assets import AudioAsset, AudioAssetParams\n\n# Create an audio asset with specific volume\naudio = AudioAsset.from_path(\n    \"narration.mp3\",\n    params=AudioAssetParams(volume=0.8)\n)\n</code></pre>"},{"location":"concepts/media-and-assets/#image","title":"Image","text":"<p>Image assets handle static visuals like backgrounds, overlays, logos, and photos in your video. They come with key properties to control how they appear: size (width and height), position, layer order (z-index), cropping, and background mode. These properties let you precisely control how images look and work together in your video.</p> <p>Example usage: <pre><code>from mosaico.assets import ImageAsset, ImageAssetParams\n\n# Create an image asset with positioning\nimage = ImageAsset.from_path(\n    \"background.jpg\",\n    params=ImageAssetParams(\n        position=AbsolutePosition(x=100, y=100),\n        as_background=True\n    )\n)\n</code></pre></p>"},{"location":"concepts/media-and-assets/#text","title":"Text","text":"<p>Text assets let you add titles, captions, and other text elements to your videos. They include styling options like fonts, colors, alignments, and effects such as shadows and strokes. This gives you full control over how text looks and appears in your video while maintaining professional quality.</p> <p>Example usage: <pre><code>from mosaico.assets import TextAsset, TextAssetParams\n\n# Create styled text\ntext = TextAsset.from_data(\n    \"Welcome to My Video\",\n    params=TextAssetParams(\n        font_size=48,\n        font_color=Color(\"white\"),\n        align=\"center\"\n    )\n)\n</code></pre></p>"},{"location":"concepts/media-and-assets/#subtitles","title":"Subtitles","text":"<p>Subtitle assets are specialized text assets designed for video captioning. They handle dialog subtitles, closed captions, translations, and timed text overlays. You can adjust their positioning, font sizes, and background colors. They include features for readability and multi-language support to create accessible videos.</p> <p>Example usage: <pre><code>from mosaico.assets import SubtitleAsset\n\n# Create a subtitle with proper positioning\nsubtitle = SubtitleAsset.from_data(\n    \"This is a subtitle\",\n    params=TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\"),\n        font_size=36\n    )\n)\n</code></pre></p>"},{"location":"concepts/media-and-assets/#working-with-assets","title":"Working with Assets","text":"<p>Given that you already have a collection of assets, you can now start working with them to create your video composition.</p> <p>A common pipeline for working with assets in Mosaico involves loading, managing, and combining assets to create a video sequence. The later will be covered in another section, but here is how you can perform basic operations with assets solely.</p>"},{"location":"concepts/media-and-assets/#loading-assets","title":"Loading Assets","text":"<p>For the video composition process to start, you need to load your media into assets. If you already know where and how a certain content should be displayed, you can directly create the corresponding assets by calling the asset type class methods or using the asset factory system.</p> From filesFrom raw dataFrom factoryFrom existing media <pre><code>from mosaico.assets import ImageAsset\n\nimage = ImageAsset.from_path(\"logo.png\")\n</code></pre> <pre><code>from mosaico.assets import TextAsset\n\ntext = TextAsset.from_data(\"Hello World\")\n</code></pre> <pre><code>from mosaico.assets import create_asset\n\nasset = create_asset(\"image\", path=\"logo.png\")\n</code></pre> <pre><code>from mosaico.assets.utils import convert_media_to_asset\n\nasset = convert_media_to_asset(media_object)\n</code></pre>"},{"location":"concepts/media-and-assets/#managing-asset-parameters","title":"Managing Asset Parameters","text":"<p>All assets have parameters that control their appearance and behavior. You can update these parameters to customize how assets are displayed in your video composition.</p> <pre><code># Update text styling\ntext_asset = text_asset.with_params({\n    \"font_size\": 48,\n    \"font_color\": \"#FFFFFF\",\n    \"align\": \"center\"\n})\n</code></pre>"},{"location":"concepts/media-and-assets/#best-practices","title":"Best Practices","text":"<p>When working with assets, consider the following best practices to ensure your video composition is well-organized and efficient:</p> <ol> <li> <p>Organization</p> <ul> <li>Use meaningful asset IDs</li> <li>Group related assets together</li> <li>Maintain clear asset hierarchies</li> </ul> </li> <li> <p>Performance</p> <ul> <li>Optimize image sizes before loading</li> <li>Use appropriate audio formats</li> <li>Clean up unused assets</li> </ul> </li> <li> <p>Maintainability</p> <ul> <li>Document asset metadata</li> <li>Use consistent naming conventions</li> <li>Keep asset parameters organized</li> </ul> </li> <li> <p>Reusability</p> <ul> <li>Create reusable asset templates</li> <li>Share common parameters</li> <li>Use asset references effectively</li> </ul> </li> </ol>"},{"location":"concepts/media-and-assets/#workflow-benefits","title":"Workflow Benefits","text":"<p>This two-stage approach provides several advantages:</p> <ol> <li> <p>Clean Separation of Concerns</p> <ul> <li>Media handling is separated from production logic</li> <li>Clear distinction between raw and processed content</li> <li>Easier content management</li> </ul> </li> <li> <p>Flexible Content Pipeline</p> <ul> <li>Raw content can be processed differently for different uses</li> <li>Same media can create different types of assets</li> <li>Easy integration with external content sources</li> </ul> </li> <li> <p>Professional Workflow</p> <ul> <li>Mirrors professional video production processes</li> <li>Clear stages for content preparation</li> <li>Organized asset management</li> </ul> </li> <li> <p>Resource Optimization</p> <ul> <li>Raw content is processed only when needed</li> <li>Multiple assets can reference same media</li> <li>Efficient resource usage</li> </ul> </li> </ol>"},{"location":"concepts/media-and-assets/#conclusion","title":"Conclusion","text":"<p>Understanding this distinction between Media and Assets is fundamental to working effectively with Mosaico, as it reflects the natural progression from raw content to finished video production.</p>"},{"location":"concepts/positioning/","title":"Positioning System","text":"<p>Prerequisites</p> <ul> <li>Assets</li> </ul>"},{"location":"concepts/positioning/#overview","title":"Overview","text":"<p>The Positioning System in Mosaico provides a flexible way to place visual elements (like images and text) in your video composition. It offers three distinct positioning strategies, each suited for different use cases.</p>"},{"location":"concepts/positioning/#positioning-types","title":"Positioning Types","text":""},{"location":"concepts/positioning/#absolute-positioning-pixel-based","title":"Absolute Positioning (Pixel-Based)","text":"<p>Precise positioning using exact pixel coordinates from the top-left corner of the frame.</p> <pre><code>from mosaico.positioning import AbsolutePosition\n\nclass AbsolutePosition:\n    type: Literal[\"absolute\"] = \"absolute\"\n    x: NonNegativeInt = 0          # Pixels from left\n    y: NonNegativeInt = 0          # Pixels from top\n</code></pre> <p>Example Usage: <pre><code># Position an element 100 pixels from left, 50 from top\nlogo_position = AbsolutePosition(x=100, y=50)\n</code></pre></p>"},{"location":"concepts/positioning/#relative-positioning-percentage-based","title":"Relative Positioning (Percentage-Based)","text":"<p>Position elements using percentages of the frame dimensions.</p> <pre><code>from mosaico.positioning import RelativePosition\n\nclass RelativePosition:\n    type: Literal[\"relative\"] = \"relative\"\n    x: NonNegativeFloat = 0.5      # 0.0 to 1.0 (left to right)\n    y: NonNegativeFloat = 0.5      # 0.0 to 1.0 (top to bottom)\n</code></pre> <p>Example Usage: <pre><code># Center an element (50% from left and top)\ncentered_position = RelativePosition(x=0.5, y=0.5)\n\n# Position at bottom-right corner\ncorner_position = RelativePosition(x=1.0, y=1.0)\n</code></pre></p> <p>Use Cases:</p> <ul> <li>Responsive layouts</li> <li>Resolution-independent positioning</li> <li>Dynamic compositions</li> <li>Adaptable designs</li> </ul>"},{"location":"concepts/positioning/#region-positioning-named-regions","title":"Region Positioning (Named Regions)","text":"<p>Position elements using predefined regions of the frame.</p> <pre><code>from mosaico.positioning import RegionPosition\n\nclass RegionPosition:\n    type: Literal[\"region\"] = \"region\"\n    x: Literal[\"left\", \"center\", \"right\"] = \"center\"\n    y: Literal[\"top\", \"center\", \"bottom\"] = \"center\"\n</code></pre> <p>Example Usage: <pre><code># Position in bottom-center (typical for subtitles)\nsubtitle_position = RegionPosition(x=\"center\", y=\"bottom\")\n\n# Position in top-right corner\ntitle_position = RegionPosition(x=\"right\", y=\"top\")\n</code></pre></p> <p>Use Cases:</p> <ul> <li>Subtitles</li> <li>Lower thirds</li> <li>Standard video elements</li> <li>Quick positioning</li> </ul>"},{"location":"concepts/positioning/#position-conversion","title":"Position Conversion","text":"<p>Mosaico provides utilities to convert between position types:</p> <pre><code>from mosaico.positioning.utils import convert_position_to_absolute\n\n# Convert any position type to absolute coordinates\nabsolute_pos = convert_position_to_absolute(\n    position=RegionPosition(x=\"center\", y=\"bottom\"),\n    frame_size=(1920, 1080)\n)\n</code></pre>"},{"location":"concepts/positioning/#real-world-examples","title":"Real-World Examples","text":""},{"location":"concepts/positioning/#logo-placement","title":"Logo Placement","text":"<pre><code># Create an image asset with absolute positioning\nlogo = create_asset(\n    \"image\",\n    path=\"logo.png\",\n    params=ImageAssetParams(\n        position=AbsolutePosition(x=50, y=30)\n    )\n)\n</code></pre>"},{"location":"concepts/positioning/#centered-title","title":"Centered Title","text":"<pre><code># Create a centered text title\ntitle = create_asset(\n    \"text\",\n    data=\"Welcome\",\n    params=TextAssetParams(\n        position=RelativePosition(x=0.5, y=0.5),\n        align=\"center\"\n    )\n)\n</code></pre>"},{"location":"concepts/positioning/#subtitles","title":"Subtitles","text":"<pre><code># Create subtitles in standard position\nsubtitle = create_asset(\n    \"subtitle\",\n    data=\"Hello world\",\n    params=TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\")\n    )\n)\n</code></pre>"},{"location":"concepts/positioning/#position-validation-and-helpers","title":"Position Validation and Helpers","text":""},{"location":"concepts/positioning/#type-checking","title":"Type Checking","text":"<pre><code>from mosaico.positioning.utils import (\n    is_absolute_position,\n    is_relative_position,\n    is_region_position\n)\n\n# Check position types\nif is_region_position(position):\n    # Handle region position\n    pass\nelif is_relative_position(position):\n    # Handle relative position\n    pass\nelif is_absolute_position(position):\n    # Handle absolute position\n    pass\n</code></pre>"},{"location":"concepts/positioning/#region-position-creation","title":"Region Position Creation","text":"<pre><code># Create from string shorthand\nposition = RegionPosition.from_string(\"bottom\")  # center-bottom\nposition = RegionPosition.from_string(\"right\")   # right-center\n</code></pre>"},{"location":"concepts/positioning/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Choosing the Right Position Type</p> <ul> <li>Use Absolute for pixel-perfect requirements</li> <li>Use Relative for resolution-independent layouts</li> <li>Use Region for standard video elements</li> </ul> </li> <li> <p>Resolution Considerations <pre><code># Bad: Hard-coded absolute positions\nposition = AbsolutePosition(x=1920, y=1080)\n\n# Good: Relative positioning for flexibility\nposition = RelativePosition(x=1.0, y=1.0)\n</code></pre></p> </li> <li> <p>Maintainable Layouts <pre><code># Create reusable positions\nLOWER_THIRD_POSITION = RegionPosition(x=\"left\", y=\"bottom\")\nWATERMARK_POSITION = AbsolutePosition(x=50, y=50)\n</code></pre></p> </li> <li> <p>Dynamic Positioning <pre><code># Adjust position based on content\ndef get_title_position(title_length: int) -&gt; Position:\n    if title_length &gt; 50:\n        return RegionPosition(x=\"center\", y=\"top\")\n    return RelativePosition(x=0.5, y=0.3)\n</code></pre></p> </li> </ol>"},{"location":"concepts/positioning/#conclusion","title":"Conclusion","text":"<p>Understanding and effectively using the positioning system is crucial for creating professional-looking video compositions. The flexibility of having three positioning strategies allows you to handle any layout requirement while maintaining clean and maintainable code.</p>"},{"location":"concepts/script-generators/","title":"Script Generators","text":"<p>Prerequisites</p> <ul> <li>Media</li> <li>Speech Synthesizers</li> </ul>"},{"location":"concepts/script-generators/#overview","title":"Overview","text":"<p>Script Generators in Mosaico provide an automated way to create video shooting scripts from media collections. They're particularly useful for converting content like news articles into structured video scripts that can be used to generate complete video projects.</p>"},{"location":"concepts/script-generators/#script-generation-system","title":"Script Generation System","text":"<p>The system consists of three main components:</p> <ol> <li>Script Generator Protocol: Defines the interface for script generators</li> <li>Shooting Script: Represents the structured output generated by the script generator</li> <li>Shot: Represents individual segments of the script</li> </ol>"},{"location":"concepts/script-generators/#the-scriptgenerator-protocol","title":"The <code>ScriptGenerator</code> Protocol","text":"<p>Key characteristics:</p> <ul> <li>Runtime checkable protocol</li> <li>Flexible input handling</li> <li>Standardized output format</li> <li>Extensible design</li> </ul> <pre><code>from mosaico.script_generators.protocol import ScriptGenerator\nfrom mosaico.media import Media\n\n@runtime_checkable\nclass ScriptGenerator(Protocol):\n    def generate(self, media: Sequence[Media], **kwargs: Any) -&gt; ShootingScript:\n        \"\"\"Generate a shooting script from media.\"\"\"\n        ...\n</code></pre>"},{"location":"concepts/script-generators/#shooting-scripts","title":"Shooting Scripts","text":"<p>A <code>ShootingScript</code> represents a complete video script with multiple shots. The idea is to provide a structured format that can be used to generate video projects. The shooting script format was chosen to be simple and flexible, while still capturing the essential elements of a video script.</p> <p>The main components of a shooting script are:</p> <ul> <li>Title: The title of the script</li> <li>Description: An optional description of the script content</li> <li>Shots: Collection of shots that make up the script</li> </ul> <p>These components provide a high-level overview of the video content and the individual segments that will be included in the final video.</p>"},{"location":"concepts/script-generators/#shots","title":"Shots","text":"<p>Individual shots represent distinct segments in the script that can be used to create video projects. Each shot has the following properties:</p> <ul> <li>Number: A unique identifier for the shot</li> <li>Description: A brief description of the shot content</li> <li>Start Time: The start time of the shot in the video</li> <li>End Time: The end time of the shot in the video</li> <li>Subtitle: Optional subtitles for the shot</li> <li>Media References: References to the media used in the shot</li> <li>Effects: Optional effects applied to the shot</li> </ul> <p>Warning</p> <p>Media references are not objects such as <code>AssetReference</code>, but rather simple strings that can be used to identify media objects in a media list. They should not be confused with actual media objects or <code>AssetReference</code> objects.</p>"},{"location":"concepts/script-generators/#using-script-generators","title":"Using Script Generators","text":""},{"location":"concepts/script-generators/#basic-script-generation","title":"Basic Script Generation","text":"<pre><code># Create generator\ngenerator = MyVideoScriptGenerator(\n    context=\"News article content...\",\n    num_paragraphs=10\n)\n\n# Generate script from media\nscript = generator.generate(\n    media=[\n        image1_media,\n        image2_media,\n        video_media\n    ]\n)\n</code></pre>"},{"location":"concepts/script-generators/#creating-video-projects","title":"Creating Video Projects","text":"<pre><code>from mosaico.video.project import VideoProject\n\n# Generate project from script\nproject = VideoProject.from_script_generator(\n    script_generator=generator,\n    media=media_files,\n    speech_synthesizer=tts_engine,\n    audio_transcriber=transcriber\n)\n</code></pre>"},{"location":"concepts/script-generators/#custom-script-generator","title":"Custom Script Generator","text":"<pre><code>class CustomScriptGenerator:\n    \"\"\"Custom implementation of ScriptGenerator.\"\"\"\n\n    def generate(self,\n                media: Sequence[Media],\n                **kwargs: Any) -&gt; ShootingScript:\n        # Custom script generation logic\n        shots = [\n            Shot(\n                number=1,\n                description=\"Opening shot\",\n                start_time=0,\n                end_time=5,\n                subtitle=\"Welcome\",\n                media_references=[0],\n                effects=[\"zoom_in\"]\n            )\n        ]\n\n        return ShootingScript(\n            title=\"Custom Video\",\n            shots=shots\n        )\n</code></pre>"},{"location":"concepts/script-generators/#best-practices","title":"Best Practices","text":"<p>Media Organization</p> <ul> <li>Provide clear media descriptions</li> <li>Order media logically</li> <li>Include relevant metadata</li> </ul> <p>Shot Management</p> <ul> <li>Keep shots focused and concise</li> <li>Ensure logical transitions</li> <li>Match media to content</li> </ul>"},{"location":"concepts/script-generators/#working-with-generated-scripts","title":"Working with Generated Scripts","text":""},{"location":"concepts/script-generators/#script-analysis","title":"Script Analysis","text":"<pre><code># Analyze generated script\nprint(f\"Script duration: {script.duration}s\")\nprint(f\"Number of shots: {script.shot_count}\")\n\nfor shot in script.shots:\n    print(f\"Shot {shot.number}: {shot.duration}s\")\n    print(f\"Media used: {shot.media_references}\")\n</code></pre>"},{"location":"concepts/script-generators/#script-validation","title":"Script Validation","text":"<pre><code>def validate_script(script: ShootingScript) -&gt; bool:\n    \"\"\"Validate script properties.\"\"\"\n    if script.duration &gt; max_duration:\n        return False\n\n    if not all(shot.subtitle for shot in script.shots):\n        return False\n\n    return True\n</code></pre>"},{"location":"concepts/script-generators/#media-reference-checking","title":"Media Reference Checking","text":"<pre><code>def check_media_references(\n    script: ShootingScript,\n    media: Sequence[Media]\n) -&gt; bool:\n    \"\"\"Verify all media references are valid.\"\"\"\n    media_count = len(media)\n\n    for shot in script.shots:\n        if any(ref &gt;= media_count for ref in shot.media_references):\n            return False\n\n    return True\n</code></pre>"},{"location":"concepts/script-generators/#integration-with-other-components","title":"Integration with Other Components","text":""},{"location":"concepts/script-generators/#speech-synthesis","title":"Speech Synthesis","text":"<pre><code># Generate speech for subtitles\nspeech_assets = speech_synthesizer.synthesize(\n    [shot.subtitle for shot in script.shots]\n)\n</code></pre>"},{"location":"concepts/script-generators/#effect-application","title":"Effect Application","text":"<pre><code># Apply effects from script\nfor shot in script.shots:\n    effects = [create_effect(effect) for effect in shot.effects]\n    # Apply to corresponding assets\n</code></pre>"},{"location":"concepts/script-generators/#conclusion","title":"Conclusion","text":"<p>Understanding script generators is crucial for automated video production in Mosaico. They provide a bridge between raw content and structured video projects, enabling efficient content transformation while maintaining creative control and quality standards.</p>"},{"location":"concepts/speech-synthesizers/","title":"Speech Synthesizers","text":"<p>Prerequisites</p> <ul> <li>Media</li> <li>Assets</li> <li>Video Projects</li> </ul>"},{"location":"concepts/speech-synthesizers/#overview","title":"Overview","text":"<p>Speech Synthesizers in Mosaico are components that convert text into natural-sounding speech for video narration. The system supports multiple synthesizer implementations and offers flexible configuration options.</p>"},{"location":"concepts/speech-synthesizers/#working-with-synthesizers","title":"Working with Synthesizers","text":"<pre><code>from mosaico.speech_synthesizers import OpenAISpeechSynthesizer\n\n# Create synthesizer with configuration\ntts = OpenAISpeechSynthesizer(\n    model=\"tts-1\",              # TTS model to use\n    voice=\"alloy\",              # Voice selection\n    speed=1.0,                  # Speech speed\n    api_key=\"your_api_key\"      # Optional API key\n)\n\n# Generate speech\naudio_assets = tts.synthesize(\n    texts=[\"Welcome to our video\", \"This is a demo\"],\n    audio_params=AudioAssetParams(volume=0.8)\n)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#integration-with-video-projects","title":"Integration with Video Projects","text":""},{"location":"concepts/speech-synthesizers/#basic-integration","title":"Basic Integration","text":"<pre><code># Create project with speech\nproject = (\n    VideoProject.from_script_generator(\n        script_generator=generator,\n        media=media_files,\n    )\n    .add_narration(tts_engine)\n)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#manual-speech-addition","title":"Manual Speech Addition","text":"<pre><code># Generate speech for specific text\nspeech_asset = tts.synthesize([\"Welcome message\"])[0]\n\n# Add to project\nproject = (\n    project\n    .add_assets(speech_asset)\n    .add_timeline_events(\n        AssetReference.from_asset(speech_asset)\n            .with_start_time(0)\n            .with_end_time(speech_asset.duration)\n    )\n)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#custom-speech-parameters","title":"Custom Speech Parameters","text":""},{"location":"concepts/speech-synthesizers/#audio-configuration","title":"Audio Configuration","text":"<pre><code># Configure audio parameters\nparams = AudioAssetParams(\n    volume=0.8,         # Set volume level\n    crop=(0, 30)       # Use specific segment\n)\n\n# Generate with parameters\nassets = tts.synthesize(\n    texts=[\"Narration text\"],\n    audio_params=params\n)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#voice-customization","title":"Voice Customization","text":"<pre><code># OpenAI customization\nopenai_tts = OpenAISpeechSynthesizer(\n    model=\"tts-1-hd\",    # High-definition model\n    voice=\"nova\",        # Different voice\n    speed=1.2           # Faster speech\n)\n\n# ElevenLabs customization\nelevenlabs_tts = ElevenLabsSpeechSynthesizer(\n    voice_id=\"custom_voice\",\n    voice_stability=0.7,\n    voice_similarity_boost=0.8,\n    voice_speaker_boost=True\n)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#common-use-cases","title":"Common Use Cases","text":""},{"location":"concepts/speech-synthesizers/#video-narration","title":"Video Narration","text":"<pre><code># Generate news narration\nnews_tts = OpenAISpeechSynthesizer(\n    voice=\"nova\",     # Clear, professional voice\n    speed=1.1        # Slightly faster for news\n)\n\nnarration = news_tts.synthesize(\n    [shot.subtitle for shot in news_script.shots]\n)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#tutorial-voice-over","title":"Tutorial Voice-Over","text":"<pre><code># Tutorial narration with pauses\ntutorial_tts = ElevenLabsSpeechSynthesizer(\n    voice_id=\"tutorial_voice\",\n    voice_stability=0.8,    # More consistent\n    voice_style=0.3        # Less emotional\n)\n\n# Add pauses between steps\ntutorial_texts = [f\"{text}...\" for text in tutorial_steps]\ntutorial_audio = tutorial_tts.synthesize(tutorial_texts)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#multi-language-support","title":"Multi-Language Support","text":"<pre><code># Create synthesizers for different languages\ntts_en = OpenAISpeechSynthesizer(language_code=\"en\")\ntts_es = OpenAISpeechSynthesizer(language_code=\"es\")\ntts_fr = OpenAISpeechSynthesizer(language_code=\"fr\")\n\n# Generate multi-language audio\naudio_en = tts_en.synthesize(texts_en)\naudio_es = tts_es.synthesize(texts_es)\naudio_fr = tts_fr.synthesize(texts_fr)\n</code></pre>"},{"location":"concepts/speech-synthesizers/#conclusion","title":"Conclusion","text":"<p>Understanding speech synthesizers in Mosaico enables the creation of professional-quality narration for various video types. The flexible synthesizer system and configuration options allow for customized voice output suitable for different content needs.</p>"},{"location":"concepts/video-projects/","title":"Video Projects","text":"<p>Prerequisites</p> <ul> <li>Assets</li> <li>Asset References</li> <li>Scenes</li> <li>Script Generators</li> </ul>"},{"location":"concepts/video-projects/#overview","title":"Overview","text":"<p>A video project in Mosaico represents a complete video composition that consists of three main components:</p> <p>Project Configuration</p> <ul> <li>Basic project metadata and settings</li> <li>Video output specifications</li> <li>Technical parameters</li> </ul> <p>Asset Collection</p> <ul> <li>Registry of all media elements</li> <li>Mapping between asset IDs and asset objects</li> <li>Asset validation and management</li> </ul> <p>Timeline</p> <ul> <li>Sequence of events (scenes and asset references)</li> <li>Timing and synchronization</li> <li>Event organization</li> </ul>"},{"location":"concepts/video-projects/#project-configuration","title":"Project Configuration","text":"<p>A video can be configured to a specific set of parameters that define its appearance and behavior. The <code>VideoProjectConfig</code> class defines the basic settings for your video:</p> <pre><code>from mosaico.video.project import VideoProjectConfig\n\nconfig = VideoProjectConfig(\n    name=\"My Project\",          # Project name\n    version=1,                  # Project version\n    resolution=(1920, 1080),    # Video dimensions\n    fps=30                      # Frames per second\n)\n</code></pre> <p>For instance, to change the project resolution, just update the <code>resolution</code> attribute...</p> <pre><code>config.resolution = (1280, 720)\n</code></pre> <p>... and there you have it: the video project will be rendered at the new resolution.</p>"},{"location":"concepts/video-projects/#creating-video-projects","title":"Creating Video Projects","text":"<p>There are three main ways to create a video project:</p>"},{"location":"concepts/video-projects/#direct-creation","title":"Direct Creation","text":"<p>The user already knows the project structure, the assets configuration and their disposition in the timeline. In this case, the project can be created directly:</p> <pre><code>from mosaico.video.project import VideoProject\n\nproject = VideoProject(\n    config=VideoProjectConfig(\n        name=\"Direct Creation Example\",\n        resolution=(1920, 1080)\n    )\n)\n</code></pre>"},{"location":"concepts/video-projects/#script-based-generation","title":"Script-Based Generation","text":"<p>The user wants to generate a video project based on a script that defines the project structure. The script can be generated by a script generator, which is a class that implements the <code>ScriptGenerator</code> protocol:</p> <p>About Script Generators</p> <p>They are the main bridge between video projects and AI. The <code>ScriptGenerator</code> protocol lies at the core of the video project generation process, as it defines the structure of the script that will be used to create the video project and spares the user from having to manually define the project structure.</p> <pre><code>project = VideoProject.from_script_generator(\n    script_generator=script_generator,  # ScriptGenerator instance\n    media=media_files,                  # Sequence of Media objects\n    config=video_config,                # Optional configuration\n    speech_synthesizer=tts_engine,      # Optional speech synthesis\n    audio_transcriber=transcriber,      # Optional transcription\n    background_audio=bg_music           # Optional background music\n)\n</code></pre>"},{"location":"concepts/video-projects/#loading-from-file","title":"Loading from File","text":"<p>One of the main features of Mosaico is the ability to serialize and deserialize video projects to and from files. This allows users to save their projects and load them later, or share them with others.</p> <p>Based on the YAML format, the <code>VideoProject</code> class provides methods to load and save projects:</p> <pre><code># Load from YAML\nproject = VideoProject.from_file(\"project.yml\")\n\n# Save to YAML\nproject.to_file(\"project.yml\")\n</code></pre>"},{"location":"concepts/video-projects/#managing-project-assets","title":"Managing Project Assets","text":"<p>The <code>VideoProject</code> provides methods to manage assets, such as adding, removing, and retrieving them. The class is responsible for guaranteeing that all assets are correctly linked to the project, have valid references in the timeline and that they are available when needed.</p>"},{"location":"concepts/video-projects/#adding-assets","title":"Adding Assets","text":"<pre><code># Add single asset\nproject.add_assets(background_image)\n\n# Add multiple assets\nproject.add_assets([\n    main_video,\n    background_music,\n    subtitle_text\n])\n\n# Add with custom IDs\nproject.add_assets({\n    \"background\": background_image,\n    \"music\": background_music\n})\n</code></pre>"},{"location":"concepts/video-projects/#retrieving-assets","title":"Retrieving Assets","text":"<pre><code># Get asset by ID\nasset = project.get_asset(\"background\")\n</code></pre>"},{"location":"concepts/video-projects/#removing-assets","title":"Removing Assets","text":"<pre><code># Remove asset\n# This will also remove all references to the asset in the timeline\nproject.remove_asset(\"background\")\n</code></pre>"},{"location":"concepts/video-projects/#timeline-management","title":"Timeline Management","text":"<p>The timeline consists of events (scenes and asset references) that define when and how assets appear in the video.</p>"},{"location":"concepts/video-projects/#adding-timeline-events","title":"Adding Timeline Events","text":"<pre><code># Add a scene\nproject.add_timeline_events(\n    Scene(\n        title=\"Opening Scene\",\n        asset_references=[\n            AssetReference.from_asset(background)\n                .with_start_time(0)\n                .with_end_time(5),\n            AssetReference.from_asset(title_text)\n                .with_start_time(1)\n                .with_end_time(4)\n        ]\n    )\n)\n\n# Add individual asset reference\nproject.add_timeline_events(\n    AssetReference.from_asset(background_music)\n        .with_start_time(0)\n        .with_end_time(project.duration)\n)\n</code></pre>"},{"location":"concepts/video-projects/#removing-timeline-events","title":"Removing Timeline Events","text":"<pre><code># Remove event by index\nproject.remove_timeline_event(0)\n</code></pre>"},{"location":"concepts/video-projects/#timeline-navigation","title":"Timeline Navigation","text":"<pre><code># Get total duration\nduration = project.duration\n\n# Get specific event\nevent = project.get_timeline_event(0)\n\n# Iterate through timeline\nfor event in project.iter_timeline():\n    print(f\"Event at {event.start_time}s\")\n</code></pre>"},{"location":"concepts/video-projects/#special-features","title":"Special Features","text":"<p>Here are some special capabilities that Mosaico provides to enhance video projects:</p>"},{"location":"concepts/video-projects/#subtitle-generation","title":"Subtitle Generation","text":"<pre><code># Add subtitles from transcription\nproject.add_subtitles_from_transcription(\n    transcription=transcription,\n    max_duration=5,  # Maximum subtitle duration\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    )\n)\n</code></pre>"},{"location":"concepts/video-projects/#subtitle-parameters-batch-updates","title":"Subtitle Parameters Batch Updates","text":"<pre><code># Update subtitle parameters globally\nproject.with_subtitle_params(\n    TextAssetParams(\n        font_size=48,\n        stroke_width=2\n    )\n)\n</code></pre>"},{"location":"concepts/video-projects/#method-chaining","title":"Method Chaining","text":"<p>The <code>VideoProject</code> class supports method chaining, which allows you to call multiple methods on an object in a single line. This can make your code more concise and easier to read.</p> <pre><code>project = (\n    VideoProject(config=VideoProjectConfig())\n    .add_assets([background_image, title_text, background_music])\n    .add_timeline_events([\n        AssetReference.from_asset(background_image)\n            .with_start_time(0)\n            .with_end_time(10),\n        AssetReference.from_asset(title_text)\n            .with_start_time(1)\n            .with_end_time(9)\n    ])\n)\n</code></pre>"},{"location":"concepts/video-projects/#best-practices","title":"Best Practices","text":"<p>Asset Organization</p> <ul> <li>Use meaningful asset IDs</li> <li>Group related assets together</li> <li>Keep track of asset dependencies</li> </ul> <p>Timeline Structure</p> <ul> <li>Organize events chronologically</li> <li>Use scenes for related content</li> <li>Maintain clear timing relationships</li> </ul> <p>Project Management</p> <ul> <li>Save projects regularly</li> <li>Version control project files</li> <li>Document project structure</li> </ul>"},{"location":"concepts/video-projects/#conclusion","title":"Conclusion","text":"<p>This documentation reflects the actual implementation of <code>VideoProject</code> in Mosaico, focusing on practical usage patterns and best practices. The examples are designed to work with the current codebase and demonstrate common video production workflows.</p>"},{"location":"cookbook/adding-audio/","title":"Adding Audio","text":"cookbook/adding_audio.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.audio import AudioAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [...]\nimage_refs = [...]\n\n\naudios = [\n    create_asset(\"audio\", path=\"human_music.mp3\"),\n    create_asset(\"audio\", path=\"human_music_2.mp3\"),\n    create_asset(\"audio\", path=\"human_music_3.mp3\"),\n    create_asset(\"audio\", path=\"human_music_4.mp3\"),\n]\n\n# Mixing Audio using the same Time Span\nmusic_1 = (\n    AssetReference.from_asset(audios[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\nmusic_2 = (\n    AssetReference.from_asset(audios[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\nmusic_3 = (\n    AssetReference.from_asset(audios[2])\n    .with_start_time(10)\n    .with_end_time(15)\n    .with_params(params=AudioAssetParams(volume=1))\n)\nmusic_4 = (\n    AssetReference.from_asset(audios[3])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\n# Create scene\nscene = Scene(asset_references=image_refs + [music_1, music_2, music_3, music_4])\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_assets(audios).add_timeline_events(scene)\n</code></pre>"},{"location":"cookbook/adding-images/","title":"Adding Images","text":"cookbook/adding_images.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import ZoomInEffect, ZoomOutEffect\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"photo_1.jpg\"),\n    create_asset(\"image\", path=\"photo_2.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(5)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()]),\n    AssetReference.from_asset(images[1])\n    .with_start_time(5)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()]),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_timeline_events(scene)\n</code></pre>"},{"location":"cookbook/adding-subtitles/","title":"Adding Subtitles","text":"cookbook/adding_subtitles.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.assets.text import TextAssetParams\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Subtitles\nsubtitles = [\n    create_asset(\n        \"text\",\n        data=\"First Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=1),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"right\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene center Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Third Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"left\", z_index=2),\n    ),\n]\n\n# Create references\nsubtitles_refs = [\n    AssetReference.from_asset(subtitles[0]).with_start_time(0).with_end_time(10),\n    AssetReference.from_asset(subtitles[1]).with_start_time(10).with_end_time(20),\n    AssetReference.from_asset(subtitles[2]).with_start_time(10).with_end_time(20),\n    AssetReference.from_asset(subtitles[3]).with_start_time(20).with_end_time(30),\n]\n\n# Create scene\nscene_1 = Scene(asset_references=[subtitles_refs[0]])\nscene_2 = Scene(asset_references=[subtitles_refs[1], subtitles_refs[2]])\nscene_3 = Scene(asset_references=[subtitles_refs[3]])\n\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig()).add_assets(subtitles).add_timeline_events([scene_1, scene_2, scene_3])\n)\n</code></pre>"},{"location":"cookbook/basic-video/","title":"Basic Video","text":"cookbook/basic_video.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create scene\nscene = Scene(asset_references=[image_ref, text_ref])\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets([image, text]).add_timeline_events(scene)\n</code></pre>"},{"location":"cookbook/creating-custom-effects/","title":"Creating Custom Effects","text":"cookbook/creating_custom_effects.py<pre><code>from typing import Annotated, Literal\n\nfrom pydantic import Field\nfrom pydantic.functional_validators import model_validator\nfrom typing_extensions import Self\n\nfrom mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import BaseZoomEffect, ZoomInEffect\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\nclass CustomZoomOutEffect(BaseZoomEffect):\n    \"\"\"Zoom-in effect for video clips.\"\"\"\n\n    type: Literal[\"zoom_in\"] = \"zoom_in\"\n    \"\"\"Effect type. Must be \"zoom_in\".\"\"\"\n\n    start_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.0\n    \"\"\"Starting zoom scale (1.0 is original size).\"\"\"\n\n    end_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.1\n    \"\"\"Ending zoom scale.\"\"\"\n\n    @model_validator(mode=\"after\")\n    def _validate_zoom_in(self) -&gt; Self:\n        if self.start_zoom &gt;= self.end_zoom:\n            raise ValueError(\"For zoom-in, start_zoom must be less than end_zoom\")\n        return self\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"photo_1.jpg\"),\n    create_asset(\"image\", path=\"photo_2.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(5)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()]),\n    AssetReference.from_asset(images[1])\n    .with_start_time(5)\n    .with_end_time(10)\n    .with_effects(effects=[CustomZoomOutEffect(), PanRightEffect()]),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_timeline_events(scene)\n</code></pre>"},{"location":"cookbook/","title":"Cookbook","text":""},{"location":"cookbook/#basic-video-creation","title":"Basic Video Creation","text":"<ul> <li>Basic Video Creation: Simple example of creating a video with background and text</li> <li>Photo Slideshow: Create an animated slideshow with multiple images and music</li> <li>Video from Article: Generate a news video from article text using AI</li> </ul>"},{"location":"cookbook/#asset-management","title":"Asset Management","text":"<ul> <li>Adding Images: Load and manipulate image assets with effects and positioning</li> <li>Adding Audio: Work with audio tracks including mixing and volume control</li> <li>Adding Subtitles: Add synchronized subtitles with custom styling</li> </ul>"},{"location":"cookbook/#advanced-scene-composition","title":"Advanced Scene Composition","text":"<ul> <li>Multilayer Scene: Create complex scenes with multiple layered assets</li> <li>Timed Transitions: Handle timing and transitions between scenes</li> </ul>"},{"location":"cookbook/#effects-and-animation","title":"Effects and Animation","text":"<ul> <li>Creating Custom Effects: Implement custom video effects and animations</li> <li>Text Animation: Animate text elements with effects and timing</li> </ul>"},{"location":"cookbook/#audio-and-speech","title":"Audio and Speech","text":"<ul> <li>Syncing Audio: Synchronize multiple audio tracks with video elements</li> </ul>"},{"location":"cookbook/#project-management","title":"Project Management","text":"<ul> <li>Project Configuration: Configure video project settings and parameters</li> <li>Timeline Management: Organize and manage timeline events</li> </ul>"},{"location":"cookbook/#external-integrations-wip","title":"External Integrations (WIP)","text":"<p>Integration examples with external frameworks:</p> <ul> <li>Haystack Integration</li> <li>LangChain Integration</li> </ul>"},{"location":"cookbook/multilayer-scene/","title":"Multilayer Scene","text":"cookbook/multilayer_scene.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.image import ImageAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import ZoomInEffect, ZoomOutEffect\nfrom mosaico.positioning import AbsolutePosition, RegionPosition\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"background.jpg\"),\n    create_asset(\"image\", path=\"logo.jpg\"),\n    create_asset(\"image\", path=\"credits.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()])\n    .with_params(params=ImageAssetParams(z_index=0, as_background=True)),\n    AssetReference.from_asset(images[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(params=ImageAssetParams(crop=(0, 0, 120, 120), position=AbsolutePosition(x=10, y=10), z_index=1)),\n    AssetReference.from_asset(images[2])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(\n        params=ImageAssetParams(crop=(120, 120, 220, 220), position=RegionPosition(x=\"right\", y=\"bottom\"), z_index=1)\n    ),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_timeline_events(scene)\n</code></pre>"},{"location":"cookbook/project-config/","title":"Video Project Configuration","text":"cookbook/project_config.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create scene\nscene = Scene(asset_references=[image_ref, text_ref])\n\n# Handle with frame rate\nconfig_1 = VideoProjectConfig(resolution=(1920, 1080), fps=30)\n\nconfig_2 = VideoProjectConfig(resolution=(1080, 1920), fps=60)\n\n# Create projects\nproject_1 = VideoProject(config=config_1).add_assets([image, text]).add_timeline_events(scene)\n\nproject_2 = VideoProject(config=config_2).add_assets([image, text]).add_timeline_events(scene)\n</code></pre>"},{"location":"cookbook/slide-show/","title":"Slide Show","text":"cookbook/slide_show.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"photo_1.jpg\"),\n    create_asset(\"image\", path=\"photo_2.jpg\"),\n    create_asset(\"image\", path=\"photo_3.jpg\"),\n    create_asset(\"image\", path=\"photo_4.jpg\"),\n    create_asset(\"image\", path=\"photo_5.jpg\"),\n    create_asset(\"image\", path=\"photo_6.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(image).with_start_time(i * 5).with_end_time((i + 1) * 5) for i, image in enumerate(images)\n]\n\n\nbackground_music = create_asset(\"audio\", path=\"human_music.mp3\")\naudio_ref = AssetReference.from_asset(background_music).with_start_time(0).with_end_time(len(images) * 5)\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig())\n    .add_assets(images)\n    .add_assets([background_music])\n    .add_timeline_events(scene)\n)\n</code></pre>"},{"location":"cookbook/syncing-audio/","title":"Syncing Audio","text":"cookbook/syncing_audio.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.audio import AudioAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [...]\nimage_refs = [...]\n\n\naudios = [\n    create_asset(\"audio\", path=\"human_music.mp3\"),\n    create_asset(\"audio\", path=\"human_music_2.mp3\"),\n    create_asset(\"audio\", path=\"human_music_3.mp3\"),\n    create_asset(\"audio\", path=\"human_music_4.mp3\"),\n]\n\n# Mixing Audio using the same Time Span\nmusic_1 = (\n    AssetReference.from_asset(audios[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\nmusic_2 = (\n    AssetReference.from_asset(audios[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\nmusic_3 = (\n    AssetReference.from_asset(audios[2])\n    .with_start_time(10)\n    .with_end_time(15)\n    .with_params(params=AudioAssetParams(volume=1))\n)\nmusic_4 = (\n    AssetReference.from_asset(audios[3])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\n# Create scene\nscene_1 = Scene(asset_references=image_refs + [music_1, music_2])\nscene_2 = Scene(asset_references=image_refs + [music_1, music_2])\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig())\n    .add_assets(images)\n    .add_assets(audios)\n    .add_timeline_events([scene_1, scene_2])\n)\n</code></pre>"},{"location":"cookbook/text-animation/","title":"Text Animation","text":"cookbook/text_animation.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.assets.text import TextAssetParams\nfrom mosaico.effects.fade import FadeInEffect, FadeOutEffect\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Subtitles\nsubtitles = [\n    create_asset(\n        \"text\",\n        data=\"First Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=1),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"right\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene center Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Third Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"left\", z_index=2),\n    ),\n]\n\n# Create references\nsubtitles_refs = [\n    AssetReference.from_asset(subtitles[0]).with_start_time(0).with_end_time(10).with_effects(effects=[FadeInEffect()]),\n    AssetReference.from_asset(subtitles[1])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_effects(effects=[FadeOutEffect()]),\n    AssetReference.from_asset(subtitles[2])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_effects(effects=[FadeOutEffect()]),\n    AssetReference.from_asset(subtitles[3])\n    .with_start_time(20)\n    .with_end_time(30)\n    .with_effects(effects=[FadeInEffect()]),\n]\n\n# Create scene\nscene_1 = Scene(asset_references=[subtitles_refs[0]])\nscene_2 = Scene(asset_references=[subtitles_refs[1], subtitles_refs[2]])\nscene_3 = Scene(asset_references=[subtitles_refs[3]])\n\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig()).add_assets(subtitles).add_timeline_events([scene_1, scene_2, scene_3])\n)\n</code></pre>"},{"location":"cookbook/timed-transition/","title":"Timed Transition","text":"cookbook/timed_transition.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.image import ImageAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import ZoomInEffect, ZoomOutEffect\nfrom mosaico.positioning import AbsolutePosition, RegionPosition\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"background.jpg\"),\n    create_asset(\"image\", path=\"logo.jpg\"),\n    create_asset(\"image\", path=\"credits.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()])\n    .with_params(params=ImageAssetParams(z_index=0, as_background=True)),\n    AssetReference.from_asset(images[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(params=ImageAssetParams(crop=(0, 0, 120, 120), position=AbsolutePosition(x=10, y=10), z_index=1)),\n    AssetReference.from_asset(images[2])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(\n        params=ImageAssetParams(crop=(120, 120, 220, 220), position=RegionPosition(x=\"right\", y=\"bottom\"), z_index=1)\n    ),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject_2 = (\n    VideoProject(\n        config=VideoProjectConfig(\n            resolution=(1920, 1080),\n        )\n    )\n    .add_assets(images)\n    .add_timeline_events(scene)\n)\n\n# Create project\nproject_2 = (\n    VideoProject(\n        config=VideoProjectConfig(\n            resolution=(1080, 1920),\n        )\n    )\n    .add_assets(images)\n    .add_timeline_events(scene)\n)\n</code></pre>"},{"location":"cookbook/timeline-management/","title":"Timeline Management","text":"cookbook/timeline_management.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create scene\nscene_1 = Scene(asset_references=[image_ref, text_ref])\nscene_2 = Scene(asset_references=[image_ref, text_ref])\nscene_3 = Scene(asset_references=[image_ref, text_ref])\nscene_4 = Scene(asset_references=[image_ref, text_ref])\n\n# Handle with frame rate\nconfig = VideoProjectConfig(resolution=(1920, 1080), fps=30)\n\n# Create projects\nproject = (\n    VideoProject(config=config)\n    .add_assets([image, text])\n    .add_timeline_events([scene_3, scene_2, scene_1, scene_4])  # Handle Scene Ordering\n)\n</code></pre>"},{"location":"cookbook/video-from-article/","title":"Video From Article","text":"cookbook/video_from_article.py<pre><code>from mosaico.audio_transcribers.assemblyai import AssemblyAIAudioTranscriber\nfrom mosaico.script_generators.news import NewsVideoScriptGenerator\nfrom mosaico.speech_synthesizers.elevenlabs import ElevenLabsSpeechSynthesizer\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Setup\n### Note: To deal with AI, see cookbooks at AI section.\nscript_generator = NewsVideoScriptGenerator(\n    context=\"breaking news text...\", api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL\n)\n\nspeech_synthesizer = ElevenLabsSpeechSynthesizer(\n    api_key=ELEVENLABS_API_KEY,\n    voice_id=\"Xb7hH8MSUJpSbSDYk0k2\",\n    voice_stability=0.8,\n    voice_similarity_boost=0.75,\n    voice_speaker_boost=False,\n)\n\n# Create assets\nimages = [...]  # List of image Assets\n\naudio_transcriber = AssemblyAIAudioTranscriber(api_key=ASSEMBLYAI_API_KEY)\nconfig = VideoProjectConfig(name=\"Breaking News\")\nproject = VideoProject.from_script_generator(\n    script_generator,\n    images,\n    config=config,\n    speech_synthesizer=speech_synthesizer,\n    audio_transcriber=audio_transcriber,\n)\n</code></pre>"},{"location":"development/contributing/","title":"Contributing","text":"<p>We welcome contributions from the community to help improve and expand this open source video generation framework.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork and clone the repository</li> <li>Install uv</li> <li>Run the following commands:</li> <li><code>make install</code> to install dependencies</li> <li><code>make test</code> to run unit tests</li> <li><code>make format</code> to format code</li> <li><code>make lint</code> to analyze code</li> <li><code>make docs</code> to generate documentation</li> <li><code>make docs-serve</code> to serve documentation locally</li> </ol> <p>Now you're ready to start contributing!</p>"},{"location":"development/contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Ensure all tests pass and code is properly formatted</li> <li>Update documentation as needed</li> <li>Submit your changes and create a pull request with:<ul> <li>Clear description of changes</li> <li>Purpose and motivation</li> <li>Any related issues</li> </ul> </li> <li>Respond to review feedback promptly</li> </ol>"},{"location":"development/contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you find a bug or have a feature suggestion:</p> <ol> <li>Check existing issues first</li> <li>Open a new issue with:<ul> <li>Clear description</li> <li>Steps to reproduce (for bugs)</li> <li>Expected vs actual behavior</li> <li>Environment details</li> <li>Screenshots/examples if applicable</li> </ul> </li> </ol>"},{"location":"development/contributing/#development-guidelines","title":"Development Guidelines","text":"<ul> <li>Write clear, documented code</li> <li>Follow existing code style</li> <li>Add tests for new features</li> <li>Keep PRs focused and atomic</li> <li>Document significant changes</li> </ul>"},{"location":"development/contributing/#license","title":"License","text":"<p>By contributing to Mosaico, you agree that your contributions will be licensed under the project's license (see LICENSE file).</p>"},{"location":"getting-started/architecture/","title":"Architecture","text":"<p>Mosaico follows a modular architecture organized around several key concepts:</p>"},{"location":"getting-started/architecture/#assets","title":"Assets","text":"<p>The foundation of the library is the asset system. Assets represent media elements that can be composed into scenes. The base <code>BaseAsset</code> class provides core functionality, with specialized implementations for different media types.</p>"},{"location":"getting-started/architecture/#positioning","title":"Positioning","text":"<p>The positioning system provides multiple ways to place elements in a frame through the <code>Position</code> protocol, with implementations for absolute, relative and region-based positioning.</p>"},{"location":"getting-started/architecture/#effects","title":"Effects","text":"<p>Effects are implemented through the <code>Effect</code> protocol, allowing for extensible animation and visual effects. Built-in effects include pan and zoom capabilities.</p>"},{"location":"getting-started/architecture/#scenes","title":"Scenes","text":"<p>Scenes group related assets together and manage their timing and organization. The <code>Scene</code> class handles asset references and timing coordination.</p>"},{"location":"getting-started/architecture/#script-generation","title":"Script Generation","text":"<p>Script generation is handled through the <code>ScriptGenerator</code> protocol, with implementations for specific use cases like news video generation.</p>"},{"location":"getting-started/architecture/#speech-synthesis","title":"Speech Synthesis","text":"<p>Speech synthesis is abstracted through the <code>SpeechSynthesizer</code> protocol, with implementations for different TTS providers.</p>"},{"location":"getting-started/architecture/#simplified-diagram","title":"Simplified Diagram","text":"<pre><code>graph TD\n    subgraph Core\n        Media[Media] --&gt; Asset[Asset]\n        Asset --&gt; |references| Scene\n        Position --&gt; Asset\n        Effect --&gt; Scene\n    end\n\n    subgraph Assets\n        Asset --&gt; ImageAsset\n        Asset --&gt; AudioAsset\n        Asset --&gt; TextAsset\n        Asset --&gt; SubtitleAsset\n    end\n\n    subgraph Generators\n        ScriptGenerator --&gt; Scene\n        SpeechSynthesizer --&gt; AudioAsset\n    end\n\n    subgraph Integrations\n        Adapter --&gt; Media\n        Adapter --&gt; ScriptGenerator\n    end\n\n    classDef protocol fill:#f9f,stroke:#333,stroke-width:2px\n    classDef base fill:#bbf,stroke:#333,stroke-width:2px\n    classDef concrete fill:#dfd,stroke:#333,stroke-width:2px\n\n    class Position,Effect,ScriptGenerator,SpeechSynthesizer,Adapter protocol\n    class Media,Asset base\n    class ImageAsset,AudioAsset,TextAsset,SubtitleAsset concrete</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<p>Before installing the Mosaico framework, you need to make sure you have the following prerequisites:</p> <ol> <li> <p>Python 3.10 or superior</p> <p>Mosaico requires Python 3.10 or superior. You can check your Python version by running:</p> <pre><code>python --version\n</code></pre> <p>If you need to update or install Python, visit python.org to get the latest version.</p> </li> <li> <p>FFmpeg</p> <p>Mosaico depends on FFmpeg for video processing. You must have FFmpeg installed and available in your system PATH.</p> <p>To check if FFmpeg is installed, run:</p> <pre><code>ffmpeg -version\n</code></pre> <p>If it's not installed, you can get it from ffmpeg.org or use your operating system's package manager.</p> Ubuntu/DebianmacOS (with Homebrew)Windows (with Chocolatey) <pre><code>sudo apt update\nsudo apt install ffmpeg\n</code></pre> <pre><code>brew install ffmpeg\n</code></pre> <pre><code>choco install ffmpeg\n</code></pre> </li> </ol> <p>After ensuring these prerequisites are satisfied, you can proceed with the Mosaico installation.</p>"},{"location":"getting-started/installation/#installation_1","title":"Installation","text":"<p>To install Mosaico, run the following command according to your preferred package manager:</p> pippipxuvpoetrypdm <pre><code>pip install mosaico\n</code></pre> <pre><code>pipx install mosaico\n</code></pre> <pre><code>uv add mosaico\n</code></pre> <pre><code>poetry add mosaico\n</code></pre> <pre><code>pdm add mosaico\n</code></pre> <p>It is also possible to install Mosaico from source by cloning the repository and running the following command:</p> <pre><code>git clone https://github.com/folhalab/mosaico.git\ncd mosaico\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#additional-dependencies","title":"Additional Dependencies","text":"<p>To install optional dependencies for Mosaico, use the following command, replacing <code>news</code> with the desired feature or concatenating multiple features separated by commas:</p> Single featureMultiple features <pre><code>pip install \"mosaico[news]\"\n</code></pre> <pre><code>pip install \"mosaico[news,elevenlabs,assemblyai]\"\n</code></pre> <p>Available features and their dependencies are listed below:</p> Feature Component Dependencies Description <code>news</code> script generator <code>litellm</code>, <code>instructor</code> AI-powered script generation for videos <code>openai</code> speech synthesizer, audio transcriber <code>openai</code> Text-to-speech synthesis and audio transcription integrations with OpenAI <code>elevenlabs</code> speech synthesizer <code>elevenlabs</code> Text-to-speech synthesis integration with ElevenLabs <code>assemblyai</code> audio transcriber <code>assemblyai</code> Audio transcription integration with AssemblyAI"},{"location":"getting-started/quick-start/","title":"Quick Start","text":""},{"location":"getting-started/quick-start/#creating-assets","title":"Creating Assets","text":"From factory functionFrom asset classes <pre><code>from mosaico.assets import create_asset\n\n# Create an image asset\nimage = create_asset(\"image\", path=\"background.jpg\")\n\n# Create a text asset\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create an audio asset\naudio = create_asset(\"audio\", path=\"narration.mp3\")\n</code></pre> <p>The <code>create_asset()</code> factory function creates different types of assets:</p> <ul> <li>Each asset requires a type identifier (\"image\", \"audio\", \"text\", \"subtitle\")</li> <li>Assets can be created from files using <code>path</code> or direct data using <code>data</code></li> <li>Assets automatically detect properties like dimensions, duration, etc.</li> </ul> <pre><code>from mosaico.assets import ImageAsset, TextAsset, AudioAsset\n\n# Create an image asset\nimage = ImageAsset.from_path(\"background.jpg\")\n\n# Create a text asset\ntext = TextAsset.from_data(\"Hello World\")\n\n# Create an audio asset\naudio = AudioAsset.from_path(\"narration.mp3\")\n</code></pre> <p>Alternatively, assets can be created directly using their respective classes:</p> <ul> <li>Each asset class has specific properties and methods</li> <li>Assets can be created from files using <code>from_path()</code> or direct data using <code>from_data()</code></li> <li>Assets automatically detect properties like dimensions, duration, etc.</li> </ul>"},{"location":"getting-started/quick-start/#creating-asset-references","title":"Creating Asset References","text":"<pre><code>from mosaico.assets.reference import AssetReference\n\n# Create reference for background image\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\n\n# Create reference for text overlay\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create reference for audio narration\naudio_ref = AssetReference.from_asset(audio).with_start_time(0).with_end_time(5)\n</code></pre> <p>Asset references determine when and how assets appear in the video:</p> <ul> <li><code>from_asset()</code> creates a reference from an asset</li> <li><code>with_start_time()</code> sets when the asset appears</li> <li><code>with_end_time()</code> sets when the asset disappears</li> <li>Times are in seconds</li> <li>References can also include effects and custom parameters</li> </ul>"},{"location":"getting-started/quick-start/#creating-a-scene","title":"Creating a Scene","text":"<pre><code>from mosaico.scene import Scene\n\n# Create a scene containing the assets\nscene = Scene(asset_references=[image_ref, text_ref, audio_ref])\n</code></pre> <p>Scenes group related assets together:</p> <ul> <li>Takes a list of asset references</li> <li>Handles timing and synchronization</li> <li>Can include title and description</li> <li>Multiple scenes can be combined in a project</li> </ul>"},{"location":"getting-started/quick-start/#creating-a-complete-project","title":"Creating a Complete Project","text":"<pre><code>from mosaico.video.project import VideoProject, VideoProjectConfig\n\n# Create project configuration\nconfig = VideoProjectConfig(\n    name=\"My First Video\",\n    resolution=(1920, 1080),\n    fps=30\n)\n\n# Create, configure and add assets and scene to the project\nproject = (\n    VideoProject(config=config)\n    .add_assets([image, text, audio])\n    .add_timeline_events(scene)\n)\n</code></pre> <p>The <code>VideoProject</code> ties everything together:</p> <ul> <li>Configure project settings like resolution and framerate</li> <li>Add all assets used in the video</li> <li>Add scenes to the timeline</li> <li>Manages the complete video composition</li> </ul>"},{"location":"getting-started/quick-start/#export-the-video-project","title":"Export the Video Project","text":"<p>The project can be exported to a YAML file:</p> <pre><code>project.to_file(\"my_first_video.yml\")\n</code></pre>"},{"location":"getting-started/quick-start/#optional-adding-effects","title":"Optional: Adding Effects","text":"<pre><code>from mosaico.effects.factory import create_effect\n\n# Create a zoom effect\nzoom_effect = create_effect(\"zoom_in\", start_zoom=1.0, end_zoom=1.2)\n\n# Add effect to text reference\ntext_ref = text_ref.with_effects([zoom_effect])\n</code></pre> <p>Effects can be added to asset references:</p> <ul> <li>Various built-in effects (zoom, pan)</li> <li>Effects have configurable parameters</li> <li>Multiple effects can be combined</li> <li>Effects are applied during rendering</li> </ul>"},{"location":"getting-started/quick-start/#complete-example","title":"Complete Example","text":"<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\nfrom mosaico.effects.factory import create_effect\n\n# 1. Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\naudio = create_asset(\"audio\", path=\"narration.mp3\")\n\n# 2. Create effect\nzoom_effect = create_effect(\"zoom_in\", start_zoom=1.0, end_zoom=1.2)\n\n# 3. Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = (\n    AssetReference.from_asset(text)\n    .with_start_time(1)\n    .with_end_time(4)\n    .with_effects([zoom_effect])\n)\naudio_ref = AssetReference.from_asset(audio).with_start_time(0).with_end_time(5)\n\n# 4. Create scene\nscene = Scene(\n    title=\"Opening Scene\",\n    asset_references=[image_ref, text_ref, audio_ref]\n)\n\n# 5. Create, configure and add assets and events to the project\nproject = (\n    VideoProject(\n        config=VideoProjectConfig(\n            name=\"My First Video\",\n            resolution=(1920, 1080),\n            fps=30\n        )\n    )\n    .add_assets([image, text, audio])\n    .add_timeline_events(scene)\n)\n\n# 6. Save project\nproject.to_file(\"my_video.yml\")\n</code></pre> <p>This creates a 5-second video with:</p> <ul> <li>A background image</li> <li>Text that fades in at 1s with a zoom effect</li> <li>Audio narration throughout</li> <li>HD resolution at 30fps</li> </ul> <p>The project can be saved to a YAML file for later editing or rendering.</p>"},{"location":"integrations/","title":"Integrations","text":""},{"location":"integrations/#ai-framework-integrations","title":"AI Framework Integrations","text":"<p>Mosaico integrates with popular AI frameworks for document processing and script generation:</p> <ul> <li>Haystack - Document processing and script generation</li> <li>LangChain - Document processing and AI workflows</li> </ul>"},{"location":"integrations/#speech-transcription-integrations","title":"Speech &amp; Transcription Integrations","text":"<p>Mosaico provides integrations with speech synthesis and transcription services:</p> <ul> <li>OpenAI - Text-to-speech and transcription via Whisper</li> <li>ElevenLabs - High-quality speech synthesis</li> <li>AssemblyAI - Advanced audio transcription</li> </ul>"},{"location":"integrations/frameworks/haystack/","title":"Haystack","text":"<p>This documentation page is currently under construction and will be updated soon.</p>"},{"location":"integrations/frameworks/langchain/","title":"LangChain","text":"<p>This documentation page is currently under construction and will be updated soon.</p>"},{"location":"integrations/platforms/assemblyai/","title":"AssemblyAI","text":""},{"location":"integrations/platforms/assemblyai/#overview","title":"Overview","text":"<p>AssemblyAI integration in Mosaico provides automated speech-to-text transcription capabilities for audio assets. This integration enables accurate transcription with word-level timing, which is essential for subtitle generation and content synchronization.</p>"},{"location":"integrations/platforms/assemblyai/#requirements","title":"Requirements","text":"<ul> <li>AssemblyAI Python package (<code>pip install assemblyai</code>)</li> <li>Valid AssemblyAI API key</li> <li>Audio in a supported format (MP3, WAV, etc.)</li> </ul>"},{"location":"integrations/platforms/assemblyai/#usage","title":"Usage","text":"<pre><code>from mosaico.audio_transcribers import AssemblyAIAudioTranscriber\nfrom mosaico.assets.audio import AudioAsset\nfrom mosaico.video.project import VideoProject\n\n# Initialize transcriber\ntranscriber = AssemblyAIAudioTranscriber(\n    api_key=\"your_api_key\",\n    model=\"best\",  # or \"nano\" for faster processing\n    language=\"en\"  # optional language specification\n)\n\n# Create audio asset\naudio = AudioAsset.from_path(\"narration.mp3\")\n\n# Transcribe audio\ntranscription = transcriber.transcribe(audio)\n\n# Access transcription results\nfor word in transcription.words:\n    print(f\"{word.text}: {word.start_time} - {word.end_time}\")\n</code></pre>"},{"location":"integrations/platforms/assemblyai/#configuration-options","title":"Configuration Options","text":"<p>The <code>AssemblyAIAudioTranscriber</code> supports several configuration options:</p> <ul> <li><code>api_key</code>: Your AssemblyAI API key (required)</li> <li><code>model</code>: Transcription model to use (<code>best</code> or <code>nano</code>)</li> <li><code>language</code>: Optional language specification</li> <li><code>custom_spelling</code>: Dictionary of custom spelling corrections</li> </ul>"},{"location":"integrations/platforms/assemblyai/#features","title":"Features","text":""},{"location":"integrations/platforms/assemblyai/#language-detection","title":"Language Detection","text":"<pre><code># Automatic language detection\ntranscriber = AssemblyAIAudioTranscriber(\n    api_key=\"your_api_key\",\n    language=None  # Enables automatic detection\n)\n</code></pre>"},{"location":"integrations/platforms/assemblyai/#custom-spelling","title":"Custom Spelling","text":"<pre><code># Add custom spelling corrections\ntranscriber = AssemblyAIAudioTranscriber(\n    api_key=\"your_api_key\",\n    custom_spelling={\n        \"mosaico\": \"Mosaico\",\n        \"ai\": [\"AI\", \"A.I.\"]\n    }\n)\n</code></pre>"},{"location":"integrations/platforms/assemblyai/#integration-with-video-projects","title":"Integration with Video Projects","text":"<p>The transcription can be used in multiple ways with video projects:</p> <pre><code># Create video project\nproject = VideoProject()\n\n# Add audio asset\nproject.add_assets(audio_asset)\n\n# Add captions from transcriber\nproject = project.add_captions_from_transcriber(\n    transcriber,\n    max_duration=5,  # Maximum subtitle duration\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    ),\n    overwrite=False  # Don't overwrite existing captions\n)\n\n# Or manually add captions from transcription\nproject = project.add_captions(\n    transcription,\n    max_duration=5,\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    ),\n    scene_index=0,  # Add to specific scene\n    overwrite=True  # Replace existing captions\n)\n</code></pre>"},{"location":"integrations/platforms/elevenlabs/","title":"ElevenLabs","text":""},{"location":"integrations/platforms/elevenlabs/#overview","title":"Overview","text":"<p>Mosaico integrates with ElevenLabs' text-to-speech API through the <code>ElevenLabsSpeechSynthesizer</code> class, providing high-quality voice synthesis for video narration. This integration supports multiple languages, voice customization, and batch processing of text.</p>"},{"location":"integrations/platforms/elevenlabs/#configuration","title":"Configuration","text":"<pre><code>from mosaico.speech_synthesizers import ElevenLabsSpeechSynthesizer\n\nsynthesizer = ElevenLabsSpeechSynthesizer(\n    api_key=\"your-api-key\",            # ElevenLabs API key\n    voice_id=\"voice-id\",               # Selected voice ID\n    model=\"eleven_multilingual_v2\",    # Model to use\n    language_code=\"en\",                # Language code\n\n    # Voice customization\n    voice_stability=0.5,               # Voice consistency (0-1)\n    voice_similarity_boost=0.5,        # Voice matching accuracy (0-1)\n    voice_style=0.5,                   # Style intensity (0-1)\n    voice_speaker_boost=True           # Enhanced speaker clarity\n)\n</code></pre>"},{"location":"integrations/platforms/elevenlabs/#supported-models","title":"Supported Models","text":"<ul> <li><code>eleven_turbo_v2_5</code> - Latest turbo model</li> <li><code>eleven_turbo_v2</code> - Fast synthesis model</li> <li><code>eleven_multilingual_v2</code> - Multi-language support</li> <li><code>eleven_monolingual_v1</code> - English-only model</li> <li><code>eleven_multilingual_v1</code> - Legacy multi-language</li> </ul>"},{"location":"integrations/platforms/elevenlabs/#voice-synthesis","title":"Voice Synthesis","text":""},{"location":"integrations/platforms/elevenlabs/#basic-usage","title":"Basic Usage","text":"<pre><code># Generate audio assets from text\naudio_assets = synthesizer.synthesize(\n    texts=[\"Hello world\", \"Welcome to Mosaico\"]\n)\n\n# Use in video project\nproject.add_assets(audio_assets)\n</code></pre>"},{"location":"integrations/platforms/elevenlabs/#with-custom-parameters","title":"With Custom Parameters","text":"<pre><code>from mosaico.assets.audio import AudioAssetParams\n\n# Configure audio parameters\naudio_params = AudioAssetParams(\n    volume=0.8,\n    crop=(0, 10)  # Crop first 10 seconds\n)\n\n# Generate audio with parameters\naudio_assets = synthesizer.synthesize(\n    texts=[\"Narration text\"],\n    audio_params=audio_params\n)\n</code></pre>"},{"location":"integrations/platforms/elevenlabs/#advanced-features","title":"Advanced Features","text":""},{"location":"integrations/platforms/elevenlabs/#context-awareness","title":"Context Awareness","text":"<p>The synthesizer maintains context between consecutive text segments for natural flow:</p> <pre><code>texts = [\n    \"This is the first sentence.\",\n    \"This is the second sentence.\",\n    \"This is the final sentence.\"\n]\n\n# Each segment will be synthesized with awareness of surrounding text\naudio_assets = synthesizer.synthesize(texts)\n</code></pre>"},{"location":"integrations/platforms/elevenlabs/#voice-customization","title":"Voice Customization","text":"<p>Fine-tune voice characteristics:</p> <pre><code>synthesizer = ElevenLabsSpeechSynthesizer(\n    voice_id=\"voice-id\",\n    voice_stability=0.8,        # More consistent voice\n    voice_similarity_boost=0.7, # Higher accuracy\n    voice_style=0.6,           # Stronger style\n    voice_speaker_boost=True    # Enhanced clarity\n)\n</code></pre>"},{"location":"integrations/platforms/elevenlabs/#integration-with-video-projects","title":"Integration with Video Projects","text":"<pre><code>from mosaico.video.project import VideoProject\n\n# Create project from script generator\nproject = VideoProject.from_script_generator(\n    script_generator=news_generator,\n    media=media_files\n)\n\n# Add narration to scenes with subtitles\nproject.add_narration(synthesizer)\n\n# Or add specific narration\nscene = project.get_timeline_event(0)\nnarration_assets = synthesizer.synthesize([scene.subtitle])\nproject.add_assets(narration_assets)\n</code></pre> <p>The ElevenLabs integration enables high-quality voice synthesis for your video projects, with extensive customization options and multi-language support. The integration handles context awareness and provides seamless incorporation into the Mosaico video production workflow.</p>"},{"location":"integrations/platforms/openai/","title":"OpenAI","text":""},{"location":"integrations/platforms/openai/#overview","title":"Overview","text":"<p>Mosaico provides robust integration with OpenAI's services through two main components:</p> <ul> <li>Speech synthesis using OpenAI's Text-to-Speech API</li> <li>Audio transcription using OpenAI's Whisper API</li> </ul>"},{"location":"integrations/platforms/openai/#speech-synthesis","title":"Speech Synthesis","text":"<p>The <code>OpenAISpeechSynthesizer</code> class provides text-to-speech capabilities:</p> <pre><code>from mosaico.speech_synthesizers.openai import OpenAISpeechSynthesizer\n\nsynthesizer = OpenAISpeechSynthesizer(\n    api_key=\"your-api-key\",\n    model=\"tts-1\",              # or \"tts-1-hd\" for higher quality\n    voice=\"alloy\",              # available: alloy, echo, fable, onyx, nova, shimmer\n    speed=1.0                   # 0.25 to 4.0\n)\n\n# Generate speech assets\naudio_assets = synthesizer.synthesize(\n    texts=[\"Text to convert to speech\"],\n    audio_params=AudioAssetParams(volume=1.0)\n)\n</code></pre>"},{"location":"integrations/platforms/openai/#configuration-options","title":"Configuration Options","text":"<ul> <li>Models:<ul> <li><code>tts-1</code>: Standard quality model</li> <li><code>tts-1-hd</code>: High-definition model</li> </ul> </li> <li>Voices:<ul> <li>alloy: Neutral and balanced</li> <li>echo: Warm and clear</li> <li>fable: Expressive and dynamic</li> <li>onyx: Deep and authoritative</li> <li>nova: Energetic and bright</li> <li>shimmer: Gentle and welcoming</li> </ul> </li> <li>Speed: Control speech rate from 0.25x to 4.0x</li> </ul>"},{"location":"integrations/platforms/openai/#audio-transcription","title":"Audio Transcription","text":"<p>The <code>OpenAIWhisperTranscriber</code> class provides speech-to-text capabilities:</p> <pre><code>from mosaico.audio_transcribers.openai import OpenAIWhisperTranscriber\n\ntranscriber = OpenAIWhisperTranscriber(\n    api_key=\"your-api-key\",\n    model=\"whisper-1\",\n    language=\"en\",          # Optional language code\n    temperature=0          # Model temperature (0-1)\n)\n\n# Transcribe audio\ntranscription = transcriber.transcribe(audio_asset)\n</code></pre>"},{"location":"integrations/platforms/openai/#transcription-features","title":"Transcription Features","text":"<ul> <li>Word-level timestamps</li> <li>Multiple language support</li> <li>Temperature control for model output</li> <li>Configurable timeout settings</li> </ul>"},{"location":"integrations/platforms/openai/#common-integration-patterns","title":"Common Integration Patterns","text":""},{"location":"integrations/platforms/openai/#speech-to-text-to-speech-pipeline","title":"Speech-to-Text-to-Speech Pipeline","text":"<pre><code># Create project\nproject = VideoProject()\n\n# Add audio asset to project\nproject.add_assets(original_audio)\n\n# Add to scene\nscene = Scene(asset_references=[\n    AssetReference.from_asset(original_audio)\n        .with_start_time(0)\n        .with_end_time(original_audio.duration)\n])\n\n# Add scene to project\nproject.add_timeline_events(scene)\n\n# Add captions from transcription\nproject.add_captions_from_transcriber(transcriber, max_duration=5)\n\n# Add narration in new language\nproject.add_narration(synthesizer)\n</code></pre>"},{"location":"integrations/platforms/openai/#video-subtitling","title":"Video Subtitling","text":"<pre><code># Add captions directly from audio\nproject.add_captions_from_transcriber(\n    transcriber,\n    max_duration=5,\n    params=TextAssetParams(\n        font_size=48,\n        font_color=\"white\"\n    )\n)\n\n# Or add captions from existing transcription\nproject.add_captions(\n    transcription,\n    max_duration=5,\n    scene_index=0  # Add to specific scene\n)\n</code></pre>"},{"location":"integrations/platforms/openai/#automated-narration","title":"Automated Narration","text":"<pre><code># Generate narration for entire project\nproject.add_narration(synthesizer)\n\n# Or generate for specific scene\nscene_with_narration = scene.with_narration(synthesizer)\nproject.add_timeline_events(scene_with_narration)\n</code></pre> <p>The OpenAI integration in Mosaico provides powerful tools for audio processing in video production, enabling automated transcription, translation, and high-quality speech synthesis. The modular design allows for easy integration with other components of the video production pipeline.</p>"},{"location":"pt/","title":"Come\u00e7ando","text":"<p>Mosaico \u00e9 uma biblioteca Python para criar e gerenciar composi\u00e7\u00f5es de v\u00eddeo programaticamente. Fornece uma interface de alto n\u00edvel para trabalhar com assets de m\u00eddia, posicionar elementos, aplicar efeitos e gerar roteiros de v\u00eddeo, tudo constru\u00eddo sobre o MoviePy - uma das bibliotecas de edi\u00e7\u00e3o de v\u00eddeo mais populares em Python.</p> <p>A biblioteca foi projetada pensando em flexibilidade e extensibilidade, oferecendo abstra\u00e7\u00f5es limpas para:</p> <ul> <li>Gerenciamento de diferentes tipos de assets de m\u00eddia (\u00e1udio, imagens, texto, legendas)</li> <li>Controle preciso de posicionamento e layout</li> <li>Aplica\u00e7\u00e3o de efeitos e anima\u00e7\u00e3o</li> <li>Gera\u00e7\u00e3o de roteiros com IA</li> <li>S\u00edntese de texto em fala</li> <li>Integra\u00e7\u00e3o com frameworks populares de ML</li> </ul>"},{"location":"pt/#recursos-e-capacidades-principais","title":"Recursos e Capacidades Principais","text":"<ul> <li> <p> Gera\u00e7\u00e3o de Roteiros</p> <ul> <li>Interfaces limpas para gera\u00e7\u00e3o personalizada de roteiros</li> <li>Framework extens\u00edvel para integra\u00e7\u00e3o com IA</li> <li>Organiza\u00e7\u00e3o de cenas e tomadas</li> <li>Renderiza\u00e7\u00e3o de roteiro para v\u00eddeo</li> </ul> </li> <li> <p> Gerenciamento de Assets</p> <ul> <li>Suporte para m\u00faltiplos tipos de m\u00eddia</li> <li>Manipula\u00e7\u00e3o flex\u00edvel de par\u00e2metros e metadados de assets</li> <li>Sistema de refer\u00eancia para rastreamento de assets em cenas</li> </ul> </li> <li> <p> Sistema de Posicionamento</p> <ul> <li>M\u00faltiplos modos de posicionamento (absoluto, relativo, baseado em regi\u00f5es)</li> <li>C\u00e1lculos de posicionamento com consci\u00eancia de quadro</li> <li>Op\u00e7\u00f5es flex\u00edveis de alinhamento</li> </ul> </li> <li> <p> Motor de Efeitos</p> <ul> <li>Efeitos incorporados de pan e zoom</li> <li>Sistema extens\u00edvel de efeitos</li> <li>Configura\u00e7\u00e3o baseada em par\u00e2metros</li> <li>Suporte \u00e0 composi\u00e7\u00e3o de efeitos</li> </ul> </li> <li> <p> S\u00edntese de Fala</p> <ul> <li>Integra\u00e7\u00e3o com principais provedores de TTS</li> <li>Par\u00e2metros configur\u00e1veis de voz</li> <li>Suporte \u00e0 s\u00edntese em lote</li> <li>Controles de par\u00e2metros de assets</li> </ul> </li> <li> <p> Integra\u00e7\u00f5es Externas</p> <ul> <li>Integra\u00e7\u00f5es prontas com Haystack e LangChain</li> <li>Sistema extens\u00edvel de adaptadores</li> <li>Protocolos limpos de integra\u00e7\u00e3o</li> </ul> </li> </ul>"},{"location":"pt/roadmap/","title":"Roadmap","text":"<p>O Mosaico est\u00e1 em constante evolu\u00e7\u00e3o. Estamos comprometidos com o desenvolvimento cont\u00ednuo do Mosaico, sempre buscando melhorar a experi\u00eancia do usu\u00e1rio e expandir as capacidades da biblioteca. Este roadmap est\u00e1 sujeito a altera\u00e7\u00f5es com base no feedback da comunidade e nas tend\u00eancias emergentes da tecnologia de produ\u00e7\u00e3o de v\u00eddeo.</p> <p>Abaixo est\u00e3o as principais \u00e1reas de foco para o desenvolvimento futuro da biblioteca:</p>"},{"location":"pt/roadmap/#geracao-aprimorada-de-conteudo","title":"Gera\u00e7\u00e3o Aprimorada de Conte\u00fado","text":"<ul> <li>Implementa\u00e7\u00e3o de gera\u00e7\u00e3o de scripts usando tecnologias avan\u00e7adas de IA</li> <li>Expans\u00e3o das capacidades de gera\u00e7\u00e3o automatizada de cenas</li> <li>Desenvolvimento de ferramentas para criar conte\u00fado mais din\u00e2mico e interativo</li> </ul>"},{"location":"pt/roadmap/#efeitos-e-transicoes","title":"Efeitos e Transi\u00e7\u00f5es","text":"<ul> <li>Adi\u00e7\u00e3o de uma variedade de efeitos de transi\u00e7\u00e3o entre cenas</li> <li>Implementa\u00e7\u00e3o de efeitos personaliz\u00e1veis para ativos individuais</li> <li>Cria\u00e7\u00e3o de uma biblioteca padr\u00e3o de efeitos para uso r\u00e1pido</li> </ul>"},{"location":"pt/roadmap/#audio-e-musica","title":"\u00c1udio e M\u00fasica","text":"<ul> <li>Integra\u00e7\u00e3o de funcionalidade para adicionar trilhas sonoras aos projetos</li> <li>Aprimoramento do suporte a legendas, incluindo op\u00e7\u00f5es mais din\u00e2micas e responsivas</li> <li>Expans\u00e3o das integra\u00e7\u00f5es com sintetizadores de fala</li> </ul>"},{"location":"pt/roadmap/#personalizacao-e-flexibilidade","title":"Personaliza\u00e7\u00e3o e Flexibilidade","text":"<ul> <li>Desenvolvimento de um sistema modular para cria\u00e7\u00e3o de cenas</li> <li>Implementa\u00e7\u00e3o de op\u00e7\u00f5es avan\u00e7adas de personaliza\u00e7\u00e3o para todos os aspectos do projeto</li> </ul>"},{"location":"pt/roadmap/#documentacao-e-exemplos","title":"Documenta\u00e7\u00e3o e Exemplos","text":"<ul> <li>Cria\u00e7\u00e3o de cookbooks com exemplos pr\u00e1ticos de uso</li> <li>Expans\u00e3o da documenta\u00e7\u00e3o para incluir mais idiomas</li> <li>Desenvolvimento de tutoriais interativos e guias de melhores pr\u00e1ticas</li> </ul>"},{"location":"pt/roadmap/#integracoes-e-compatibilidade","title":"Integra\u00e7\u00f5es e Compatibilidade","text":"<ul> <li>Expans\u00e3o das integra\u00e7\u00f5es com outros frameworks de IA</li> <li>Melhor compatibilidade com diferentes formatos e plataformas de m\u00eddia</li> </ul>"},{"location":"pt/roadmap/#otimizacao-e-desempenho","title":"Otimiza\u00e7\u00e3o e Desempenho","text":"<ul> <li>Aprimoramento do desempenho geral da biblioteca</li> <li>Implementa\u00e7\u00e3o de t\u00e9cnicas de otimiza\u00e7\u00e3o para projetos de grande escala</li> </ul>"},{"location":"pt/concepts/asset-references-and-scenes/","title":"Refer\u00eancias de Assets e Cenas","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>Assets</li> </ul>"},{"location":"pt/concepts/asset-references-and-scenes/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Refer\u00eancias de assets s\u00e3o um conceito central no Mosaico que permite controlar como os assets aparecem na linha do tempo do seu v\u00eddeo. Elas fornecem uma maneira de gerenciar diferentes tipos de m\u00eddia de forma eficiente, controlar como a m\u00eddia aparece no seu v\u00eddeo, manter seguran\u00e7a de tipos e valida\u00e7\u00e3o, criar composi\u00e7\u00f5es de v\u00eddeo complexas e estender funcionalidades conforme necess\u00e1rio. Um grupo de refer\u00eancias de assets pode ser combinado em uma cena para criar uma se\u00e7\u00e3o l\u00f3gica do seu v\u00eddeo.</p> <p>Em resumo, o sistema de assets no Mosaico consiste em dois componentes principais:</p> <ul> <li>Refer\u00eancias de Assets: Definem quando e como os assets aparecem na linha do tempo</li> <li>Cenas: Agrupam refer\u00eancias de assets relacionados</li> </ul> <p>Estes componentes formam os blocos de constru\u00e7\u00e3o da sua linha do tempo de v\u00eddeo e controlam a apresenta\u00e7\u00e3o dos seus assets de m\u00eddia.</p>"},{"location":"pt/concepts/asset-references-and-scenes/#referencias-de-assets","title":"Refer\u00eancias de Assets","text":"<p>Refer\u00eancias de assets s\u00e3o cruciais para controlar como os assets aparecem na sua linha do tempo de v\u00eddeo. Elas atuam como instru\u00e7\u00f5es para:</p> <ul> <li>Quando os assets aparecem e desaparecem</li> <li>Por quanto tempo ficam vis\u00edveis</li> <li>Quais efeitos s\u00e3o aplicados</li> <li>Quaisquer substitui\u00e7\u00f5es de par\u00e2metros</li> </ul> <p>Pense nelas como as \"dire\u00e7\u00f5es de palco\" para seus assets:</p> <pre><code>from mosaico.assets.reference import AssetReference\n\n# Control asset timing and effects\nasset_ref = (\n    AssetReference.from_asset(image)\n    .with_start_time(0)\n    .with_end_time(5)\n    .with_effects([fade_in_effect])\n)\n</code></pre>"},{"location":"pt/concepts/asset-references-and-scenes/#estrutura","title":"Estrutura","text":"<p>A estrutura b\u00e1sica de uma refer\u00eancia de asset consiste nos seguintes componentes:</p> <pre><code>from mosaico.assets.reference import AssetReference\n\n#Basic structure of an asset reference\nreference = AssetReference(\n    asset_id=\"background_01\",           # Asset identifier\n    asset_params=ImageAssetParams(...), # Optional parameter overrides\n    start_time=0,                       # When asset appears\n    end_time=10,                        # When asset disappears\n    effects=[]                          # Optional effects\n)\n</code></pre>"},{"location":"pt/concepts/asset-references-and-scenes/#criando-referencias-de-assets","title":"Criando Refer\u00eancias de Assets","text":"<p>Existem duas maneiras principais de criar refer\u00eancias de assets:</p> <ol> <li> <p>A partir de um Asset Existente <pre><code># Create reference from asset\nlogo_ref = AssetReference.from_asset(\n    asset=logo_asset,\n    start_time=0,\n    end_time=30\n)\n\n# Using builder pattern\ntitle_ref = AssetReference.from_asset(title_asset)\\\n    .with_start_time(5)\\\n    .with_end_time(10)\\\n    .with_params(TextAssetParams(font_size=48))\\\n    .with_effects([fade_in_effect])\n</code></pre></p> </li> <li> <p>Constru\u00e7\u00e3o Direta <pre><code># Manual reference creation\nmusic_ref = AssetReference(\n    asset_id=\"background_music\",\n    start_time=0,\n    end_time=60,\n    asset_params=AudioAssetParams(volume=0.8)\n)\n</code></pre></p> </li> </ol>"},{"location":"pt/concepts/asset-references-and-scenes/#cenas","title":"Cenas","text":"<p>Cenas s\u00e3o uma maneira de agrupar assets na sua linha do tempo de v\u00eddeo. Elas permitem organizar seu v\u00eddeo em se\u00e7\u00f5es l\u00f3gicas e aplicar efeitos a v\u00e1rios assets de uma vez. Cenas podem ser usadas para criar transi\u00e7\u00f5es, aplicar efeitos globais ou agrupar assets relacionados:</p> <p>Warning</p> <p>A implementa\u00e7\u00e3o de transi\u00e7\u00f5es e efeitos globais em Cenas ainda n\u00e3o \u00e9 suportada no Mosaico, mas ser\u00e1 adicionada em vers\u00f5es futuras.</p> <pre><code>from mosaico.scenes.scene import Scene\n\n# Create a scene with multiple assets\nscene = Scene(\n    asset_references=[\n        AssetReference.from_asset(image1),\n        AssetReference.from_asset(image2),\n    ],\n)\n</code></pre>"},{"location":"pt/concepts/asset-references-and-scenes/#padroes-comuns","title":"Padr\u00f5es Comuns","text":""},{"location":"pt/concepts/asset-references-and-scenes/#fundo-com-sobreposicao","title":"Fundo com Sobreposi\u00e7\u00e3o","text":"<pre><code>scene = Scene(\n    title=\"Title Scene\",\n    asset_references=[\n        # Background layer\n        AssetReference.from_asset(background)\n            .with_start_time(0)\n            .with_end_time(10),\n\n        # Text overlay\n        AssetReference.from_asset(title)\n            .with_start_time(2)\n            .with_end_time(8)\n    ]\n)\n</code></pre>"},{"location":"pt/concepts/asset-references-and-scenes/#sincronizacao-audio-visual","title":"Sincroniza\u00e7\u00e3o \u00c1udio-Visual","text":"<pre><code>narration_ref = AssetReference.from_asset(narration)\n    .with_start_time(0)\n    .with_end_time(narration.duration)\n\nscene = Scene(\n    asset_references=[\n        # Visual content matches narration timing\n        AssetReference.from_asset(visual)\n            .with_start_time(narration_ref.start_time)\n            .with_end_time(narration_ref.end_time),\n        narration_ref\n    ]\n)\n</code></pre>"},{"location":"pt/concepts/asset-references-and-scenes/#conteudo-sequencial","title":"Conte\u00fado Sequencial","text":"<pre><code>def create_sequence_scene(assets: list[BaseAsset], duration_per_asset: float) -&gt; Scene:\n    \"\"\"Create a scene with sequential assets.\"\"\"\n    references = []\n    current_time = 0\n\n    for asset in assets:\n        references.append(\n            AssetReference.from_asset(asset)\n                .with_start_time(current_time)\n                .with_end_time(current_time + duration_per_asset)\n        )\n        current_time += duration_per_asset\n\n    return Scene(asset_references=references)\n</code></pre>"},{"location":"pt/concepts/asset-references-and-scenes/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<p>Organiza\u00e7\u00e3o de Refer\u00eancias de Assets</p> <ul> <li>Mantenha assets relacionados juntos em cenas</li> <li>Use rela\u00e7\u00f5es de tempo significativas</li> <li>Aplique efeitos com modera\u00e7\u00e3o</li> </ul> <p>Estrutura de Cena</p> <ul> <li>Agrupe conte\u00fado logicamente relacionado</li> <li>Mantenha hierarquias de tempo claras</li> <li>Adicione t\u00edtulos e descri\u00e7\u00f5es descritivos</li> </ul> <p>Gerenciamento da Linha do Tempo</p> <ul> <li>Verifique a exist\u00eancia de assets antes de referenci\u00e1-los</li> <li>Verifique a consist\u00eancia do tempo</li> <li>Gerencie transi\u00e7\u00f5es entre cenas</li> </ul>"},{"location":"pt/concepts/asset-references-and-scenes/#conclusao","title":"Conclus\u00e3o","text":"<p>Este sistema abrangente de assets permite gerenciar diferentes tipos de m\u00eddia de forma eficiente, controlar como a m\u00eddia aparece no seu v\u00eddeo, manter seguran\u00e7a de tipos e valida\u00e7\u00e3o, criar composi\u00e7\u00f5es de v\u00eddeo complexas e estender funcionalidades conforme necess\u00e1rio.</p>"},{"location":"pt/concepts/audio-transcriptors/","title":"Transcri\u00e7\u00e3o de \u00c1udio","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>Media</li> <li>Assets</li> <li>Video Projects</li> </ul>"},{"location":"pt/concepts/audio-transcriptors/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Mosaico fornece componentes de transcri\u00e7\u00e3o de \u00e1udio para converter fala em texto, que podem ser usados para gera\u00e7\u00e3o de legendas e sincroniza\u00e7\u00e3o de conte\u00fado. O sistema usa uma abordagem baseada em protocolo permitindo que diferentes servi\u00e7os de transcri\u00e7\u00e3o sejam integrados atrav\u00e9s de uma interface comum.</p>"},{"location":"pt/concepts/audio-transcriptors/#protocolo-de-transcricao-de-audio","title":"Protocolo de Transcri\u00e7\u00e3o de \u00c1udio","text":"<p>O sistema de transcri\u00e7\u00e3o \u00e9 constru\u00eddo em torno do protocolo <code>AudioTranscriber</code>:</p> <pre><code>from mosaico.audio_transcribers.protocol import AudioTranscriber\nfrom mosaico.assets.audio import AudioAsset\nfrom mosaico.audio_transcribers.transcription import Transcription\n\nclass MyTranscriber(AudioTranscriber):\n    def transcribe(self, audio_asset: AudioAsset) -&gt; Transcription:\n        # Implement transcription logic\n        ...\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#estrutura-de-transcricao","title":"Estrutura de Transcri\u00e7\u00e3o","text":"<p>As transcri\u00e7\u00f5es s\u00e3o representadas usando a classe <code>Transcription</code>:</p> <pre><code>from mosaico.audio_transcribers.transcription import Transcription, TranscriptionWord\n\nwords = [\n    TranscriptionWord(\n        start_time=0.0,\n        end_time=0.5,\n        text=\"Hello\"\n    ),\n    TranscriptionWord(\n        start_time=0.6,\n        end_time=1.0,\n        text=\"world\"\n    )\n]\n\ntranscription = Transcription(words=words)\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#usando-transcricoes-em-projetos","title":"Usando Transcri\u00e7\u00f5es em Projetos","text":"<p>Transcritores podem ser usados para gerar legendas para projetos de v\u00eddeo:</p> <pre><code># Create transcriptor\ntranscriber = MyTranscriber()\n\n# Transcribe audio asset\ntranscription = transcriber.transcribe(audio_asset)\n\n# Add subtitles from transcription\nproject = project.add_captions_from_transcriber(\n    transcription,\n    max_duration=5,  # Maximum subtitle duration\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    )\n)\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#formatos-de-transcricao","title":"Formatos de Transcri\u00e7\u00e3o","text":""},{"location":"pt/concepts/audio-transcriptors/#formato-vtt","title":"Formato VTT","text":"<pre><code># Convert to WebVTT\nvtt_content = transcription.as_vtt()\n\n# Create from VTT\ntranscription = Transcription.from_vtt(vtt_content)\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#formato-srt","title":"Formato SRT","text":"<pre><code># Create from SRT\ntranscription = Transcription.from_srt(srt_content)\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":""},{"location":"pt/concepts/audio-transcriptors/#lidando-com-conteudo-longo","title":"Lidando com Conte\u00fado Longo","text":"<ul> <li>Dividir transcri\u00e7\u00f5es longas em partes gerenci\u00e1veis</li> <li>Considerar o uso de mem\u00f3ria para arquivos grandes</li> <li>Usar dura\u00e7\u00f5es apropriadas para legendas</li> </ul>"},{"location":"pt/concepts/audio-transcriptors/#sincronizacao-de-tempo","title":"Sincroniza\u00e7\u00e3o de Tempo","text":"<ul> <li>Verificar sincroniza\u00e7\u00e3o de \u00e1udio/legendas</li> <li>Lidar com falas sobrepostas</li> <li>Considerar pausas e intervalos</li> </ul>"},{"location":"pt/concepts/audio-transcriptors/#processamento-de-texto","title":"Processamento de Texto","text":"<ul> <li>Limpar o texto da transcri\u00e7\u00e3o</li> <li>Lidar corretamente com pontua\u00e7\u00e3o</li> <li>Formatar n\u00fameros e caracteres especiais</li> </ul>"},{"location":"pt/concepts/audio-transcriptors/#casos-de-uso-comuns","title":"Casos de Uso Comuns","text":""},{"location":"pt/concepts/audio-transcriptors/#legendas-de-video","title":"Legendas de V\u00eddeo","text":"<pre><code># Create news video with transcribed subtitles\nproject = (\n    VideoProject.from_script_generator(news_generator, media_files)\n    .add_captions_from_transcriber(\n        transcriber,\n        max_duration=5,\n        params=TextAssetParams(\n            font_size=24,\n            font_color=\"yellow\"\n        )\n    )\n)\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#legendagem-de-entrevistas","title":"Legendagem de Entrevistas","text":"<pre><code># Process interview audio\ntranscription = transcriber.transcribe(interview_audio)\n\n# Add captions to video\nproject = project.add_captions(\n    transcription,\n    params=TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\")\n    )\n)\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#suporte-multi-idioma","title":"Suporte Multi-idioma","text":"<pre><code># Create subtitles in different languages\nfor language in languages:\n    translated_transcription = translate_transcription(\n        transcription,\n        target_language=language\n    )\n    project.add_captions(\n        translated_transcription,\n        params=subtitle_params[language]\n    )\n</code></pre>"},{"location":"pt/concepts/audio-transcriptors/#conclusao","title":"Conclus\u00e3o","text":"<p>O sistema de transcri\u00e7\u00e3o no Mosaico fornece uma base flex\u00edvel para adicionar legendas aos seus v\u00eddeos, com suporte para diferentes formatos e op\u00e7\u00f5es de processamento.</p>"},{"location":"pt/concepts/effects/","title":"Efeitos","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>Assets</li> <li>Asset References</li> </ul>"},{"location":"pt/concepts/effects/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Sistema de Efeitos do Mosaico fornece uma maneira de adicionar anima\u00e7\u00f5es din\u00e2micas e efeitos visuais aos seus elementos de v\u00eddeo. Os efeitos podem ser aplicados a qualquer refer\u00eancia de asset e podem ser combinados para criar anima\u00e7\u00f5es complexas.</p>"},{"location":"pt/concepts/effects/#interface","title":"Interface","text":"<p>No n\u00facleo do sistema de efeitos est\u00e1 o protocolo Effect:</p> <pre><code>from moviepy.Clip import Clip\nfrom typing import Protocol, TypeVar\n\nClipType = TypeVar(\"ClipType\", bound=Clip)\n\nclass Effect(Protocol[ClipType]):\n    \"\"\"Base protocol for all effects.\"\"\"\n\n    def apply(self, clip: ClipType) -&gt; ClipType:\n        \"\"\"Apply the effect to a clip.\"\"\"\n        ...\n</code></pre> <p>O usu\u00e1rio pode criar efeitos personalizados implementando o m\u00e9todo <code>apply</code>. O m\u00e9todo <code>apply</code> recebe um objeto <code>Clip</code> e retorna um objeto <code>Clip</code> modificado com o efeito aplicado.</p>"},{"location":"pt/concepts/effects/#efeitos-integrados","title":"Efeitos Integrados","text":"<p>O Mosaico fornece um conjunto de efeitos integrados que podem ser usados para criar anima\u00e7\u00f5es din\u00e2micas em suas composi\u00e7\u00f5es de v\u00eddeo. Esses efeitos se dividem em duas categorias principais: efeitos de movimento de c\u00e2mera (pan) e efeitos de escala din\u00e2mica (zoom).</p> <p>Aqui est\u00e1 uma lista completa dos efeitos dispon\u00edveis:</p> Efeito Tipo Par\u00e2metros Descri\u00e7\u00e3o PanLeftEffect <code>pan_left</code> <code>zoom_factor: float = 1.1</code> Move da direita para a esquerda atrav\u00e9s do quadro PanRightEffect <code>pan_right</code> <code>zoom_factor: float = 1.1</code> Move da esquerda para a direita atrav\u00e9s do quadro PanUpEffect <code>pan_up</code> <code>zoom_factor: float = 1.1</code> Move de baixo para cima atrav\u00e9s do quadro PanDownEffect <code>pan_down</code> <code>zoom_factor: float = 1.1</code> Move de cima para baixo atrav\u00e9s do quadro ZoomInEffect <code>zoom_in</code> <code>start_zoom: float = 1.0</code><code>end_zoom: float = 1.1</code> Aproxima o quadro ZoomOutEffect <code>zoom_out</code> <code>start_zoom: float = 1.5</code><code>end_zoom: float = 1.4</code> Afasta o quadro <p>Aqui est\u00e3o alguns exemplos de como usar esses efeitos:</p> <pre><code>from mosaico.effects.factory import create_effect\n\n# Pan effect example\npan_right = create_effect(\n    \"pan_right\",\n    zoom_factor=1.2\n)\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects([pan_right])\n\n# Zoom effect example\nzoom_in = create_effect(\n    \"zoom_in\",\n    start_zoom=1.0,\n    end_zoom=1.3\n)\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects([zoom_in])\n\n# Combining pan and zoom\ncombined_effect = [\n    create_effect(\"pan_right\", zoom_factor=1.1),\n    create_effect(\"zoom_in\", start_zoom=1.0, end_zoom=1.2)\n]\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects(combined_effect)\n</code></pre>"},{"location":"pt/concepts/effects/#criando-efeitos-personalizados","title":"Criando Efeitos Personalizados","text":"<p>Voc\u00ea pode criar efeitos personalizados implementando o protocolo Effect:</p> <pre><code>from moviepy.video.VideoClip import VideoClip\n\nclass CustomFadeEffect:\n    \"\"\"Custom fade effect implementation.\"\"\"\n\n    def __init__(self, fade_duration: float = 1.0):\n        self.fade_duration = fade_duration\n\n    def apply(self, clip: VideoClip) -&gt; VideoClip:\n        \"\"\"Apply custom fade effect.\"\"\"\n        def modify_frame(t):\n            # Custom frame modification logic\n            frame = clip.get_frame(t)\n            alpha = min(1.0, t / self.fade_duration)\n            return frame * alpha\n\n        return clip.fl(modify_frame)\n</code></pre>"},{"location":"pt/concepts/effects/#combinando-efeitos","title":"Combinando Efeitos","text":"<p>Os efeitos podem ser combinados para criar anima\u00e7\u00f5es complexas:</p> <pre><code># Create multiple effects\npan_right = create_effect(\"pan_right\")\nzoom_in = create_effect(\"zoom_in\")\n\n# Apply both effects to an asset\nimage_ref = AssetReference.from_asset(image)\\\n    .with_effects([pan_right, zoom_in])\n</code></pre>"},{"location":"pt/concepts/effects/#exemplos-do-mundo-real","title":"Exemplos do Mundo Real","text":""},{"location":"pt/concepts/effects/#efeito-ken-burns","title":"Efeito Ken Burns","text":"<pre><code># Create a subtle Ken Burns effect\nken_burns = [\n    create_effect(\n        \"zoom_in\",\n        start_zoom=1.0,\n        end_zoom=1.2\n    ),\n    create_effect(\"pan_right\")\n]\n\n# Apply to background image\nbackground_ref = AssetReference.from_asset(background)\\\n    .with_effects(ken_burns)\n</code></pre>"},{"location":"pt/concepts/effects/#animacao-de-titulo","title":"Anima\u00e7\u00e3o de T\u00edtulo","text":"<pre><code># Create title entrance effect\ntitle_effects = [\n    create_effect(\"zoom_in\", start_zoom=0.8, end_zoom=1.0),\n    create_effect(\"pan_up\")\n]\n\n# Apply to title\ntitle_ref = AssetReference.from_asset(title)\\\n    .with_effects(title_effects)\n</code></pre>"},{"location":"pt/concepts/effects/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<ol> <li> <p>Temporiza\u00e7\u00e3o de Efeitos <pre><code># Consider clip duration when setting effect parameters\nif clip_duration &lt; 2:\n    zoom_factor = 1.1  # Subtle for short clips\nelse:\n    zoom_factor = 1.3  # More dramatic for longer clips\n</code></pre></p> </li> <li> <p>Considera\u00e7\u00f5es de Desempenho <pre><code># Limit number of simultaneous effects\nMAX_EFFECTS = 2\n\nif len(effects) &gt; MAX_EFFECTS:\n    warnings.warn(\"Too many effects may impact performance\")\n</code></pre></p> </li> <li> <p>Combina\u00e7\u00f5es de Efeitos <pre><code># Create reusable effect combinations\ndef create_entrance_effects():\n    return [\n        create_effect(\"zoom_in\", start_zoom=0.8),\n        create_effect(\"pan_up\")\n    ]\n</code></pre></p> </li> </ol>"},{"location":"pt/concepts/effects/#conclusao","title":"Conclus\u00e3o","text":"<p>O Sistema de Efeitos do Mosaico fornece uma maneira poderosa de adicionar elementos din\u00e2micos \u00e0s suas composi\u00e7\u00f5es de v\u00eddeo. Ao entender e usar adequadamente os efeitos, voc\u00ea pode criar v\u00eddeos com apar\u00eancia profissional e elementos visuais envolventes. Seja usando efeitos integrados ou criando personalizados, a flexibilidade do sistema permite produ\u00e7\u00f5es de v\u00eddeo criativas e impactantes.</p>"},{"location":"pt/concepts/","title":"Conceitos","text":""},{"location":"pt/concepts/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Mosaico \u00e9 constru\u00eddo em torno de v\u00e1rios conceitos fundamentais que trabalham juntos para criar composi\u00e7\u00f5es de v\u00eddeo:</p> <ul> <li>M\u00eddia e Assets: Conte\u00fado bruto e elementos prontos para produ\u00e7\u00e3o</li> <li>Sistema de Posicionamento: Controle de posicionamento e layout</li> <li>Refer\u00eancias de Assets e Cenas: Organiza\u00e7\u00e3o da linha do tempo</li> <li>Projetos de V\u00eddeo: Composi\u00e7\u00f5es de v\u00eddeo de alto n\u00edvel</li> <li>Geradores de Script: Cria\u00e7\u00e3o automatizada de conte\u00fado</li> <li>Efeitos: Anima\u00e7\u00f5es din\u00e2micas e efeitos visuais</li> </ul>"},{"location":"pt/concepts/media-and-assets/","title":"M\u00eddia e Assets","text":""},{"location":"pt/concepts/media-and-assets/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>No Mosaico, m\u00eddia e assets s\u00e3o os elementos fundamentais da produ\u00e7\u00e3o de v\u00eddeo. Eles representam os materiais brutos e elementos prontos para produ\u00e7\u00e3o que comp\u00f5em uma composi\u00e7\u00e3o de v\u00eddeo. Este guia explica a diferen\u00e7a entre m\u00eddia e assets, como s\u00e3o utilizados na produ\u00e7\u00e3o de v\u00eddeo e o sistema de tipos de assets no Mosaico.</p>"},{"location":"pt/concepts/media-and-assets/#entendendo-o-pipeline-de-producao","title":"Entendendo o Pipeline de Produ\u00e7\u00e3o","text":"<p>Na produ\u00e7\u00e3o de v\u00eddeo com o Mosaico, existem duas etapas distintas de manipula\u00e7\u00e3o de conte\u00fado:</p> <ol> <li>Est\u00e1gio de M\u00eddia: Coleta de Conte\u00fado Bruto</li> <li>Est\u00e1gio de Assets: Elementos Prontos para Produ\u00e7\u00e3o</li> </ol> <p>Esta abordagem em duas etapas reflete os fluxos de trabalho profissionais de produ\u00e7\u00e3o de v\u00eddeo, onde materiais brutos s\u00e3o preparados e transformados em elementos prontos para produ\u00e7\u00e3o. A conex\u00e3o entre essas etapas s\u00e3o os geradores de script, que ser\u00e3o abordados em uma se\u00e7\u00e3o posterior.</p>"},{"location":"pt/concepts/media-and-assets/#objetos-de-midia-materiais-brutos","title":"Objetos de M\u00eddia: Materiais Brutos","text":"<p>Objetos de m\u00eddia representam o est\u00e1gio de \"materiais brutos\" do seu conte\u00fado:</p> <ul> <li>Clipes de v\u00eddeo brutos</li> <li>Arquivos de \u00e1udio n\u00e3o processados</li> <li>Imagens originais</li> <li>Conte\u00fado de texto simples</li> </ul> <pre><code>from mosaico.media import Media\n\n# Collecting raw materials\nbackground = Media.from_path(\"media/background.png\")\nvoice_over = Media.from_path(\"media/narration.wav\")\ngraphics = Media.from_path(\"media/graphics.png\")\nscript = Media.from_path(\"media/script.txt\")\n</code></pre> <p>Pense nos objetos Media como itens em sua \"biblioteca de m\u00eddia\" antes de serem preparados para produ\u00e7\u00e3o.</p>"},{"location":"pt/concepts/media-and-assets/#assets-elementos-prontos-para-producao","title":"Assets: Elementos Prontos para Produ\u00e7\u00e3o","text":"<p>Assets s\u00e3o os blocos fundamentais de qualquer composi\u00e7\u00e3o de v\u00eddeo no Mosaico e representam o est\u00e1gio \"pronto para produ\u00e7\u00e3o\" de uma m\u00eddia. Eles representam diferentes tipos de elementos de m\u00eddia que podem ser combinados para criar um v\u00eddeo, como imagens, clipes de \u00e1udio, sobreposi\u00e7\u00f5es de texto e legendas. Pense em assets como os materiais prontos necess\u00e1rios para construir seu v\u00eddeo.</p> <p>Cada asset no Mosaico tem essencialmente a mesma estrutura de um objeto de m\u00eddia, mas com propriedades e capacidades adicionais, como par\u00e2metros espec\u00edficos de tipo e metadados. Assets s\u00e3o projetados para estarem prontos para produ\u00e7\u00e3o e podem ser usados diretamente em composi\u00e7\u00f5es de v\u00eddeo:</p> <ul> <li>Um identificador \u00fanico</li> <li>Conte\u00fado principal (os dados reais da m\u00eddia)</li> <li>Par\u00e2metros espec\u00edficos do tipo</li> <li>Metadados para informa\u00e7\u00f5es adicionais</li> <li>Capacidades de valida\u00e7\u00e3o e processamento integradas</li> </ul> <pre><code>from mosaico.assets import ImageAsset, AudioAsset\n\n# Instantiating assets\nbackground = ImageAsset.from_path(\"assets/background.png\")\nvoice_over = AudioAsset.from_path(\"assets/narration.wav\")\ngraphics = ImageAsset.from_path(\"assets/graphics.png\")\nsubtitles = [SubtitleAsset.from_data(data) for data in subtitle_data]\n</code></pre>"},{"location":"pt/concepts/media-and-assets/#diferencas-principais","title":"Diferen\u00e7as Principais","text":"<p>Aqui est\u00e1 um resumo das principais diferen\u00e7as entre M\u00eddia e Assets:</p> Aspecto Objetos de M\u00eddia Assets Prop\u00f3sito Armazenamento e manipula\u00e7\u00e3o b\u00e1sica de conte\u00fado bruto Manipula\u00e7\u00e3o de elementos de produ\u00e7\u00e3o de v\u00eddeo Estado Forma original, n\u00e3o processada Processado, pronto para produ\u00e7\u00e3o Propriedades Metadados b\u00e1sicos e acesso ao conte\u00fado Par\u00e2metros de produ\u00e7\u00e3o e comportamentos Uso Coleta e armazenamento de conte\u00fado Timeline e composi\u00e7\u00e3o Integra\u00e7\u00e3o Ponte com sistemas externos Sistema de renderiza\u00e7\u00e3o de v\u00eddeo"},{"location":"pt/concepts/media-and-assets/#o-sistema-de-tipos-de-asset","title":"O Sistema de Tipos de Asset","text":"<p>O Mosaico implementa um sistema de assets flex\u00edvel e com seguran\u00e7a de tipos usando uma classe base que outros tipos de assets estendem. Essa abordagem hier\u00e1rquica garante consist\u00eancia enquanto permite que cada tipo de asset tenha suas caracter\u00edsticas e par\u00e2metros espec\u00edficos.</p>"},{"location":"pt/concepts/media-and-assets/#estrutura-base-do-asset","title":"Estrutura Base do Asset","text":"<p>A classe base de asset define a estrutura central para todos os tipos de assets no Mosaico. Inclui propriedades comuns como o tipo de asset e par\u00e2metros, que s\u00e3o ent\u00e3o estendidos por tipos espec\u00edficos de assets.</p> <pre><code>from mosaico.assets.base import BaseAsset\nfrom pydantic import BaseModel\n\nclass BaseAsset(Media, Generic[T]):\n    type: str\n    params: T\n</code></pre>"},{"location":"pt/concepts/media-and-assets/#tipos-de-assets","title":"Tipos de Assets","text":"<p>Para criar uma composi\u00e7\u00e3o de v\u00eddeo, voc\u00ea precisa de diferentes tipos de assets que representam v\u00e1rios elementos de m\u00eddia. Aqui est\u00e3o alguns tipos comuns de assets no Mosaico:</p> <p>Assets de V\u00eddeo</p> <p>Embora planejados, assets de v\u00eddeo n\u00e3o est\u00e3o atualmente implementados no Mosaico, pois sua arquitetura de integra\u00e7\u00e3o ainda est\u00e1 em discuss\u00e3o. Eles ser\u00e3o adicionados em breve em vers\u00f5es futuras.</p>"},{"location":"pt/concepts/media-and-assets/#audio","title":"\u00c1udio","text":"<p>Assets de \u00e1udio gerenciam todos os elementos sonoros em seu v\u00eddeo, incluindo narra\u00e7\u00e3o, m\u00fasica, efeitos sonoros e vozes. Eles incluem propriedades b\u00e1sicas como dura\u00e7\u00e3o, taxa de amostragem, canais, volume e pontos de corte. Isso ajuda voc\u00ea a controlar como o \u00e1udio \u00e9 reproduzido em seu v\u00eddeo mantendo padr\u00f5es de qualidade profissional.</p> <p>Exemplo de uso:</p> <pre><code>from mosaico.assets import AudioAsset, AudioAssetParams\n\n# Create an audio asset with specific volume\naudio = AudioAsset.from_path(\n    \"narration.mp3\",\n    params=AudioAssetParams(volume=0.8)\n)\n</code></pre>"},{"location":"pt/concepts/media-and-assets/#imagem","title":"Imagem","text":"<p>Assets de imagem lidam com visuais est\u00e1ticos como fundos, sobreposi\u00e7\u00f5es, logos e fotos em seu v\u00eddeo. Eles v\u00eam com propriedades-chave para controlar como aparecem: tamanho (largura e altura), posi\u00e7\u00e3o, ordem de camada (z-index), recorte e modo de fundo. Essas propriedades permitem que voc\u00ea controle com precis\u00e3o como as imagens aparecem e trabalham juntas em seu v\u00eddeo.</p> <p>Exemplo de uso: <pre><code>from mosaico.assets import ImageAsset, ImageAssetParams\n\n# Create an image asset with positioning\nimage = ImageAsset.from_path(\n    \"background.jpg\",\n    params=ImageAssetParams(\n        position=AbsolutePosition(x=100, y=100),\n        as_background=True\n    )\n)\n</code></pre></p>"},{"location":"pt/concepts/media-and-assets/#texto","title":"Texto","text":"<p>Assets de texto permitem que voc\u00ea adicione t\u00edtulos, legendas e outros elementos de texto aos seus v\u00eddeos. Eles incluem op\u00e7\u00f5es de estilo como fontes, cores, alinhamentos e efeitos como sombras e contornos. Isso d\u00e1 a voc\u00ea controle total sobre como o texto aparece em seu v\u00eddeo mantendo qualidade profissional.</p> <p>Exemplo de uso: <pre><code>from mosaico.assets import TextAsset, TextAssetParams\n\n# Create styled text\ntext = TextAsset.from_data(\n    \"Welcome to My Video\",\n    params=TextAssetParams(\n        font_size=48,\n        font_color=Color(\"white\"),\n        align=\"center\"\n    )\n)\n</code></pre></p>"},{"location":"pt/concepts/media-and-assets/#legendas","title":"Legendas","text":"<p>Assets de legenda s\u00e3o assets de texto especializados projetados para legendagem de v\u00eddeo. Eles lidam com legendas de di\u00e1logo, closed captions, tradu\u00e7\u00f5es e sobreposi\u00e7\u00f5es de texto temporizado. Voc\u00ea pode ajustar seu posicionamento, tamanhos de fonte e cores de fundo. Eles incluem recursos para legibilidade e suporte multil\u00edngue para criar v\u00eddeos acess\u00edveis.</p> <p>Exemplo de uso: <pre><code>from mosaico.assets import SubtitleAsset\n\n# Create a subtitle with proper positioning\nsubtitle = SubtitleAsset.from_data(\n    \"This is a subtitle\",\n    params=TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\"),\n        font_size=36\n    )\n)\n</code></pre></p>"},{"location":"pt/concepts/media-and-assets/#trabalhando-com-assets","title":"Trabalhando com Assets","text":"<p>Dado que voc\u00ea j\u00e1 tem uma cole\u00e7\u00e3o de assets, voc\u00ea pode come\u00e7ar a trabalhar com eles para criar sua composi\u00e7\u00e3o de v\u00eddeo.</p> <p>Um pipeline comum para trabalhar com assets no Mosaico envolve carregar, gerenciar e combinar assets para criar uma sequ\u00eancia de v\u00eddeo. O posterior ser\u00e1 coberto em outra se\u00e7\u00e3o, mas aqui est\u00e1 como voc\u00ea pode realizar opera\u00e7\u00f5es b\u00e1sicas apenas com assets.</p>"},{"location":"pt/concepts/media-and-assets/#carregando-assets","title":"Carregando Assets","text":"<p>Para o processo de composi\u00e7\u00e3o de v\u00eddeo come\u00e7ar, voc\u00ea precisa carregar sua m\u00eddia em assets. Se voc\u00ea j\u00e1 sabe onde e como um determinado conte\u00fado deve ser exibido, voc\u00ea pode criar diretamente os assets correspondentes chamando os m\u00e9todos de classe do tipo de asset ou usando o sistema de f\u00e1brica de assets.</p> From filesFrom raw dataFrom factoryFrom existing media <pre><code>from mosaico.assets import ImageAsset\n\nimage = ImageAsset.from_path(\"logo.png\")\n</code></pre> <pre><code>from mosaico.assets import TextAsset\n\ntext = TextAsset.from_data(\"Hello World\")\n</code></pre> <pre><code>from mosaico.assets import create_asset\n\nasset = create_asset(\"image\", path=\"logo.png\")\n</code></pre> <pre><code>from mosaico.assets.utils import convert_media_to_asset\n\nasset = convert_media_to_asset(media_object)\n</code></pre>"},{"location":"pt/concepts/media-and-assets/#gerenciando-parametros-de-asset","title":"Gerenciando Par\u00e2metros de Asset","text":"<p>Todos os assets t\u00eam par\u00e2metros que controlam sua apar\u00eancia e comportamento. Voc\u00ea pode atualizar esses par\u00e2metros para personalizar como os assets s\u00e3o exibidos em sua composi\u00e7\u00e3o de v\u00eddeo.</p> <pre><code># Update text styling\ntext_asset = text_asset.with_params({\n    \"font_size\": 48,\n    \"font_color\": \"#FFFFFF\",\n    \"align\": \"center\"\n})\n</code></pre>"},{"location":"pt/concepts/media-and-assets/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<p>Ao trabalhar com assets, considere as seguintes melhores pr\u00e1ticas para garantir que sua composi\u00e7\u00e3o de v\u00eddeo seja bem organizada e eficiente:</p> <ol> <li> <p>Organiza\u00e7\u00e3o</p> <ul> <li>Use IDs de asset significativos</li> <li>Agrupe assets relacionados</li> <li>Mantenha hierarquias claras de assets</li> </ul> </li> <li> <p>Desempenho</p> <ul> <li>Otimize tamanhos de imagem antes de carregar</li> <li>Use formatos de \u00e1udio apropriados</li> <li>Limpe assets n\u00e3o utilizados</li> </ul> </li> <li> <p>Manutenibilidade</p> <ul> <li>Documente metadados de assets</li> <li>Use conven\u00e7\u00f5es de nomenclatura consistentes</li> <li>Mantenha par\u00e2metros de assets organizados</li> </ul> </li> <li> <p>Reusabilidade</p> <ul> <li>Crie templates de asset reutiliz\u00e1veis</li> <li>Compartilhe par\u00e2metros comuns</li> <li>Use refer\u00eancias de asset efetivamente</li> </ul> </li> </ol>"},{"location":"pt/concepts/media-and-assets/#beneficios-do-fluxo-de-trabalho","title":"Benef\u00edcios do Fluxo de Trabalho","text":"<p>Esta abordagem em duas etapas fornece v\u00e1rias vantagens:</p> <ol> <li> <p>Separa\u00e7\u00e3o Limpa de Responsabilidades</p> <ul> <li>Manipula\u00e7\u00e3o de m\u00eddia \u00e9 separada da l\u00f3gica de produ\u00e7\u00e3o</li> <li>Distin\u00e7\u00e3o clara entre conte\u00fado bruto e processado</li> <li>Gerenciamento de conte\u00fado mais f\u00e1cil</li> </ul> </li> <li> <p>Pipeline de Conte\u00fado Flex\u00edvel</p> <ul> <li>Conte\u00fado bruto pode ser processado diferentemente para diferentes usos</li> <li>A mesma m\u00eddia pode criar diferentes tipos de assets</li> <li>F\u00e1cil integra\u00e7\u00e3o com fontes de conte\u00fado externas</li> </ul> </li> <li> <p>Fluxo de Trabalho Profissional</p> <ul> <li>Espelha processos profissionais de produ\u00e7\u00e3o de v\u00eddeo</li> <li>Etapas claras para prepara\u00e7\u00e3o de conte\u00fado</li> <li>Gerenciamento organizado de assets</li> </ul> </li> <li> <p>Otimiza\u00e7\u00e3o de Recursos</p> <ul> <li>Conte\u00fado bruto \u00e9 processado apenas quando necess\u00e1rio</li> <li>M\u00faltiplos assets podem referenciar a mesma m\u00eddia</li> <li>Uso eficiente de recursos</li> </ul> </li> </ol>"},{"location":"pt/concepts/media-and-assets/#conclusao","title":"Conclus\u00e3o","text":"<p>Entender essa distin\u00e7\u00e3o entre M\u00eddia e Assets \u00e9 fundamental para trabalhar efetivamente com o Mosaico, pois reflete a progress\u00e3o natural do conte\u00fado bruto para a produ\u00e7\u00e3o final de v\u00eddeo.</p>"},{"location":"pt/concepts/positioning/","title":"Sistema de Posicionamento","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>Assets</li> </ul>"},{"location":"pt/concepts/positioning/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Sistema de Posicionamento no Mosaico fornece uma maneira flex\u00edvel de posicionar elementos visuais (como imagens e texto) em sua composi\u00e7\u00e3o de v\u00eddeo. Ele oferece tr\u00eas estrat\u00e9gias distintas de posicionamento, cada uma adequada para diferentes casos de uso.</p>"},{"location":"pt/concepts/positioning/#tipos-de-posicionamento","title":"Tipos de Posicionamento","text":""},{"location":"pt/concepts/positioning/#posicionamento-absoluto-baseado-em-pixels","title":"Posicionamento Absoluto (Baseado em Pixels)","text":"<p>Posicionamento preciso usando coordenadas exatas em pixels a partir do canto superior esquerdo do quadro.</p> <pre><code>from mosaico.positioning import AbsolutePosition\n\nclass AbsolutePosition:\n    type: Literal[\"absolute\"] = \"absolute\"\n    x: NonNegativeInt = 0          # Pixels from left\n    y: NonNegativeInt = 0          # Pixels from top\n</code></pre> <p>Exemplo de Uso: <pre><code># Position an element 100 pixels from left, 50 from top\nlogo_position = AbsolutePosition(x=100, y=50)\n</code></pre></p>"},{"location":"pt/concepts/positioning/#posicionamento-relativo-baseado-em-porcentagem","title":"Posicionamento Relativo (Baseado em Porcentagem)","text":"<p>Posiciona elementos usando porcentagens das dimens\u00f5es do quadro.</p> <pre><code>from mosaico.positioning import RelativePosition\n\nclass RelativePosition:\n    type: Literal[\"relative\"] = \"relative\"\n    x: NonNegativeFloat = 0.5      # 0.0 to 1.0 (left to right)\n    y: NonNegativeFloat = 0.5      # 0.0 to 1.0 (top to bottom)\n</code></pre> <p>Exemplo de Uso: <pre><code># Center an element (50% from left and top)\ncentered_position = RelativePosition(x=0.5, y=0.5)\n\n# Position at bottom-right corner\ncorner_position = RelativePosition(x=1.0, y=1.0)\n</code></pre></p> <p>Casos de Uso:</p> <ul> <li>Layouts responsivos</li> <li>Posicionamento independente de resolu\u00e7\u00e3o</li> <li>Composi\u00e7\u00f5es din\u00e2micas</li> <li>Designs adapt\u00e1veis</li> </ul>"},{"location":"pt/concepts/positioning/#posicionamento-por-regiao-regioes-nomeadas","title":"Posicionamento por Regi\u00e3o (Regi\u00f5es Nomeadas)","text":"<p>Posiciona elementos usando regi\u00f5es predefinidas do quadro.</p> <pre><code>from mosaico.positioning import RegionPosition\n\nclass RegionPosition:\n    type: Literal[\"region\"] = \"region\"\n    x: Literal[\"left\", \"center\", \"right\"] = \"center\"\n    y: Literal[\"top\", \"center\", \"bottom\"] = \"center\"\n</code></pre> <p>Exemplo de Uso: <pre><code># Position in bottom-center (typical for subtitles)\nsubtitle_position = RegionPosition(x=\"center\", y=\"bottom\")\n\n# Position in top-right corner\ntitle_position = RegionPosition(x=\"right\", y=\"top\")\n</code></pre></p> <p>Casos de Uso:</p> <ul> <li>Legendas</li> <li>Lower thirds</li> <li>Elementos padr\u00e3o de v\u00eddeo</li> <li>Posicionamento r\u00e1pido</li> </ul>"},{"location":"pt/concepts/positioning/#conversao-de-posicao","title":"Convers\u00e3o de Posi\u00e7\u00e3o","text":"<p>O Mosaico fornece utilit\u00e1rios para converter entre tipos de posi\u00e7\u00e3o:</p> <pre><code>from mosaico.positioning.utils import convert_position_to_absolute\n\n# Convert any position type to absolute coordinates\nabsolute_pos = convert_position_to_absolute(\n    position=RegionPosition(x=\"center\", y=\"bottom\"),\n    frame_size=(1920, 1080)\n)\n</code></pre>"},{"location":"pt/concepts/positioning/#exemplos-praticos","title":"Exemplos Pr\u00e1ticos","text":""},{"location":"pt/concepts/positioning/#posicionamento-de-logo","title":"Posicionamento de Logo","text":"<pre><code># Create an image asset with absolute positioning\nlogo = create_asset(\n    \"image\",\n    path=\"logo.png\",\n    params=ImageAssetParams(\n        position=AbsolutePosition(x=50, y=30)\n    )\n)\n</code></pre>"},{"location":"pt/concepts/positioning/#titulo-centralizado","title":"T\u00edtulo Centralizado","text":"<pre><code># Create a centered text title\ntitle = create_asset(\n    \"text\",\n    data=\"Welcome\",\n    params=TextAssetParams(\n        position=RelativePosition(x=0.5, y=0.5),\n        align=\"center\"\n    )\n)\n</code></pre>"},{"location":"pt/concepts/positioning/#legendas","title":"Legendas","text":"<pre><code># Create subtitles in standard position\nsubtitle = create_asset(\n    \"subtitle\",\n    data=\"Hello world\",\n    params=TextAssetParams(\n        position=RegionPosition(x=\"center\", y=\"bottom\")\n    )\n)\n</code></pre>"},{"location":"pt/concepts/positioning/#validacao-de-posicao-e-auxiliares","title":"Valida\u00e7\u00e3o de Posi\u00e7\u00e3o e Auxiliares","text":""},{"location":"pt/concepts/positioning/#verificacao-de-tipo","title":"Verifica\u00e7\u00e3o de Tipo","text":"<pre><code>from mosaico.positioning.utils import (\n    is_absolute_position,\n    is_relative_position,\n    is_region_position\n)\n\n# Check position types\nif is_region_position(position):\n    # Handle region position\n    pass\nelif is_relative_position(position):\n    # Handle relative position\n    pass\nelif is_absolute_position(position):\n    # Handle absolute position\n    pass\n</code></pre>"},{"location":"pt/concepts/positioning/#criacao-de-posicao-por-regiao","title":"Cria\u00e7\u00e3o de Posi\u00e7\u00e3o por Regi\u00e3o","text":"<pre><code># Create from string shorthand\nposition = RegionPosition.from_string(\"bottom\")  # center-bottom\nposition = RegionPosition.from_string(\"right\")   # right-center\n</code></pre>"},{"location":"pt/concepts/positioning/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<ol> <li> <p>Escolhendo o Tipo de Posi\u00e7\u00e3o Correto</p> <ul> <li>Use Absoluto para requisitos de precis\u00e3o em pixels</li> <li>Use Relativo para layouts independentes de resolu\u00e7\u00e3o</li> <li>Use Regi\u00e3o para elementos padr\u00e3o de v\u00eddeo</li> </ul> </li> <li> <p>Considera\u00e7\u00f5es sobre Resolu\u00e7\u00e3o <pre><code># Bad: Hard-coded absolute positions\nposition = AbsolutePosition(x=1920, y=1080)\n\n# Good: Relative positioning for flexibility\nposition = RelativePosition(x=1.0, y=1.0)\n</code></pre></p> </li> <li> <p>Layouts Manuten\u00edveis <pre><code># Create reusable positions\nLOWER_THIRD_POSITION = RegionPosition(x=\"left\", y=\"bottom\")\nWATERMARK_POSITION = AbsolutePosition(x=50, y=50)\n</code></pre></p> </li> <li> <p>Posicionamento Din\u00e2mico <pre><code># Adjust position based on content\ndef get_title_position(title_length: int) -&gt; Position:\n    if title_length &gt; 50:\n        return RegionPosition(x=\"center\", y=\"top\")\n    return RelativePosition(x=0.5, y=0.3)\n</code></pre></p> </li> </ol>"},{"location":"pt/concepts/positioning/#conclusao","title":"Conclus\u00e3o","text":"<p>Entender e usar efetivamente o sistema de posicionamento \u00e9 crucial para criar composi\u00e7\u00f5es de v\u00eddeo com apar\u00eancia profissional. A flexibilidade de ter tr\u00eas estrat\u00e9gias de posicionamento permite que voc\u00ea lide com qualquer requisito de layout enquanto mant\u00e9m um c\u00f3digo limpo e manuten\u00edvel.</p>"},{"location":"pt/concepts/script-generators/","title":"Geradores de Script","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>M\u00eddia</li> <li>Sintetizadores de Fala</li> </ul>"},{"location":"pt/concepts/script-generators/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Os Geradores de Script no Mosaico fornecem uma maneira automatizada de criar roteiros de v\u00eddeo a partir de cole\u00e7\u00f5es de m\u00eddia. S\u00e3o particularmente \u00fateis para converter conte\u00fado como artigos de not\u00edcias em roteiros de v\u00eddeo estruturados que podem ser usados para gerar projetos de v\u00eddeo completos.</p>"},{"location":"pt/concepts/script-generators/#sistema-de-geracao-de-script","title":"Sistema de Gera\u00e7\u00e3o de Script","text":"<p>O sistema consiste em tr\u00eas componentes principais:</p> <ol> <li>Protocolo do Gerador de Script: Define a interface para geradores de script</li> <li>Roteiro de Filmagem: Representa a sa\u00edda estruturada gerada pelo gerador de script</li> <li>Tomada: Representa segmentos individuais do script</li> </ol>"},{"location":"pt/concepts/script-generators/#o-protocolo-scriptgenerator","title":"O Protocolo <code>ScriptGenerator</code>","text":"<p>Caracter\u00edsticas principais:</p> <ul> <li>Protocolo verific\u00e1vel em tempo de execu\u00e7\u00e3o</li> <li>Manipula\u00e7\u00e3o flex\u00edvel de entrada</li> <li>Formato de sa\u00edda padronizado</li> <li>Design extens\u00edvel</li> </ul> <pre><code>from mosaico.script_generators.protocol import ScriptGenerator\nfrom mosaico.media import Media\n\n@runtime_checkable\nclass ScriptGenerator(Protocol):\n    def generate(self, media: Sequence[Media], **kwargs: Any) -&gt; ShootingScript:\n        \"\"\"Generate a shooting script from media.\"\"\"\n        ...\n</code></pre>"},{"location":"pt/concepts/script-generators/#roteiros-de-filmagem","title":"Roteiros de Filmagem","text":"<p>Um <code>ShootingScript</code> representa um roteiro de v\u00eddeo completo com m\u00faltiplas tomadas. A ideia \u00e9 fornecer um formato estruturado que pode ser usado para gerar projetos de v\u00eddeo. O formato do roteiro de filmagem foi escolhido para ser simples e flex\u00edvel, mantendo os elementos essenciais de um roteiro de v\u00eddeo.</p> <p>Os principais componentes de um roteiro de filmagem s\u00e3o:</p> <ul> <li>T\u00edtulo: O t\u00edtulo do roteiro</li> <li>Descri\u00e7\u00e3o: Uma descri\u00e7\u00e3o opcional do conte\u00fado do roteiro</li> <li>Tomadas: Cole\u00e7\u00e3o de tomadas que comp\u00f5em o roteiro</li> </ul> <p>Estes componentes fornecem uma vis\u00e3o geral do conte\u00fado do v\u00eddeo e dos segmentos individuais que ser\u00e3o inclu\u00eddos no v\u00eddeo final.</p>"},{"location":"pt/concepts/script-generators/#tomadas","title":"Tomadas","text":"<p>Tomadas individuais representam segmentos distintos no roteiro que podem ser usados para criar projetos de v\u00eddeo. Cada tomada tem as seguintes propriedades:</p> <ul> <li>N\u00famero: Um identificador \u00fanico para a tomada</li> <li>Descri\u00e7\u00e3o: Uma breve descri\u00e7\u00e3o do conte\u00fado da tomada</li> <li>Tempo Inicial: O tempo de in\u00edcio da tomada no v\u00eddeo</li> <li>Tempo Final: O tempo final da tomada no v\u00eddeo</li> <li>Legenda: Legendas opcionais para a tomada</li> <li>Refer\u00eancias de M\u00eddia: Refer\u00eancias \u00e0 m\u00eddia usada na tomada</li> <li>Efeitos: Efeitos opcionais aplicados \u00e0 tomada</li> </ul> <p>Warning</p> <p>Refer\u00eancias de m\u00eddia n\u00e3o s\u00e3o objetos como <code>AssetReference</code>, mas sim strings simples que podem ser usadas para identificar objetos de m\u00eddia em uma lista de m\u00eddia. N\u00e3o devem ser confundidas com objetos de m\u00eddia reais ou objetos <code>AssetReference</code>.</p>"},{"location":"pt/concepts/script-generators/#usando-geradores-de-script","title":"Usando Geradores de Script","text":""},{"location":"pt/concepts/script-generators/#geracao-basica-de-script","title":"Gera\u00e7\u00e3o B\u00e1sica de Script","text":"<pre><code># Create generator\ngenerator = MyVideoScriptGenerator(\n    context=\"News article content...\",\n    num_paragraphs=10\n)\n\n# Generate script from media\nscript = generator.generate(\n    media=[\n        image1_media,\n        image2_media,\n        video_media\n    ]\n)\n</code></pre>"},{"location":"pt/concepts/script-generators/#criando-projetos-de-video","title":"Criando Projetos de V\u00eddeo","text":"<pre><code>from mosaico.video.project import VideoProject\n\n# Generate project from script\nproject = VideoProject.from_script_generator(\n    script_generator=generator,\n    media=media_files,\n    speech_synthesizer=tts_engine,\n    audio_transcriber=transcriber\n)\n</code></pre>"},{"location":"pt/concepts/script-generators/#gerador-de-script-personalizado","title":"Gerador de Script Personalizado","text":"<pre><code>class CustomScriptGenerator:\n    \"\"\"Custom implementation of ScriptGenerator.\"\"\"\n\n    def generate(self,\n                media: Sequence[Media],\n                **kwargs: Any) -&gt; ShootingScript:\n        # Custom script generation logic\n        shots = [\n            Shot(\n                number=1,\n                description=\"Opening shot\",\n                start_time=0,\n                end_time=5,\n                subtitle=\"Welcome\",\n                media_references=[0],\n                effects=[\"zoom_in\"]\n            )\n        ]\n\n        return ShootingScript(\n            title=\"Custom Video\",\n            shots=shots\n        )\n</code></pre>"},{"location":"pt/concepts/script-generators/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<p>Organiza\u00e7\u00e3o de M\u00eddia</p> <ul> <li>Fornecer descri\u00e7\u00f5es claras de m\u00eddia</li> <li>Ordenar m\u00eddia logicamente</li> <li>Incluir metadados relevantes</li> </ul> <p>Gerenciamento de Tomadas</p> <ul> <li>Manter tomadas focadas e concisas</li> <li>Garantir transi\u00e7\u00f5es l\u00f3gicas</li> <li>Combinar m\u00eddia com conte\u00fado</li> </ul>"},{"location":"pt/concepts/script-generators/#trabalhando-com-scripts-gerados","title":"Trabalhando com Scripts Gerados","text":""},{"location":"pt/concepts/script-generators/#analise-de-script","title":"An\u00e1lise de Script","text":"<pre><code># Analyze generated script\nprint(f\"Script duration: {script.duration}s\")\nprint(f\"Number of shots: {script.shot_count}\")\n\nfor shot in script.shots:\n    print(f\"Shot {shot.number}: {shot.duration}s\")\n    print(f\"Media used: {shot.media_references}\")\n</code></pre>"},{"location":"pt/concepts/script-generators/#validacao-de-script","title":"Valida\u00e7\u00e3o de Script","text":"<pre><code>def validate_script(script: ShootingScript) -&gt; bool:\n    \"\"\"Validate script properties.\"\"\"\n    if script.duration &gt; max_duration:\n        return False\n\n    if not all(shot.subtitle for shot in script.shots):\n        return False\n\n    return True\n</code></pre>"},{"location":"pt/concepts/script-generators/#verificacao-de-referencias-de-midia","title":"Verifica\u00e7\u00e3o de Refer\u00eancias de M\u00eddia","text":"<pre><code>def check_media_references(\n    script: ShootingScript,\n    media: Sequence[Media]\n) -&gt; bool:\n    \"\"\"Verify all media references are valid.\"\"\"\n    media_count = len(media)\n\n    for shot in script.shots:\n        if any(ref &gt;= media_count for ref in shot.media_references):\n            return False\n\n    return True\n</code></pre>"},{"location":"pt/concepts/script-generators/#integracao-com-outros-componentes","title":"Integra\u00e7\u00e3o com Outros Componentes","text":""},{"location":"pt/concepts/script-generators/#sintese-de-fala","title":"S\u00edntese de Fala","text":"<pre><code># Generate speech for subtitles\nspeech_assets = speech_synthesizer.synthesize(\n    [shot.subtitle for shot in script.shots]\n)\n</code></pre>"},{"location":"pt/concepts/script-generators/#aplicacao-de-efeitos","title":"Aplica\u00e7\u00e3o de Efeitos","text":"<pre><code># Apply effects from script\nfor shot in script.shots:\n    effects = [create_effect(effect) for effect in shot.effects]\n    # Apply to corresponding assets\n</code></pre>"},{"location":"pt/concepts/script-generators/#conclusao","title":"Conclus\u00e3o","text":"<p>Entender os geradores de script \u00e9 crucial para a produ\u00e7\u00e3o automatizada de v\u00eddeo no Mosaico. Eles fornecem uma ponte entre conte\u00fado bruto e projetos de v\u00eddeo estruturados, permitindo uma transforma\u00e7\u00e3o eficiente do conte\u00fado enquanto mant\u00eam o controle criativo e os padr\u00f5es de qualidade.</p>"},{"location":"pt/concepts/speech-synthesizers/","title":"Sintetizadores de Voz","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>Media</li> <li>Assets</li> <li>Video Projects</li> </ul>"},{"location":"pt/concepts/speech-synthesizers/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Os Sintetizadores de Voz no Mosaico s\u00e3o componentes que convertem texto em fala natural para narra\u00e7\u00e3o de v\u00eddeo. O sistema suporta m\u00faltiplas implementa\u00e7\u00f5es de sintetizadores e oferece op\u00e7\u00f5es flex\u00edveis de configura\u00e7\u00e3o.</p>"},{"location":"pt/concepts/speech-synthesizers/#trabalhando-com-sintetizadores","title":"Trabalhando com Sintetizadores","text":"<pre><code>from mosaico.speech_synthesizers import OpenAISpeechSynthesizer\n\n# Create synthesizer with configuration\ntts = OpenAISpeechSynthesizer(\n    model=\"tts-1\",              # TTS model to use\n    voice=\"alloy\",              # Voice selection\n    speed=1.0,                  # Speech speed\n    api_key=\"your_api_key\"      # Optional API key\n)\n\n# Generate speech\naudio_assets = tts.synthesize(\n    texts=[\"Welcome to our video\", \"This is a demo\"],\n    audio_params=AudioAssetParams(volume=0.8)\n)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#integracao-com-projetos-de-video","title":"Integra\u00e7\u00e3o com Projetos de V\u00eddeo","text":""},{"location":"pt/concepts/speech-synthesizers/#integracao-basica","title":"Integra\u00e7\u00e3o B\u00e1sica","text":"<pre><code># Create project with speech\nproject = (\n    VideoProject.from_script_generator(\n        script_generator=generator,\n        media=media_files,\n    )\n    .add_narration(tts_engine)\n)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#adicao-manual-de-fala","title":"Adi\u00e7\u00e3o Manual de Fala","text":"<pre><code># Generate speech for specific text\nspeech_asset = tts.synthesize([\"Welcome message\"])[0]\n\n# Add to project\nproject = (\n    project\n    .add_assets(speech_asset)\n    .add_timeline_events(\n        AssetReference.from_asset(speech_asset)\n            .with_start_time(0)\n            .with_end_time(speech_asset.duration)\n    )\n)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#parametros-personalizados-de-fala","title":"Par\u00e2metros Personalizados de Fala","text":""},{"location":"pt/concepts/speech-synthesizers/#configuracao-de-audio","title":"Configura\u00e7\u00e3o de \u00c1udio","text":"<pre><code># Configure audio parameters\nparams = AudioAssetParams(\n    volume=0.8,         # Set volume level\n    crop=(0, 30)       # Use specific segment\n)\n\n# Generate with parameters\nassets = tts.synthesize(\n    texts=[\"Narration text\"],\n    audio_params=params\n)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#personalizacao-de-voz","title":"Personaliza\u00e7\u00e3o de Voz","text":"<pre><code># OpenAI customization\nopenai_tts = OpenAISpeechSynthesizer(\n    model=\"tts-1-hd\",    # High-definition model\n    voice=\"nova\",        # Different voice\n    speed=1.2           # Faster speech\n)\n\n# ElevenLabs customization\nelevenlabs_tts = ElevenLabsSpeechSynthesizer(\n    voice_id=\"custom_voice\",\n    voice_stability=0.7,\n    voice_similarity_boost=0.8,\n    voice_speaker_boost=True\n)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#casos-de-uso-comuns","title":"Casos de Uso Comuns","text":""},{"location":"pt/concepts/speech-synthesizers/#narracao-de-video","title":"Narra\u00e7\u00e3o de V\u00eddeo","text":"<pre><code># Generate news narration\nnews_tts = OpenAISpeechSynthesizer(\n    voice=\"nova\",     # Clear, professional voice\n    speed=1.1        # Slightly faster for news\n)\n\nnarration = news_tts.synthesize(\n    [shot.subtitle for shot in news_script.shots]\n)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#voz-para-tutorial","title":"Voz para Tutorial","text":"<pre><code># Tutorial narration with pauses\ntutorial_tts = ElevenLabsSpeechSynthesizer(\n    voice_id=\"tutorial_voice\",\n    voice_stability=0.8,    # More consistent\n    voice_style=0.3        # Less emotional\n)\n\n# Add pauses between steps\ntutorial_texts = [f\"{text}...\" for text in tutorial_steps]\ntutorial_audio = tutorial_tts.synthesize(tutorial_texts)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#suporte-multi-idioma","title":"Suporte Multi-Idioma","text":"<pre><code># Create synthesizers for different languages\ntts_en = OpenAISpeechSynthesizer(language_code=\"en\")\ntts_es = OpenAISpeechSynthesizer(language_code=\"es\")\ntts_fr = OpenAISpeechSynthesizer(language_code=\"fr\")\n\n# Generate multi-language audio\naudio_en = tts_en.synthesize(texts_en)\naudio_es = tts_es.synthesize(texts_es)\naudio_fr = tts_fr.synthesize(texts_fr)\n</code></pre>"},{"location":"pt/concepts/speech-synthesizers/#conclusao","title":"Conclus\u00e3o","text":"<p>Entender os sintetizadores de voz no Mosaico permite a cria\u00e7\u00e3o de narra\u00e7\u00f5es de qualidade profissional para v\u00e1rios tipos de v\u00eddeo. O sistema flex\u00edvel de sintetizadores e as op\u00e7\u00f5es de configura\u00e7\u00e3o permitem uma sa\u00edda de voz personalizada adequada para diferentes necessidades de conte\u00fado.</p>"},{"location":"pt/concepts/video-projects/","title":"Projetos de V\u00eddeo","text":"<p>Pr\u00e9-requisitos</p> <ul> <li>Assets</li> <li>Refer\u00eancias de Asset</li> <li>Cenas</li> <li>Geradores de Script</li> </ul>"},{"location":"pt/concepts/video-projects/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Um projeto de v\u00eddeo no Mosaico representa uma composi\u00e7\u00e3o completa de v\u00eddeo que consiste em tr\u00eas componentes principais:</p> <p>Configura\u00e7\u00e3o do Projeto</p> <ul> <li>Metadados b\u00e1sicos e configura\u00e7\u00f5es do projeto</li> <li>Especifica\u00e7\u00f5es de sa\u00edda do v\u00eddeo</li> <li>Par\u00e2metros t\u00e9cnicos</li> </ul> <p>Cole\u00e7\u00e3o de Assets</p> <ul> <li>Registro de todos os elementos de m\u00eddia</li> <li>Mapeamento entre IDs de assets e objetos</li> <li>Valida\u00e7\u00e3o e gerenciamento de assets</li> </ul> <p>Linha do Tempo</p> <ul> <li>Sequ\u00eancia de eventos (cenas e refer\u00eancias de assets)</li> <li>Sincroniza\u00e7\u00e3o de tempo</li> <li>Organiza\u00e7\u00e3o de eventos</li> </ul>"},{"location":"pt/concepts/video-projects/#configuracao-do-projeto","title":"Configura\u00e7\u00e3o do Projeto","text":"<p>Um v\u00eddeo pode ser configurado com um conjunto espec\u00edfico de par\u00e2metros que definem sua apar\u00eancia e comportamento. A classe <code>VideoProjectConfig</code> define as configura\u00e7\u00f5es b\u00e1sicas para seu v\u00eddeo:</p> <pre><code>from mosaico.video.project import VideoProjectConfig\n\nconfig = VideoProjectConfig(\n    name=\"My Project\",          # Project name\n    version=1,                  # Project version\n    resolution=(1920, 1080),    # Video dimensions\n    fps=30                      # Frames per second\n)\n</code></pre> <p>Por exemplo, para alterar a resolu\u00e7\u00e3o do projeto, basta atualizar o atributo <code>resolution</code>...</p> <pre><code>config.resolution = (1280, 720)\n</code></pre> <p>... e pronto: o projeto de v\u00eddeo ser\u00e1 renderizado na nova resolu\u00e7\u00e3o.</p>"},{"location":"pt/concepts/video-projects/#criando-projetos-de-video","title":"Criando Projetos de V\u00eddeo","text":"<p>Existem tr\u00eas maneiras principais de criar um projeto de v\u00eddeo:</p>"},{"location":"pt/concepts/video-projects/#criacao-direta","title":"Cria\u00e7\u00e3o Direta","text":"<p>O usu\u00e1rio j\u00e1 conhece a estrutura do projeto, a configura\u00e7\u00e3o dos assets e sua disposi\u00e7\u00e3o na linha do tempo. Neste caso, o projeto pode ser criado diretamente:</p> <pre><code>from mosaico.video.project import VideoProject\n\nproject = VideoProject(\n    config=VideoProjectConfig(\n        name=\"Direct Creation Example\",\n        resolution=(1920, 1080)\n    )\n)\n</code></pre>"},{"location":"pt/concepts/video-projects/#geracao-baseada-em-script","title":"Gera\u00e7\u00e3o Baseada em Script","text":"<p>O usu\u00e1rio deseja gerar um projeto de v\u00eddeo baseado em um script que define a estrutura do projeto. O script pode ser gerado por um gerador de script, que \u00e9 uma classe que implementa o protocolo <code>ScriptGenerator</code>:</p> <p>Sobre Geradores de Script</p> <p>Eles s\u00e3o a principal ponte entre projetos de v\u00eddeo e IA. O protocolo <code>ScriptGenerator</code> est\u00e1 no centro do processo de gera\u00e7\u00e3o de projetos de v\u00eddeo, pois define a estrutura do script que ser\u00e1 usado para criar o projeto de v\u00eddeo e evita que o usu\u00e1rio tenha que definir manualmente a estrutura do projeto.</p> <pre><code>project = VideoProject.from_script_generator(\n    script_generator=script_generator,  # ScriptGenerator instance\n    media=media_files,                  # Sequence of Media objects\n    config=video_config,                # Optional configuration\n    speech_synthesizer=tts_engine,      # Optional speech synthesis\n    audio_transcriber=transcriber,      # Optional transcription\n    background_audio=bg_music           # Optional background music\n)\n</code></pre>"},{"location":"pt/concepts/video-projects/#carregando-de-arquivo","title":"Carregando de Arquivo","text":"<p>Uma das principais caracter\u00edsticas do Mosaico \u00e9 a capacidade de serializar e desserializar projetos de v\u00eddeo para e de arquivos. Isso permite que os usu\u00e1rios salvem seus projetos e os carreguem posteriormente, ou os compartilhem com outros.</p> <p>Baseado no formato YAML, a classe <code>VideoProject</code> fornece m\u00e9todos para carregar e salvar projetos:</p> <pre><code># Load from YAML\nproject = VideoProject.from_file(\"project.yml\")\n\n# Save to YAML\nproject.to_file(\"project.yml\")\n</code></pre>"},{"location":"pt/concepts/video-projects/#gerenciando-assets-do-projeto","title":"Gerenciando Assets do Projeto","text":"<p>O <code>VideoProject</code> fornece m\u00e9todos para gerenciar assets, como adicionar, remover e recuper\u00e1-los. A classe \u00e9 respons\u00e1vel por garantir que todos os assets estejam corretamente vinculados ao projeto, tenham refer\u00eancias v\u00e1lidas na linha do tempo e estejam dispon\u00edveis quando necess\u00e1rio.</p>"},{"location":"pt/concepts/video-projects/#adicionando-assets","title":"Adicionando Assets","text":"<pre><code># Add single asset\nproject.add_assets(background_image)\n\n# Add multiple assets\nproject.add_assets([\n    main_video,\n    background_music,\n    subtitle_text\n])\n\n# Add with custom IDs\nproject.add_assets({\n    \"background\": background_image,\n    \"music\": background_music\n})\n</code></pre>"},{"location":"pt/concepts/video-projects/#recuperando-assets","title":"Recuperando Assets","text":"<pre><code># Get asset by ID\nasset = project.get_asset(\"background\")\n</code></pre>"},{"location":"pt/concepts/video-projects/#removendo-assets","title":"Removendo Assets","text":"<pre><code># Remove asset\n# This will also remove all references to the asset in the timeline\nproject.remove_asset(\"background\")\n</code></pre>"},{"location":"pt/concepts/video-projects/#gerenciamento-da-linha-do-tempo","title":"Gerenciamento da Linha do Tempo","text":"<p>A linha do tempo consiste em eventos (cenas e refer\u00eancias de assets) que definem quando e como os assets aparecem no v\u00eddeo.</p>"},{"location":"pt/concepts/video-projects/#adicionando-eventos-na-linha-do-tempo","title":"Adicionando Eventos na Linha do Tempo","text":"<pre><code># Add a scene\nproject.add_timeline_events(\n    Scene(\n        title=\"Opening Scene\",\n        asset_references=[\n            AssetReference.from_asset(background)\n                .with_start_time(0)\n                .with_end_time(5),\n            AssetReference.from_asset(title_text)\n                .with_start_time(1)\n                .with_end_time(4)\n        ]\n    )\n)\n\n# Add individual asset reference\nproject.add_timeline_events(\n    AssetReference.from_asset(background_music)\n        .with_start_time(0)\n        .with_end_time(project.duration)\n)\n</code></pre>"},{"location":"pt/concepts/video-projects/#removendo-eventos-da-linha-do-tempo","title":"Removendo Eventos da Linha do Tempo","text":"<pre><code># Remove event by index\nproject.remove_timeline_event(0)\n</code></pre>"},{"location":"pt/concepts/video-projects/#navegacao-na-linha-do-tempo","title":"Navega\u00e7\u00e3o na Linha do Tempo","text":"<pre><code># Get total duration\nduration = project.duration\n\n# Get specific event\nevent = project.get_timeline_event(0)\n\n# Iterate through timeline\nfor event in project.iter_timeline():\n    print(f\"Event at {event.start_time}s\")\n</code></pre>"},{"location":"pt/concepts/video-projects/#recursos-especiais","title":"Recursos Especiais","text":"<p>Aqui est\u00e3o alguns recursos especiais que o Mosaico oferece para aprimorar projetos de v\u00eddeo:</p>"},{"location":"pt/concepts/video-projects/#geracao-de-legendas","title":"Gera\u00e7\u00e3o de Legendas","text":"<pre><code># Add subtitles from transcription\nproject.add_subtitles_from_transcription(\n    transcription=transcription,\n    max_duration=5,  # Maximum subtitle duration\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    )\n)\n</code></pre>"},{"location":"pt/concepts/video-projects/#atualizacao-em-lote-de-parametros-de-legendas","title":"Atualiza\u00e7\u00e3o em Lote de Par\u00e2metros de Legendas","text":"<pre><code># Update subtitle parameters globally\nproject.with_subtitle_params(\n    TextAssetParams(\n        font_size=48,\n        stroke_width=2\n    )\n)\n</code></pre>"},{"location":"pt/concepts/video-projects/#encadeamento-de-metodos","title":"Encadeamento de M\u00e9todos","text":"<p>A classe <code>VideoProject</code> suporta encadeamento de m\u00e9todos, o que permite chamar v\u00e1rios m\u00e9todos em um objeto em uma \u00fanica linha. Isso pode tornar seu c\u00f3digo mais conciso e f\u00e1cil de ler.</p> <pre><code>project = (\n    VideoProject(config=VideoProjectConfig())\n    .add_assets([background_image, title_text, background_music])\n    .add_timeline_events([\n        AssetReference.from_asset(background_image)\n            .with_start_time(0)\n            .with_end_time(10),\n        AssetReference.from_asset(title_text)\n            .with_start_time(1)\n            .with_end_time(9)\n    ])\n)\n</code></pre>"},{"location":"pt/concepts/video-projects/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<p>Organiza\u00e7\u00e3o de Assets</p> <ul> <li>Use IDs significativos para assets</li> <li>Agrupe assets relacionados</li> <li>Mantenha o controle das depend\u00eancias dos assets</li> </ul> <p>Estrutura da Linha do Tempo</p> <ul> <li>Organize eventos cronologicamente</li> <li>Use cenas para conte\u00fado relacionado</li> <li>Mantenha rela\u00e7\u00f5es claras de tempo</li> </ul> <p>Gerenciamento de Projetos</p> <ul> <li>Salve projetos regularmente</li> <li>Use controle de vers\u00e3o para arquivos do projeto</li> <li>Documente a estrutura do projeto</li> </ul>"},{"location":"pt/concepts/video-projects/#conclusao","title":"Conclus\u00e3o","text":"<p>Esta documenta\u00e7\u00e3o reflete a implementa\u00e7\u00e3o atual do <code>VideoProject</code> no Mosaico, focando em padr\u00f5es pr\u00e1ticos de uso e melhores pr\u00e1ticas. Os exemplos s\u00e3o projetados para funcionar com o c\u00f3digo atual e demonstrar fluxos de trabalho comuns de produ\u00e7\u00e3o de v\u00eddeo.</p>"},{"location":"pt/cookbook/adding-audio/","title":"Adicionando \u00c1udio","text":"cookbook/adding_audio.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.audio import AudioAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [...]\nimage_refs = [...]\n\n\naudios = [\n    create_asset(\"audio\", path=\"human_music.mp3\"),\n    create_asset(\"audio\", path=\"human_music_2.mp3\"),\n    create_asset(\"audio\", path=\"human_music_3.mp3\"),\n    create_asset(\"audio\", path=\"human_music_4.mp3\"),\n]\n\n# Mixing Audio using the same Time Span\nmusic_1 = (\n    AssetReference.from_asset(audios[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\nmusic_2 = (\n    AssetReference.from_asset(audios[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\nmusic_3 = (\n    AssetReference.from_asset(audios[2])\n    .with_start_time(10)\n    .with_end_time(15)\n    .with_params(params=AudioAssetParams(volume=1))\n)\nmusic_4 = (\n    AssetReference.from_asset(audios[3])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\n# Create scene\nscene = Scene(asset_references=image_refs + [music_1, music_2, music_3, music_4])\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_assets(audios).add_timeline_events(scene)\n</code></pre>"},{"location":"pt/cookbook/adding-images/","title":"Adicionando Imagens","text":"cookbook/adding_images.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import ZoomInEffect, ZoomOutEffect\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"photo_1.jpg\"),\n    create_asset(\"image\", path=\"photo_2.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(5)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()]),\n    AssetReference.from_asset(images[1])\n    .with_start_time(5)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()]),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_timeline_events(scene)\n</code></pre>"},{"location":"pt/cookbook/adding-subtitles/","title":"Adicionando Legendas","text":"cookbook/adding_subtitles.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.assets.text import TextAssetParams\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Subtitles\nsubtitles = [\n    create_asset(\n        \"text\",\n        data=\"First Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=1),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"right\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene center Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Third Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"left\", z_index=2),\n    ),\n]\n\n# Create references\nsubtitles_refs = [\n    AssetReference.from_asset(subtitles[0]).with_start_time(0).with_end_time(10),\n    AssetReference.from_asset(subtitles[1]).with_start_time(10).with_end_time(20),\n    AssetReference.from_asset(subtitles[2]).with_start_time(10).with_end_time(20),\n    AssetReference.from_asset(subtitles[3]).with_start_time(20).with_end_time(30),\n]\n\n# Create scene\nscene_1 = Scene(asset_references=[subtitles_refs[0]])\nscene_2 = Scene(asset_references=[subtitles_refs[1], subtitles_refs[2]])\nscene_3 = Scene(asset_references=[subtitles_refs[3]])\n\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig()).add_assets(subtitles).add_timeline_events([scene_1, scene_2, scene_3])\n)\n</code></pre>"},{"location":"pt/cookbook/basic-video/","title":"V\u00eddeo B\u00e1sico","text":"cookbook/basic_video.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create scene\nscene = Scene(asset_references=[image_ref, text_ref])\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets([image, text]).add_timeline_events(scene)\n</code></pre>"},{"location":"pt/cookbook/creating-custom-effects/","title":"Criando Efeitos Personalizados","text":"cookbook/creating_custom_effects.py<pre><code>from typing import Annotated, Literal\n\nfrom pydantic import Field\nfrom pydantic.functional_validators import model_validator\nfrom typing_extensions import Self\n\nfrom mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import BaseZoomEffect, ZoomInEffect\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\nclass CustomZoomOutEffect(BaseZoomEffect):\n    \"\"\"Zoom-in effect for video clips.\"\"\"\n\n    type: Literal[\"zoom_in\"] = \"zoom_in\"\n    \"\"\"Effect type. Must be \"zoom_in\".\"\"\"\n\n    start_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.0\n    \"\"\"Starting zoom scale (1.0 is original size).\"\"\"\n\n    end_zoom: Annotated[float, Field(ge=0.1, le=2)] = 1.1\n    \"\"\"Ending zoom scale.\"\"\"\n\n    @model_validator(mode=\"after\")\n    def _validate_zoom_in(self) -&gt; Self:\n        if self.start_zoom &gt;= self.end_zoom:\n            raise ValueError(\"For zoom-in, start_zoom must be less than end_zoom\")\n        return self\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"photo_1.jpg\"),\n    create_asset(\"image\", path=\"photo_2.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(5)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()]),\n    AssetReference.from_asset(images[1])\n    .with_start_time(5)\n    .with_end_time(10)\n    .with_effects(effects=[CustomZoomOutEffect(), PanRightEffect()]),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_timeline_events(scene)\n</code></pre>"},{"location":"pt/cookbook/#criacao-basica-de-video","title":"Cria\u00e7\u00e3o B\u00e1sica de V\u00eddeo","text":"<ul> <li>Cria\u00e7\u00e3o B\u00e1sica de V\u00eddeo: Exemplo simples de cria\u00e7\u00e3o de v\u00eddeo com fundo e texto</li> <li>Apresenta\u00e7\u00e3o de Fotos: Crie uma apresenta\u00e7\u00e3o animada com m\u00faltiplas imagens e m\u00fasica</li> <li>V\u00eddeo a partir de Artigo: Gere um v\u00eddeo de not\u00edcias a partir de texto de artigo usando IA</li> </ul>"},{"location":"pt/cookbook/#gerenciamento-de-assets","title":"Gerenciamento de Assets","text":"<ul> <li>Adicionando Imagens: Carregue e manipule assets de imagem com efeitos e posicionamento</li> <li>Adicionando \u00c1udio: Trabalhe com faixas de \u00e1udio incluindo mixagem e controle de volume</li> <li>Adicionando Legendas: Adicione legendas sincronizadas com estiliza\u00e7\u00e3o personalizada</li> </ul>"},{"location":"pt/cookbook/#composicao-avancada-de-cenas","title":"Composi\u00e7\u00e3o Avan\u00e7ada de Cenas","text":"<ul> <li>Cena Multicamadas: Crie cenas complexas com m\u00faltiplos assets em camadas</li> <li>Transi\u00e7\u00f5es Temporizada: Gerencie temporiza\u00e7\u00e3o e transi\u00e7\u00f5es entre cenas</li> </ul>"},{"location":"pt/cookbook/#efeitos-e-animacao","title":"Efeitos e Anima\u00e7\u00e3o","text":"<ul> <li>Criando Efeitos Personalizados: Implemente efeitos e anima\u00e7\u00f5es de v\u00eddeo personalizados</li> <li>Anima\u00e7\u00e3o de Texto: Anime elementos de texto com efeitos e temporiza\u00e7\u00e3o</li> </ul>"},{"location":"pt/cookbook/#audio-e-fala","title":"\u00c1udio e Fala","text":"<ul> <li>Sincroniza\u00e7\u00e3o de \u00c1udio: Sincronize m\u00faltiplas faixas de \u00e1udio com elementos de v\u00eddeo</li> </ul>"},{"location":"pt/cookbook/#gerenciamento-de-projeto","title":"Gerenciamento de Projeto","text":"<ul> <li>Configura\u00e7\u00e3o do Projeto: Configure as defini\u00e7\u00f5es e par\u00e2metros do projeto de v\u00eddeo</li> <li>Gerenciamento da Linha do Tempo: Organize e gerencie eventos da linha do tempo</li> </ul>"},{"location":"pt/cookbook/#integracoes-externas-wip","title":"Integra\u00e7\u00f5es Externas (WIP)","text":"<p>Exemplos de integra\u00e7\u00e3o com frameworks externos:</p> <ul> <li>Integra\u00e7\u00e3o Haystack</li> <li>Integra\u00e7\u00e3o LangChain</li> </ul>"},{"location":"pt/cookbook/multilayer-scene/","title":"Cena Multicamada","text":"cookbook/multilayer_scene.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.image import ImageAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import ZoomInEffect, ZoomOutEffect\nfrom mosaico.positioning import AbsolutePosition, RegionPosition\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"background.jpg\"),\n    create_asset(\"image\", path=\"logo.jpg\"),\n    create_asset(\"image\", path=\"credits.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()])\n    .with_params(params=ImageAssetParams(z_index=0, as_background=True)),\n    AssetReference.from_asset(images[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(params=ImageAssetParams(crop=(0, 0, 120, 120), position=AbsolutePosition(x=10, y=10), z_index=1)),\n    AssetReference.from_asset(images[2])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(\n        params=ImageAssetParams(crop=(120, 120, 220, 220), position=RegionPosition(x=\"right\", y=\"bottom\"), z_index=1)\n    ),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject = VideoProject(config=VideoProjectConfig()).add_assets(images).add_timeline_events(scene)\n</code></pre>"},{"location":"pt/cookbook/project-config/","title":"Configura\u00e7\u00e3o de Projeto de V\u00eddeo","text":"cookbook/project_config.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create scene\nscene = Scene(asset_references=[image_ref, text_ref])\n\n# Handle with frame rate\nconfig_1 = VideoProjectConfig(resolution=(1920, 1080), fps=30)\n\nconfig_2 = VideoProjectConfig(resolution=(1080, 1920), fps=60)\n\n# Create projects\nproject_1 = VideoProject(config=config_1).add_assets([image, text]).add_timeline_events(scene)\n\nproject_2 = VideoProject(config=config_2).add_assets([image, text]).add_timeline_events(scene)\n</code></pre>"},{"location":"pt/cookbook/syncing-audio/","title":"Sincronizando \u00c1udio","text":"cookbook/syncing_audio.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.audio import AudioAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [...]\nimage_refs = [...]\n\n\naudios = [\n    create_asset(\"audio\", path=\"human_music.mp3\"),\n    create_asset(\"audio\", path=\"human_music_2.mp3\"),\n    create_asset(\"audio\", path=\"human_music_3.mp3\"),\n    create_asset(\"audio\", path=\"human_music_4.mp3\"),\n]\n\n# Mixing Audio using the same Time Span\nmusic_1 = (\n    AssetReference.from_asset(audios[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\nmusic_2 = (\n    AssetReference.from_asset(audios[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\nmusic_3 = (\n    AssetReference.from_asset(audios[2])\n    .with_start_time(10)\n    .with_end_time(15)\n    .with_params(params=AudioAssetParams(volume=1))\n)\nmusic_4 = (\n    AssetReference.from_asset(audios[3])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_params(params=AudioAssetParams(volume=0.5))\n)\n\n# Create scene\nscene_1 = Scene(asset_references=image_refs + [music_1, music_2])\nscene_2 = Scene(asset_references=image_refs + [music_1, music_2])\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig())\n    .add_assets(images)\n    .add_assets(audios)\n    .add_timeline_events([scene_1, scene_2])\n)\n</code></pre>"},{"location":"pt/cookbook/text-animation/","title":"Anima\u00e7\u00e3o de Texto","text":"cookbook/text_animation.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.assets.text import TextAssetParams\nfrom mosaico.effects.fade import FadeInEffect, FadeOutEffect\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Subtitles\nsubtitles = [\n    create_asset(\n        \"text\",\n        data=\"First Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=1),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"right\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Second Scene center Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"center\", z_index=2),\n    ),\n    create_asset(\n        \"text\",\n        data=\"Third Scene Subtitles\",\n        params=TextAssetParams(font_size=20, font_family=\"Arial\", align=\"left\", z_index=2),\n    ),\n]\n\n# Create references\nsubtitles_refs = [\n    AssetReference.from_asset(subtitles[0]).with_start_time(0).with_end_time(10).with_effects(effects=[FadeInEffect()]),\n    AssetReference.from_asset(subtitles[1])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_effects(effects=[FadeOutEffect()]),\n    AssetReference.from_asset(subtitles[2])\n    .with_start_time(10)\n    .with_end_time(20)\n    .with_effects(effects=[FadeOutEffect()]),\n    AssetReference.from_asset(subtitles[3])\n    .with_start_time(20)\n    .with_end_time(30)\n    .with_effects(effects=[FadeInEffect()]),\n]\n\n# Create scene\nscene_1 = Scene(asset_references=[subtitles_refs[0]])\nscene_2 = Scene(asset_references=[subtitles_refs[1], subtitles_refs[2]])\nscene_3 = Scene(asset_references=[subtitles_refs[3]])\n\n\n# Create project\nproject = (\n    VideoProject(config=VideoProjectConfig()).add_assets(subtitles).add_timeline_events([scene_1, scene_2, scene_3])\n)\n</code></pre>"},{"location":"pt/cookbook/timed-transition/","title":"Transi\u00e7\u00f5es por Tempo","text":"cookbook/timed_transition.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.image import ImageAssetParams\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.effects.pan import PanLeftEffect, PanRightEffect\nfrom mosaico.effects.zoom import ZoomInEffect, ZoomOutEffect\nfrom mosaico.positioning import AbsolutePosition, RegionPosition\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimages = [\n    create_asset(\"image\", path=\"background.jpg\"),\n    create_asset(\"image\", path=\"logo.jpg\"),\n    create_asset(\"image\", path=\"credits.jpg\"),\n]\n\nimage_refs = [\n    AssetReference.from_asset(images[0])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomInEffect(), PanLeftEffect()])\n    .with_params(params=ImageAssetParams(z_index=0, as_background=True)),\n    AssetReference.from_asset(images[1])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(params=ImageAssetParams(crop=(0, 0, 120, 120), position=AbsolutePosition(x=10, y=10), z_index=1)),\n    AssetReference.from_asset(images[2])\n    .with_start_time(0)\n    .with_end_time(10)\n    .with_effects(effects=[ZoomOutEffect(), PanRightEffect()])\n    .with_params(\n        params=ImageAssetParams(crop=(120, 120, 220, 220), position=RegionPosition(x=\"right\", y=\"bottom\"), z_index=1)\n    ),\n]\n\n# Create scene\nscene = Scene(asset_references=image_refs)\n\n# Create project\nproject_2 = (\n    VideoProject(\n        config=VideoProjectConfig(\n            resolution=(1920, 1080),\n        )\n    )\n    .add_assets(images)\n    .add_timeline_events(scene)\n)\n\n# Create project\nproject_2 = (\n    VideoProject(\n        config=VideoProjectConfig(\n            resolution=(1080, 1920),\n        )\n    )\n    .add_assets(images)\n    .add_timeline_events(scene)\n)\n</code></pre>"},{"location":"pt/cookbook/timeline-management/","title":"Gerenciamento de Timeline","text":"cookbook/timeline_management.py<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create scene\nscene_1 = Scene(asset_references=[image_ref, text_ref])\nscene_2 = Scene(asset_references=[image_ref, text_ref])\nscene_3 = Scene(asset_references=[image_ref, text_ref])\nscene_4 = Scene(asset_references=[image_ref, text_ref])\n\n# Handle with frame rate\nconfig = VideoProjectConfig(resolution=(1920, 1080), fps=30)\n\n# Create projects\nproject = (\n    VideoProject(config=config)\n    .add_assets([image, text])\n    .add_timeline_events([scene_3, scene_2, scene_1, scene_4])  # Handle Scene Ordering\n)\n</code></pre>"},{"location":"pt/cookbook/video-from-article/","title":"V\u00eddeo a Partir de Artigo","text":"cookbook/video_from_article.py<pre><code>from mosaico.audio_transcribers.assemblyai import AssemblyAIAudioTranscriber\nfrom mosaico.script_generators.news import NewsVideoScriptGenerator\nfrom mosaico.speech_synthesizers.elevenlabs import ElevenLabsSpeechSynthesizer\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\n\n\n# Setup\n### Note: To deal with AI, see cookbooks at AI section.\nscript_generator = NewsVideoScriptGenerator(\n    context=\"breaking news text...\", api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL\n)\n\nspeech_synthesizer = ElevenLabsSpeechSynthesizer(\n    api_key=ELEVENLABS_API_KEY,\n    voice_id=\"Xb7hH8MSUJpSbSDYk0k2\",\n    voice_stability=0.8,\n    voice_similarity_boost=0.75,\n    voice_speaker_boost=False,\n)\n\n# Create assets\nimages = [...]  # List of image Assets\n\naudio_transcriber = AssemblyAIAudioTranscriber(api_key=ASSEMBLYAI_API_KEY)\nconfig = VideoProjectConfig(name=\"Breaking News\")\nproject = VideoProject.from_script_generator(\n    script_generator,\n    images,\n    config=config,\n    speech_synthesizer=speech_synthesizer,\n    audio_transcriber=audio_transcriber,\n)\n</code></pre>"},{"location":"pt/development/contributing/","title":"Contribuindo","text":"<p>Recebemos contribui\u00e7\u00f5es da comunidade para ajudar a melhorar e expandir este framework de gera\u00e7\u00e3o de v\u00eddeo de c\u00f3digo aberto.</p>"},{"location":"pt/development/contributing/#comecando","title":"Come\u00e7ando","text":"<ol> <li>Fa\u00e7a um fork e clone o reposit\u00f3rio</li> <li>Instale o uv</li> <li>Execute os seguintes comandos:</li> <li><code>make install</code> para instalar as depend\u00eancias</li> <li><code>make test</code> para executar os testes unit\u00e1rios</li> <li><code>make format</code> para formatar o c\u00f3digo</li> <li><code>make lint</code> para analisar o c\u00f3digo</li> <li><code>make docs</code> para gerar a documenta\u00e7\u00e3o</li> <li><code>make docs-serve</code> para servir a documenta\u00e7\u00e3o localmente</li> </ol> <p>Agora voc\u00ea est\u00e1 pronto para come\u00e7ar a contribuir!</p>"},{"location":"pt/development/contributing/#enviando-alteracoes","title":"Enviando Altera\u00e7\u00f5es","text":"<ol> <li>Certifique-se que todos os testes passam e o c\u00f3digo est\u00e1 formatado corretamente</li> <li>Atualize a documenta\u00e7\u00e3o conforme necess\u00e1rio</li> <li>Envie suas altera\u00e7\u00f5es e crie um pull request com:<ul> <li>Descri\u00e7\u00e3o clara das altera\u00e7\u00f5es</li> <li>Prop\u00f3sito e motiva\u00e7\u00e3o</li> <li>Quaisquer issues relacionadas</li> </ul> </li> <li>Responda ao feedback de revis\u00e3o prontamente</li> </ol>"},{"location":"pt/development/contributing/#reportando-issues","title":"Reportando Issues","text":"<p>Se voc\u00ea encontrar um bug ou tiver uma sugest\u00e3o de funcionalidade:</p> <ol> <li>Verifique primeiro as issues existentes</li> <li>Abra uma nova issue com:<ul> <li>Descri\u00e7\u00e3o clara</li> <li>Passos para reproduzir (para bugs)</li> <li>Comportamento esperado vs real</li> <li>Detalhes do ambiente</li> <li>Screenshots/exemplos se aplic\u00e1vel</li> </ul> </li> </ol>"},{"location":"pt/development/contributing/#diretrizes-de-desenvolvimento","title":"Diretrizes de Desenvolvimento","text":"<ul> <li>Escreva c\u00f3digo claro e documentado</li> <li>Siga o estilo de c\u00f3digo existente</li> <li>Adicione testes para novas funcionalidades</li> <li>Mantenha PRs focados e at\u00f4micos</li> <li>Documente mudan\u00e7as significativas</li> </ul>"},{"location":"pt/development/contributing/#licenca","title":"Licen\u00e7a","text":"<p>Ao contribuir para o Mosaico, voc\u00ea concorda que suas contribui\u00e7\u00f5es ser\u00e3o licenciadas sob a licen\u00e7a do projeto (veja arquivo LICENSE).</p>"},{"location":"pt/getting-started/architecture/","title":"Arquitetura","text":"<p>Mosaico segue uma arquitetura modular organizada em torno de v\u00e1rios conceitos-chave:</p>"},{"location":"pt/getting-started/architecture/#assets","title":"Assets","text":"<p>O fundamento da biblioteca \u00e9 o sistema de assets. Assets representam elementos de m\u00eddia que podem ser compostos em cenas. A classe base <code>BaseAsset</code> fornece funcionalidade central, com implementa\u00e7\u00f5es especializadas para diferentes tipos de m\u00eddia.</p>"},{"location":"pt/getting-started/architecture/#posicionamento","title":"Posicionamento","text":"<p>O sistema de posicionamento oferece m\u00faltiplas formas de posicionar elementos em um quadro atrav\u00e9s do protocolo <code>Position</code>, com implementa\u00e7\u00f5es para posicionamento absoluto, relativo e baseado em regi\u00f5es.</p>"},{"location":"pt/getting-started/architecture/#efeitos","title":"Efeitos","text":"<p>Os efeitos s\u00e3o implementados atrav\u00e9s do protocolo <code>Effect</code>, permitindo anima\u00e7\u00f5es e efeitos visuais extens\u00edveis. Os efeitos integrados incluem recursos de panor\u00e2mica e zoom.</p>"},{"location":"pt/getting-started/architecture/#cenas","title":"Cenas","text":"<p>Cenas agrupam assets relacionados e gerenciam seu timing e organiza\u00e7\u00e3o. A classe <code>Scene</code> lida com refer\u00eancias de assets e coordena\u00e7\u00e3o de timing.</p>"},{"location":"pt/getting-started/architecture/#geracao-de-script","title":"Gera\u00e7\u00e3o de Script","text":"<p>A gera\u00e7\u00e3o de script \u00e9 tratada atrav\u00e9s do protocolo <code>ScriptGenerator</code>, com implementa\u00e7\u00f5es para casos de uso espec\u00edficos como gera\u00e7\u00e3o de v\u00eddeos de not\u00edcias.</p>"},{"location":"pt/getting-started/architecture/#sintese-de-fala","title":"S\u00edntese de Fala","text":"<p>A s\u00edntese de fala \u00e9 abstra\u00edda atrav\u00e9s do protocolo <code>SpeechSynthesizer</code>, com implementa\u00e7\u00f5es para diferentes provedores de TTS.</p>"},{"location":"pt/getting-started/architecture/#diagrama-simplificado","title":"Diagrama Simplificado","text":"<pre><code>graph TD\n    subgraph Core\n        Media[Media] --&gt; Asset[Asset]\n        Asset --&gt; |references| Scene\n        Position --&gt; Asset\n        Effect --&gt; Scene\n    end\n\n    subgraph Assets\n        Asset --&gt; ImageAsset\n        Asset --&gt; AudioAsset\n        Asset --&gt; TextAsset\n        Asset --&gt; SubtitleAsset\n    end\n\n    subgraph Generators\n        ScriptGenerator --&gt; Scene\n        SpeechSynthesizer --&gt; AudioAsset\n    end\n\n    subgraph Integrations\n        Adapter --&gt; Media\n        Adapter --&gt; ScriptGenerator\n    end\n\n    classDef protocol fill:#f9f,stroke:#333,stroke-width:2px\n    classDef base fill:#bbf,stroke:#333,stroke-width:2px\n    classDef concrete fill:#dfd,stroke:#333,stroke-width:2px\n\n    class Position,Effect,ScriptGenerator,SpeechSynthesizer,Adapter protocol\n    class Media,Asset base\n    class ImageAsset,AudioAsset,TextAsset,SubtitleAsset concrete</code></pre>"},{"location":"pt/getting-started/installation/","title":"Instala\u00e7\u00e3o","text":""},{"location":"pt/getting-started/installation/#requisitos","title":"Requisitos","text":"<p>Antes de instalar o framework Mosaico, voc\u00ea precisa garantir que tem os seguintes pr\u00e9-requisitos:</p> <ol> <li> <p>Python 3.10 ou superior</p> <p>O Mosaico requer Python 3.10 ou superior. Voc\u00ea pode verificar sua vers\u00e3o do Python executando:</p> <pre><code>python --version\n</code></pre> <p>Se voc\u00ea precisar atualizar ou instalar o Python, visite python.org para obter a vers\u00e3o mais recente.</p> </li> <li> <p>FFmpeg</p> <p>O Mosaico depende do FFmpeg para processamento de v\u00eddeo. Voc\u00ea deve ter o FFmpeg instalado e dispon\u00edvel no PATH do seu sistema.</p> <p>Para verificar se o FFmpeg est\u00e1 instalado, execute:</p> <pre><code>ffmpeg -version\n</code></pre> <p>Se n\u00e3o estiver instalado, voc\u00ea pode obt\u00ea-lo em ffmpeg.org ou usar o gerenciador de pacotes do seu sistema operacional.</p> Ubuntu/DebianmacOS (com Homebrew)Windows (com Chocolatey) <pre><code>sudo apt update\nsudo apt install ffmpeg\n</code></pre> <pre><code>brew install ffmpeg\n</code></pre> <pre><code>choco install ffmpeg\n</code></pre> </li> </ol> <p>Depois de garantir que esses pr\u00e9-requisitos estejam satisfeitos, voc\u00ea pode prosseguir com a instala\u00e7\u00e3o do Mosaico.</p>"},{"location":"pt/getting-started/installation/#instalacao_1","title":"Instala\u00e7\u00e3o","text":"<p>Para instalar o Mosaico, execute o seguinte comando de acordo com seu gerenciador de pacotes preferido:</p> pippipxuvpoetrypdm <pre><code>pip install mosaico\n</code></pre> <pre><code>pipx install mosaico\n</code></pre> <pre><code>uv add mosaico\n</code></pre> <pre><code>poetry add mosaico\n</code></pre> <pre><code>pdm add mosaico\n</code></pre> <p>Tamb\u00e9m \u00e9 poss\u00edvel instalar o Mosaico a partir do c\u00f3digo fonte clonando o reposit\u00f3rio e executando o seguinte comando:</p> <pre><code>git clone https://github.com/folhalab/mosaico.git\ncd mosaico\npip install -e .\n</code></pre>"},{"location":"pt/getting-started/installation/#dependencias-adicionais","title":"Depend\u00eancias Adicionais","text":"<p>Para instalar depend\u00eancias opcionais para o Mosaico, use o seguinte comando, substituindo <code>news</code> pelo recurso desejado ou concatenando m\u00faltiplos recursos separados por v\u00edrgulas:</p> Recurso \u00fanicoM\u00faltiplos recursos <pre><code>pip install \"mosaico[news]\"\n</code></pre> <pre><code>pip install \"mosaico[news,elevenlabs,assemblyai]\"\n</code></pre> <p>Os recursos dispon\u00edveis e suas depend\u00eancias est\u00e3o listados abaixo:</p> Recurso Componente Depend\u00eancias Descri\u00e7\u00e3o <code>news</code> gerador de script <code>litellm</code>, <code>instructor</code> Gera\u00e7\u00e3o de scripts para v\u00eddeos baseada em IA <code>openai</code> sintetizador de fala, transcritor de \u00e1udio <code>openai</code> Integra\u00e7\u00f5es de s\u00edntese de texto para fala e transcri\u00e7\u00e3o de \u00e1udio com OpenAI <code>elevenlabs</code> sintetizador de fala <code>elevenlabs</code> Integra\u00e7\u00e3o de s\u00edntese de texto para fala com ElevenLabs <code>assemblyai</code> transcritor de \u00e1udio <code>assemblyai</code> Integra\u00e7\u00e3o de transcri\u00e7\u00e3o de \u00e1udio com AssemblyAI"},{"location":"pt/getting-started/quick-start/","title":"In\u00edcio r\u00e1pido","text":""},{"location":"pt/getting-started/quick-start/#criando-assets","title":"Criando Assets","text":"From factory functionFrom asset classes <pre><code>from mosaico.assets import create_asset\n\n# Create an image asset\nimage = create_asset(\"image\", path=\"background.jpg\")\n\n# Create a text asset\ntext = create_asset(\"text\", data=\"Hello World\")\n\n# Create an audio asset\naudio = create_asset(\"audio\", path=\"narration.mp3\")\n</code></pre> <p>O <code>create_asset()</code> cria tipos diferentes de assets:</p> <ul> <li>Cada tipo de asset requer um identificador unico (\"image\", \"audio\", \"text\", \"subtitle\")</li> <li>Os ativos podem ser criados a partir de arquivos usando <code>path</code> ou dados diretos usando <code>data</code></li> <li>Os ativos detectam automaticamente propriedades como dimens\u00f5es, dura\u00e7\u00e3o, etc.</li> </ul> <pre><code>from mosaico.assets import ImageAsset, TextAsset, AudioAsset\n\n# Create an image asset\nimage = ImageAsset.from_path(\"background.jpg\")\n\n# Create a text asset\ntext = TextAsset.from_data(\"Hello World\")\n\n# Create an audio asset\naudio = AudioAsset.from_path(\"narration.mp3\")\n</code></pre> <p>Alternativamente, os ativos podem ser criados diretamente usando suas respectivas classes:</p> <ul> <li>Cada classe de ativos tem propriedades e m\u00e9todos espec\u00edficos</li> <li>Os ativos podem ser criados a partir de arquivos usando <code>from_path()</code> ou dados diretos usando <code>from_data()</code></li> <li>Os ativos detectam automaticamente propriedades como dimens\u00f5es, dura\u00e7\u00e3o, etc.</li> </ul>"},{"location":"pt/getting-started/quick-start/#criando-referencias-de-assets","title":"Criando refer\u00eancias de assets","text":"<pre><code>from mosaico.assets.reference import AssetReference\n\n# Create reference for background image\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\n\n# Create reference for text overlay\ntext_ref = AssetReference.from_asset(text).with_start_time(1).with_end_time(4)\n\n# Create reference for audio narration\naudio_ref = AssetReference.from_asset(audio).with_start_time(0).with_end_time(5)\n</code></pre> <p>As refer\u00eancias de ativos determinam quando e como os ativos aparecem no v\u00eddeo:</p> <ul> <li><code>from_asset()</code> cria uma refer\u00eancia a partir de um ativo</li> <li><code>with_start_time()</code> define quando o ativo aparece</li> <li><code>with_end_time()</code> define quando o ativo desaparece</li> <li>Os tempos est\u00e3o em segundos</li> <li>As refer\u00eancias tamb\u00e9m podem incluir efeitos e par\u00e2metros personalizados</li> </ul>"},{"location":"pt/getting-started/quick-start/#criando-uma-cena","title":"Criando uma cena","text":"<pre><code>from mosaico.scene import Scene\n\n# Create a scene containing the assets\nscene = Scene(asset_references=[image_ref, text_ref, audio_ref])\n</code></pre> <p>Cenas agrupam ativos relacionados:</p> <ul> <li>Pega uma lista de refer\u00eancias de ativos</li> <li>Lida com tempo e sincroniza\u00e7\u00e3o</li> <li>Pode incluir t\u00edtulo e descri\u00e7\u00e3o</li> <li>V\u00e1rias cenas podem ser combinadas em um projeto</li> </ul>"},{"location":"pt/getting-started/quick-start/#criando-um-projeto-completo","title":"Criando um Projeto Completo","text":"<pre><code>from mosaico.video.project import VideoProject, VideoProjectConfig\n\n# Create project configuration\nconfig = VideoProjectConfig(\n    name=\"My First Video\",\n    resolution=(1920, 1080),\n    fps=30\n)\n\n# Create, configure and add assets and scene to the project\nproject = (\n    VideoProject(config=config)\n    .add_assets([image, text, audio])\n    .add_timeline_events(scene)\n)\n</code></pre> <p>O <code>VideoProject</code> une tudo:</p> <ul> <li>Configurar as configura\u00e7\u00f5es do projeto, como resolu\u00e7\u00e3o e taxa de quadros</li> <li>Adicione todos os ativos usados \u200b\u200bno v\u00eddeo</li> <li>Adicionar cenas \u00e0 linha do tempo</li> <li>Gerencia a composi\u00e7\u00e3o completa do v\u00eddeo</li> </ul>"},{"location":"pt/getting-started/quick-start/#exportar-o-projeto-de-video","title":"Exportar o Projeto de V\u00eddeo","text":"<p>O projeto pode ser exportado para um arquivo YAML:</p> <pre><code>project.to_file(\"my_first_video.yml\")\n</code></pre>"},{"location":"pt/getting-started/quick-start/#opcional-adicionando-efeitos","title":"Opcional: Adicionando efeitos","text":"<pre><code>from mosaico.effects.factory import create_effect\n\n# Create a zoom effect\nzoom_effect = create_effect(\"zoom_in\", start_zoom=1.0, end_zoom=1.2)\n\n# Add effect to text reference\ntext_ref = text_ref.with_effects([zoom_effect])\n</code></pre> <p>Efeitos podem ser adicionados \u00e0s refer\u00eancias de Assets:</p> <ul> <li>V\u00e1rios efeitos integrados (zoom, pan)</li> <li>Os efeitos t\u00eam par\u00e2metros configur\u00e1veis</li> <li>V\u00e1rios efeitos podem ser combinados</li> <li>Os efeitos s\u00e3o aplicados durante a renderiza\u00e7\u00e3o</li> </ul>"},{"location":"pt/getting-started/quick-start/#exemplo-completo","title":"Exemplo completo","text":"<pre><code>from mosaico.assets import create_asset\nfrom mosaico.assets.reference import AssetReference\nfrom mosaico.scene import Scene\nfrom mosaico.video.project import VideoProject, VideoProjectConfig\nfrom mosaico.effects.factory import create_effect\n\n# 1. Create assets\nimage = create_asset(\"image\", path=\"background.jpg\")\ntext = create_asset(\"text\", data=\"Hello World\")\naudio = create_asset(\"audio\", path=\"narration.mp3\")\n\n# 2. Create effect\nzoom_effect = create_effect(\"zoom_in\", start_zoom=1.0, end_zoom=1.2)\n\n# 3. Create asset references with timing\nimage_ref = AssetReference.from_asset(image).with_start_time(0).with_end_time(5)\ntext_ref = (\n    AssetReference.from_asset(text)\n    .with_start_time(1)\n    .with_end_time(4)\n    .with_effects([zoom_effect])\n)\naudio_ref = AssetReference.from_asset(audio).with_start_time(0).with_end_time(5)\n\n# 4. Create scene\nscene = Scene(\n    title=\"Opening Scene\",\n    asset_references=[image_ref, text_ref, audio_ref]\n)\n\n# 5. Create, configure and add assets and events to the project\nproject = (\n    VideoProject(\n        config=VideoProjectConfig(\n            name=\"My First Video\",\n            resolution=(1920, 1080),\n            fps=30\n        )\n    )\n    .add_assets([image, text, audio])\n    .add_timeline_events(scene)\n)\n\n# 6. Save project\nproject.to_file(\"my_video.yml\")\n</code></pre> <p>Isso cria um v\u00eddeo de 5 segundos com:</p> <ul> <li>Uma imagem de fundo</li> <li>Texto que aparece aos 1s com um efeito de zoom</li> <li>Narra\u00e7\u00e3o em \u00e1udio durante todo o v\u00eddeo</li> <li>Resolu\u00e7\u00e3o HD a 30fps</li> </ul> <p>O projeto pode ser salvo em um arquivo YAML para edi\u00e7\u00e3o ou renderiza\u00e7\u00e3o posterior.</p>"},{"location":"pt/integrations/","title":"Integra\u00e7\u00f5es","text":""},{"location":"pt/integrations/#integracoes-com-frameworks-de-ia","title":"Integra\u00e7\u00f5es com Frameworks de IA","text":"<p>O Mosaico se integra com frameworks populares de IA para processamento de documentos e gera\u00e7\u00e3o de scripts:</p> <ul> <li>Haystack - Processamento de documentos e gera\u00e7\u00e3o de scripts</li> <li>LangChain - Processamento de documentos e fluxos de trabalho de IA</li> </ul>"},{"location":"pt/integrations/#integracoes-de-fala-e-transcricao","title":"Integra\u00e7\u00f5es de Fala e Transcri\u00e7\u00e3o","text":"<p>O Mosaico fornece integra\u00e7\u00f5es com servi\u00e7os de s\u00edntese de fala e transcri\u00e7\u00e3o:</p> <ul> <li>OpenAI - Convers\u00e3o de texto em fala e transcri\u00e7\u00e3o via Whisper</li> <li>ElevenLabs - S\u00edntese de fala de alta qualidade</li> <li>AssemblyAI - Transcri\u00e7\u00e3o avan\u00e7ada de \u00e1udio</li> </ul>"},{"location":"pt/integrations/frameworks/haystack/","title":"Haystack","text":"<p>Esta p\u00e1gina de documenta\u00e7\u00e3o est\u00e1 atualmente em constru\u00e7\u00e3o e ser\u00e1 atualizada em breve.</p>"},{"location":"pt/integrations/frameworks/langchain/","title":"LangChain","text":"<p>Esta p\u00e1gina de documenta\u00e7\u00e3o est\u00e1 atualmente em constru\u00e7\u00e3o e ser\u00e1 atualizada em breve.</p>"},{"location":"pt/integrations/platforms/assemblyai/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>A integra\u00e7\u00e3o do AssemblyAI no Mosaico fornece recursos automatizados de transcri\u00e7\u00e3o de fala para texto para ativos de \u00e1udio. Essa integra\u00e7\u00e3o permite transcri\u00e7\u00e3o precisa com temporiza\u00e7\u00e3o em n\u00edvel de palavra, essencial para gera\u00e7\u00e3o de legendas e sincroniza\u00e7\u00e3o de conte\u00fado.</p>"},{"location":"pt/integrations/platforms/assemblyai/#requisitos","title":"Requisitos","text":"<ul> <li>Pacote Python AssemblyAI (<code>pip install assemblyai</code>)</li> <li>Chave de API v\u00e1lida do AssemblyAI</li> <li>\u00c1udio em formato suportado (MP3, WAV, etc.)</li> </ul>"},{"location":"pt/integrations/platforms/assemblyai/#uso","title":"Uso","text":"<pre><code>from mosaico.audio_transcribers import AssemblyAIAudioTranscriber\nfrom mosaico.assets.audio import AudioAsset\nfrom mosaico.video.project import VideoProject\n\n# Initialize transcriber\ntranscriber = AssemblyAIAudioTranscriber(\n    api_key=\"your_api_key\",\n    model=\"best\",  # or \"nano\" for faster processing\n    language=\"en\"  # optional language specification\n)\n\n# Create audio asset\naudio = AudioAsset.from_path(\"narration.mp3\")\n\n# Transcribe audio\ntranscription = transcriber.transcribe(audio)\n\n# Access transcription results\nfor word in transcription.words:\n    print(f\"{word.text}: {word.start_time} - {word.end_time}\")\n</code></pre>"},{"location":"pt/integrations/platforms/assemblyai/#opcoes-de-configuracao","title":"Op\u00e7\u00f5es de Configura\u00e7\u00e3o","text":"<p>O <code>AssemblyAIAudioTranscriber</code> suporta v\u00e1rias op\u00e7\u00f5es de configura\u00e7\u00e3o:</p> <ul> <li><code>api_key</code>: Sua chave de API do AssemblyAI (obrigat\u00f3rio)</li> <li><code>model</code>: Modelo de transcri\u00e7\u00e3o a ser usado (<code>best</code> ou <code>nano</code>)</li> <li><code>language</code>: Especifica\u00e7\u00e3o opcional de idioma</li> <li><code>custom_spelling</code>: Dicion\u00e1rio de corre\u00e7\u00f5es ortogr\u00e1ficas personalizadas</li> </ul>"},{"location":"pt/integrations/platforms/assemblyai/#recursos","title":"Recursos","text":""},{"location":"pt/integrations/platforms/assemblyai/#deteccao-de-idioma","title":"Detec\u00e7\u00e3o de Idioma","text":"<pre><code># Automatic language detection\ntranscriber = AssemblyAIAudioTranscriber(\n    api_key=\"your_api_key\",\n    language=None  # Enables automatic detection\n)\n</code></pre>"},{"location":"pt/integrations/platforms/assemblyai/#ortografia-personalizada","title":"Ortografia Personalizada","text":"<pre><code># Add custom spelling corrections\ntranscriber = AssemblyAIAudioTranscriber(\n    api_key=\"your_api_key\",\n    custom_spelling={\n        \"mosaico\": \"Mosaico\",\n        \"ai\": [\"AI\", \"A.I.\"]\n    }\n)\n</code></pre>"},{"location":"pt/integrations/platforms/assemblyai/#integracao-com-projetos-de-video","title":"Integra\u00e7\u00e3o com Projetos de V\u00eddeo","text":"<p>A transcri\u00e7\u00e3o pode ser usada de v\u00e1rias maneiras com projetos de v\u00eddeo:</p> <pre><code># Create video project\nproject = VideoProject()\n\n# Add audio asset\nproject.add_assets(audio_asset)\n\n# Add captions from transcriber\nproject = project.add_captions_from_transcriber(\n    transcriber,\n    max_duration=5,  # Maximum subtitle duration\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    ),\n    overwrite=False  # Don't overwrite existing captions\n)\n\n# Or manually add captions from transcription\nproject = project.add_captions(\n    transcription,\n    max_duration=5,\n    params=TextAssetParams(\n        font_size=36,\n        font_color=\"white\"\n    ),\n    scene_index=0,  # Add to specific scene\n    overwrite=True  # Replace existing captions\n)\n</code></pre>"},{"location":"pt/integrations/platforms/elevenlabs/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Mosaico integra-se com a API de texto para fala da ElevenLabs atrav\u00e9s da classe <code>ElevenLabsSpeechSynthesizer</code>, fornecendo s\u00edntese de voz de alta qualidade para narra\u00e7\u00e3o de v\u00eddeo. Esta integra\u00e7\u00e3o suporta m\u00faltiplos idiomas, personaliza\u00e7\u00e3o de voz e processamento em lote de texto.</p>"},{"location":"pt/integrations/platforms/elevenlabs/#configuracao","title":"Configura\u00e7\u00e3o","text":"<pre><code>from mosaico.speech_synthesizers import ElevenLabsSpeechSynthesizer\n\nsynthesizer = ElevenLabsSpeechSynthesizer(\n    api_key=\"your-api-key\",            # ElevenLabs API key\n    voice_id=\"voice-id\",               # Selected voice ID\n    model=\"eleven_multilingual_v2\",    # Model to use\n    language_code=\"en\",                # Language code\n\n    # Voice customization\n    voice_stability=0.5,               # Voice consistency (0-1)\n    voice_similarity_boost=0.5,        # Voice matching accuracy (0-1)\n    voice_style=0.5,                   # Style intensity (0-1)\n    voice_speaker_boost=True           # Enhanced speaker clarity\n)\n</code></pre>"},{"location":"pt/integrations/platforms/elevenlabs/#modelos-suportados","title":"Modelos Suportados","text":"<ul> <li><code>eleven_turbo_v2_5</code> - Modelo turbo mais recente</li> <li><code>eleven_turbo_v2</code> - Modelo de s\u00edntese r\u00e1pida</li> <li><code>eleven_multilingual_v2</code> - Suporte multi-idiomas</li> <li><code>eleven_monolingual_v1</code> - Modelo apenas em ingl\u00eas</li> <li><code>eleven_multilingual_v1</code> - Multi-idiomas legado</li> </ul>"},{"location":"pt/integrations/platforms/elevenlabs/#sintese-de-voz","title":"S\u00edntese de Voz","text":""},{"location":"pt/integrations/platforms/elevenlabs/#uso-basico","title":"Uso B\u00e1sico","text":"<pre><code># Generate audio assets from text\naudio_assets = synthesizer.synthesize(\n    texts=[\"Hello world\", \"Welcome to Mosaico\"]\n)\n\n# Use in video project\nproject.add_assets(audio_assets)\n</code></pre>"},{"location":"pt/integrations/platforms/elevenlabs/#com-parametros-personalizados","title":"Com Par\u00e2metros Personalizados","text":"<pre><code>from mosaico.assets.audio import AudioAssetParams\n\n# Configure audio parameters\naudio_params = AudioAssetParams(\n    volume=0.8,\n    crop=(0, 10)  # Crop first 10 seconds\n)\n\n# Generate audio with parameters\naudio_assets = synthesizer.synthesize(\n    texts=[\"Narration text\"],\n    audio_params=audio_params\n)\n</code></pre>"},{"location":"pt/integrations/platforms/elevenlabs/#recursos-avancados","title":"Recursos Avan\u00e7ados","text":""},{"location":"pt/integrations/platforms/elevenlabs/#consciencia-de-contexto","title":"Consci\u00eancia de Contexto","text":"<p>O sintetizador mant\u00e9m o contexto entre segmentos de texto consecutivos para um fluxo natural:</p> <pre><code>texts = [\n    \"This is the first sentence.\",\n    \"This is the second sentence.\",\n    \"This is the final sentence.\"\n]\n\n# Each segment will be synthesized with awareness of surrounding text\naudio_assets = synthesizer.synthesize(texts)\n</code></pre>"},{"location":"pt/integrations/platforms/elevenlabs/#personalizacao-de-voz","title":"Personaliza\u00e7\u00e3o de Voz","text":"<p>Ajuste fino das caracter\u00edsticas da voz:</p> <pre><code>synthesizer = ElevenLabsSpeechSynthesizer(\n    voice_id=\"voice-id\",\n    voice_stability=0.8,        # More consistent voice\n    voice_similarity_boost=0.7, # Higher accuracy\n    voice_style=0.6,           # Stronger style\n    voice_speaker_boost=True    # Enhanced clarity\n)\n</code></pre>"},{"location":"pt/integrations/platforms/elevenlabs/#integracao-com-projetos-de-video","title":"Integra\u00e7\u00e3o com Projetos de V\u00eddeo","text":"<pre><code>from mosaico.video.project import VideoProject\n\n# Create project from script generator\nproject = VideoProject.from_script_generator(\n    script_generator=news_generator,\n    media=media_files\n)\n\n# Add narration to scenes with subtitles\nproject.add_narration(synthesizer)\n\n# Or add specific narration\nscene = project.get_timeline_event(0)\nnarration_assets = synthesizer.synthesize([scene.subtitle])\nproject.add_assets(narration_assets)\n</code></pre> <p>A integra\u00e7\u00e3o com ElevenLabs permite s\u00edntese de voz de alta qualidade para seus projetos de v\u00eddeo, com extensas op\u00e7\u00f5es de personaliza\u00e7\u00e3o e suporte multi-idiomas. A integra\u00e7\u00e3o gerencia a consci\u00eancia de contexto e fornece incorpora\u00e7\u00e3o perfeita no fluxo de trabalho de produ\u00e7\u00e3o de v\u00eddeo do Mosaico.</p>"},{"location":"pt/integrations/platforms/openai/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Mosaico fornece integra\u00e7\u00e3o robusta com os servi\u00e7os da OpenAI atrav\u00e9s de dois componentes principais:</p> <ul> <li>S\u00edntese de voz usando a API Text-to-Speech da OpenAI</li> <li>Transcri\u00e7\u00e3o de \u00e1udio usando a API Whisper da OpenAI</li> </ul>"},{"location":"pt/integrations/platforms/openai/#sintese-de-voz","title":"S\u00edntese de Voz","text":"<p>A classe <code>OpenAISpeechSynthesizer</code> fornece recursos de texto para voz:</p> <pre><code>from mosaico.speech_synthesizers.openai import OpenAISpeechSynthesizer\n\nsynthesizer = OpenAISpeechSynthesizer(\n    api_key=\"your-api-key\",\n    model=\"tts-1\",              # or \"tts-1-hd\" for higher quality\n    voice=\"alloy\",              # available: alloy, echo, fable, onyx, nova, shimmer\n    speed=1.0                   # 0.25 to 4.0\n)\n\n# Generate speech assets\naudio_assets = synthesizer.synthesize(\n    texts=[\"Text to convert to speech\"],\n    audio_params=AudioAssetParams(volume=1.0)\n)\n</code></pre>"},{"location":"pt/integrations/platforms/openai/#opcoes-de-configuracao","title":"Op\u00e7\u00f5es de Configura\u00e7\u00e3o","text":"<ul> <li>Modelos:<ul> <li><code>tts-1</code>: Modelo de qualidade padr\u00e3o</li> <li><code>tts-1-hd</code>: Modelo de alta defini\u00e7\u00e3o</li> </ul> </li> <li>Vozes:<ul> <li>alloy: Neutra e equilibrada</li> <li>echo: Quente e clara</li> <li>fable: Expressiva e din\u00e2mica</li> <li>onyx: Profunda e autorit\u00e1ria</li> <li>nova: Energ\u00e9tica e brilhante</li> <li>shimmer: Suave e acolhedora</li> </ul> </li> <li>Velocidade: Controle a taxa de fala de 0.25x a 4.0x</li> </ul>"},{"location":"pt/integrations/platforms/openai/#transcricao-de-audio","title":"Transcri\u00e7\u00e3o de \u00c1udio","text":"<p>A classe <code>OpenAIWhisperTranscriber</code> fornece recursos de fala para texto:</p> <pre><code>from mosaico.audio_transcribers.openai import OpenAIWhisperTranscriber\n\ntranscriber = OpenAIWhisperTranscriber(\n    api_key=\"your-api-key\",\n    model=\"whisper-1\",\n    language=\"en\",          # Optional language code\n    temperature=0          # Model temperature (0-1)\n)\n\n# Transcribe audio\ntranscription = transcriber.transcribe(audio_asset)\n</code></pre>"},{"location":"pt/integrations/platforms/openai/#recursos-de-transcricao","title":"Recursos de Transcri\u00e7\u00e3o","text":"<ul> <li>Timestamps em n\u00edvel de palavra</li> <li>Suporte a m\u00faltiplos idiomas</li> <li>Controle de temperatura do modelo</li> <li>Configura\u00e7\u00f5es ajust\u00e1veis de timeout</li> </ul>"},{"location":"pt/integrations/platforms/openai/#padroes-comuns-de-integracao","title":"Padr\u00f5es Comuns de Integra\u00e7\u00e3o","text":""},{"location":"pt/integrations/platforms/openai/#pipeline-de-fala-para-texto-para-fala","title":"Pipeline de Fala-para-Texto-para-Fala","text":"<pre><code># Create project\nproject = VideoProject()\n\n# Add audio asset to project\nproject.add_assets(original_audio)\n\n# Add to scene\nscene = Scene(asset_references=[\n    AssetReference.from_asset(original_audio)\n        .with_start_time(0)\n        .with_end_time(original_audio.duration)\n])\n\n# Add scene to project\nproject.add_timeline_events(scene)\n\n# Add captions from transcription\nproject.add_captions_from_transcriber(transcriber, max_duration=5)\n\n# Add narration in new language\nproject.add_narration(synthesizer)\n</code></pre>"},{"location":"pt/integrations/platforms/openai/#legendagem-de-video","title":"Legendagem de V\u00eddeo","text":"<pre><code># Add captions directly from audio\nproject.add_captions_from_transcriber(\n    transcriber,\n    max_duration=5,\n    params=TextAssetParams(\n        font_size=48,\n        font_color=\"white\"\n    )\n)\n\n# Or add captions from existing transcription\nproject.add_captions(\n    transcription,\n    max_duration=5,\n    scene_index=0  # Add to specific scene\n)\n</code></pre>"},{"location":"pt/integrations/platforms/openai/#narracao-automatizada","title":"Narra\u00e7\u00e3o Automatizada","text":"<pre><code># Generate narration for entire project\nproject.add_narration(synthesizer)\n\n# Or generate for specific scene\nscene_with_narration = scene.with_narration(synthesizer)\nproject.add_timeline_events(scene_with_narration)\n</code></pre> <p>A integra\u00e7\u00e3o OpenAI no Mosaico fornece ferramentas poderosas para processamento de \u00e1udio na produ\u00e7\u00e3o de v\u00eddeos, permitindo transcri\u00e7\u00e3o automatizada, tradu\u00e7\u00e3o e s\u00edntese de voz de alta qualidade. O design modular permite f\u00e1cil integra\u00e7\u00e3o com outros componentes do pipeline de produ\u00e7\u00e3o de v\u00eddeo.</p>"}]}